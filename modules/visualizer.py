# modules/visualizer.py

import os
from math import cos, radians

import streamlit as st

from folium.plugins import Fullscreen, FloatImage
from folium.features import DivIcon

import rasterio
import tempfile
import zipfile
import shutil
import folium
import geopandas as gpd
import numpy as np
import pandas as pd
import base64
import plotly.express as px
import plotly.graph_objects as go
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors
import branca.colormap as cm
import branca.colormap as bcm
from rasterio import features
from rasterio.transform import from_origin
from rasterio.transform import array_bounds
from pyproj import Transformer
import pymannkendall as mk
import requests
import io
import sys
from folium import plugins
from folium.plugins import LocateControl, MarkerCluster
from plotly.subplots import make_subplots
from prophet import Prophet
from scipy import stats
import scipy.ndimage as ndimage
from scipy.ndimage import gaussian_filter
from matplotlib import path as mpath
from folium.plugins import Fullscreen, Draw, MeasureControl, MousePosition

# Desactivar expl√≠citamente LaTeX en el renderizado de etiquetas
st.set_option('client.showErrorDetails', False)

# Imports de Ciencia de Datos y An√°lisis

from scipy.interpolate import Rbf, griddata
from shapely.geometry import Point
from shapely.geometry import LineString, MultiLineString, Point, box
from shapely.geometry import MultiPolygon, Polygon
from statsmodels.tsa.seasonal import seasonal_decompose
from streamlit_folium import st_folium, folium_static

import modules.life_zones as lz
import modules.land_cover as lc

# M√≥dulos Internos

from modules.config import Config
import modules.analysis as analysis

# Importar funciones de an√°lisis (Manejo de errores por si faltan)
try:
    from modules.analysis import (calculate_climatic_indices,
                                  calculate_duration_curve,
                                  calculate_hydrological_balance,
                                  calculate_hypsometric_curve,
                                  calculate_morphometry,
                                  calculate_percentiles_extremes,
                                  calculate_return_periods, calculate_spei,
                                  calculate_water_balance_turc,
                                  classify_holdridge_point,
                                  estimate_temperature,
                                  generate_life_zone_raster)

except ImportError:
    # Dummies para evitar crash visual si falta backend
    def calculate_morphometry(g):
        return {
            "area_km2": 100,
            "perimetro_km": 50,
            "alt_prom_m": 1500,
            "pendiente_prom": 15,
        }

# =============================================================================
# UTILIDAD: B√öSQUEDA INSENSIBLE A MAY√öSCULAS/MIN√öSCULAS ü¶Ö
# =============================================================================
def find_col(df, candidates):
    """Busca una columna en el DF ignorando may√∫sculas/min√∫sculas."""
    if df is None or df.empty: return None
    df_cols = [c.lower() for c in df.columns]
    for cand in candidates:
        if cand.lower() in df_cols:
            return df.columns[df_cols.index(cand.lower())]
    return None

    def calculate_hydrological_balance(p, t, g):
        return {"P": p, "ET": p * 0.6, "Q_mm": p * 0.4, "Vol": (p * 0.4 * 100) / 1000}

    def calculate_duration_curve(ts, c, a):
        return None

    def calculate_climatic_indices(ts, a):
        return {}

    def calculate_hypsometric_curve(g):
        return None

def get_safe_cols(df):
    """
    Funci√≥n PARCHE para compatibilidad. 
    Detecta si el DF usa nombres nuevos (latitud, nombre) o viejos (Latitud_geo, Nom_Est).
    """
    if df is None or df.empty: return None, None, None
    
    # 1. Detectar Latitud
    c_lat = next((c for c in ['latitud', 'Latitud', 'Latitud_geo', 'lat', 'LATITUD'] if c in df.columns), None)
    
    # 2. Detectar Longitud
    c_lon = next((c for c in ['longitud', 'Longitud', 'Longitud_geo', 'lon', 'LONGITUD'] if c in df.columns), None)
    
    # 3. Detectar Nombre
    c_nom = next((c for c in ['nombre', 'Nombre', 'Nom_Est', 'station_name', 'ESTACION'] if c in df.columns), None)
    
    return c_lat, c_lon, c_nom
# ------------------------------------------------

# PESTA√ëA DE BIENVENIDA (P√ÅGINA DE INICIO RENOVADA)
# ==============================================================================
def display_welcome_tab():
    # CSS para ajustar m√°rgenes
    st.markdown(
        """
        <style>
        .block-container { padding-top: 1rem; }
        h1 { margin-top: -3rem; }
        </style>
    """,
        unsafe_allow_html=True,
    )

    st.title(f"Bienvenido a {Config.APP_TITLE}")
    st.caption(
        "Sistema de Informaci√≥n Hidroclim√°tica Integrada para la Gesti√≥n Integral del Agua y la Biodiversidad en el Norte de la Region Andina"
    )

    # Pesta√±as de Inicio
    tab_intro, tab_clima, tab_modulos, tab_aleph = st.tabs(
        [
            "üìò Presentaci√≥n del Sistema",
            "üèîÔ∏è Climatolog√≠a Andina",
            "üõ†Ô∏è M√≥dulos y Capacidades",
            "üìñ El Aleph",
        ]
    )

    # --- PESTA√ëA 1: PRESENTACI√ìN (SIN LOGO) ---
    with tab_intro:
        # Usamos el ancho completo ahora
        st.markdown(
            """
        ### Origen y Visi√≥n
        **SIHCLI-POTER** nace de la necesidad imperativa de integrar datos, ciencia y tecnolog√≠a para la toma de decisiones informadas en el territorio.
        En un contexto de variabilidad clim√°tica creciente, la gesti√≥n del recurso h√≠drico y el ordenamiento territorial requieren herramientas que transformen datos dispersos en conocimiento accionable.

        Este sistema no es solo un repositorio de datos; es un **cerebro anal√≠tico** dise√±ado para procesar, modelar y visualizar la complejidad hidrometeorol√≥gica de la regi√≥n Andina.
        Su arquitectura modular permite desde el monitoreo en tiempo real hasta la proyecci√≥n de escenarios de cambio clim√°tico a largo plazo.

        ### Aplicaciones Clave
        * **Gesti√≥n del Riesgo:** Alertas tempranas y mapas de vulnerabilidad ante eventos extremos (sequ√≠as e inundaciones).
        * **Planeaci√≥n Territorial (POT):** Insumos t√©cnicos para la zonificaci√≥n ambiental y la gesti√≥n de cuencas.
        * **Agricultura de Precisi√≥n:** Calendarios de siembra basados en pron√≥sticos estacionales y zonas de vida.
        * **Investigaci√≥n:** Base de datos depurada y herramientas estad√≠sticas para estudios acad√©micos.

        ---
        **Versi√≥n:** 2.0 (Cloud-Native) | **Desarrollado por:** omejia - POTER.
        """
        )

    # --- PESTA√ëA 2: CLIMATOLOG√çA ANDINA ---
    with tab_clima:
        st.markdown(
            """
        ### La Danza del Clima en los Andes
        La regi√≥n Andina es un mosaico clim√°tico de una complejidad fascinante.
        Aqu√≠, la geograf√≠a no es solo un escenario, sino un actor protagonista que esculpe el clima kil√≥metro a kil√≥metro.

        **La Verticalidad como Destino:**
        En los Andes, viajar hacia arriba es como viajar hacia los polos.
        En pocos kil√≥metros lineales, pasamos del calor h√∫medo de los valles interandinos (bosque seco tropical) a la neblina perpetua de los bosques de niebla, y finalmente al g√©lido silencio de los p√°ramos y las nieves perpetuas. Esta **zonificaci√≥n altitudinal** (bien descrita por Holdridge) define la vocaci√≥n del suelo y la biodiversidad.

        **El Pulso de Dos Oc√©anos:**
        Somos un pa√≠s anfibio, respirando la humedad que llega tanto del Pac√≠fico (Choc√≥ Biogeogr√°fico) como de la Amazon√≠a.
        Los vientos alisios chocan contra nuestras cordilleras, descargando su humedad en las vertientes orientales y creando "f√°bricas de agua" que alimentan nuestros grandes r√≠os.

        **La Variabilidad (ENSO):**
        Este sistema complejo no es est√°tico. Est√° sometido al latido irregular del Pac√≠fico Ecuatorial:
        * **El Ni√±o (Fase C√°lida):** Cuando el oc√©ano se calienta, la atm√≥sfera sobre nosotros se estabiliza, las nubes se disipan y la sequ√≠a amenaza, trayendo consigo el riesgo de incendios y desabastecimiento.
        * **La Ni√±a (Fase Fr√≠a):** Cuando el oc√©ano se enfr√≠a, los vientos se aceleran y la humedad se condensa con furia, desbordando r√≠os y saturando laderas.

        Entender esta climatolog√≠a no es solo leer term√≥metros; es comprender la interacci√≥n din√°mica entre la monta√±a, el viento y el oc√©ano.
        """
        )

    # --- PESTA√ëA 3: M√ìDULOS ---
    with tab_modulos:
        st.markdown(
            """
        ### Arquitectura del Sistema
        SIHCLI-POTER est√° estructurado en m√≥dulos especializados interconectados:

        1.  **üö® Monitoreo (Tiempo Real):**
            * Tablero de control con las √∫ltimas lecturas de estaciones telem√©tricas.
            * Alertas inmediatas de umbrales cr√≠ticos.

        2.  **üó∫Ô∏è Distribuci√≥n Espacial:**
            * Mapas interactivos para visualizar la red de monitoreo.
            * An√°lisis de cobertura espacial y densidad de datos.

        3.  **üîÆ Pron√≥stico Clim√°tico & ENSO:**
            * Integraci√≥n directa con el **IRI (Columbia University)** para pron√≥sticos oficiales de El Ni√±o/La Ni√±a.
            * Modelos de predicci√≥n local (Prophet, SARIMA) y an√°lisis de probabilidades.

        4.  **üìâ Tendencias y Riesgo:**
            * An√°lisis estad√≠stico de largo plazo (Mann-Kendall) para detectar si llueve m√°s o menos que antes.
            * Mapas de vulnerabilidad h√≠drica interpolados.

        5.  **üõ∞Ô∏è Sat√©lite y Sesgo:**
            * Comparaci√≥n de datos de tierra vs. rean√°lisis satelital (ERA5-Land).
            * Herramientas para corregir y rellenar series hist√≥ricas.

        6.  **üå± Zonas de Vida y Cobertura:**
            * C√°lculo autom√°tico de la clasificaci√≥n de Holdridge.
            * An√°lisis de uso del suelo y cobertura vegetal.
        """
        )

    # --- PESTA√ëA 4: EL ALEPH ---
    with tab_aleph:
        c_text, c_img = st.columns([3, 1])
        with c_text:
            st.markdown(
                """
            > *"Borges y el Aleph: La met√°fora perfecta de la informaci√≥n total."*

            ### Fragmento de "El Aleph"

            "... Todo lenguaje es un alfabeto de s√≠mbolos cuyo ejercicio presupone un pasado que los interlocutores comparten;
            ¬øc√≥mo transmitir a los otros el infinito Aleph, que mi temerosa memoria apenas abarca? (...)

            En la parte inferior del escal√≥n, hacia la derecha, vi una peque√±a esfera tornasolada, de casi intolerable fulgor.
            Al principio la cre√≠ giratoria; luego comprend√≠ que ese movimiento era una ilusi√≥n producida por los vertiginosos espect√°culos que encerraba.
            El di√°metro del Aleph ser√≠a de dos o tres cent√≠metros, pero el espacio c√≥smico estaba ah√≠, sin disminuci√≥n de tama√±o.
            Cada cosa (la luna del espejo, digamos) era infinitas cosas, porque yo la ve√≠a claramente desde todos los puntos del universo.

            Vi el populoso mar, vi el alba y la tarde, vi las muchedumbres de Am√©rica,
            vi una plateada telara√±a en el centro de una negra pir√°mide, vi un laberinto roto (era Londres),
            vi interminables ojos inmediatos escrut√°ndose en m√≠ como en un espejo, vi todos los espejos del planeta y ninguno me reflej√≥...

            **Vi el engranaje del amor y la modificaci√≥n de la muerte, vi el Aleph, desde todos los puntos,
            vi en el Aleph la tierra, y en la tierra otra vez el Aleph y en el Aleph la tierra, vi mi cara y mis v√≠sceras, vi tu cara, y sent√≠ v√©rtigo y llor√©,
            porque mis ojos hab√≠an visto ese objeto secreto y conjetural, cuyo nombre usurpan los hombres, pero que ning√∫n hombre ha mirado: el inconcebible universo."**

            ‚Äî *Jorge Luis Borges (1945)*
            """
            )
        with c_img:
            st.info(
                "El Aleph del tiempo, del clima, del agua, de la biodiversidad, ... del terri-torio."
            )


# -----------------------------------------------------------------------------
# 1. FUNCIONES AUXILIARES
# -----------------------------------------------------------------------------

# --- HELPER: GEOLOCALIZACI√ìN MANUAL PARA PLOTLY ---
def _get_user_location_sidebar(key_suffix=""):
    """Agrega controles en el sidebar para ubicar al usuario en mapas Plotly."""
    with st.sidebar.expander(f"üìç Mi Ubicaci√≥n ({key_suffix})", expanded=False):
        st.caption(
            "Ingrese coordenadas para ver su ubicaci√≥n en los mapas est√°ticos (Zonas de Vida, Isoyetas, etc)."
        )
        # Usamos key_suffix para hacer √∫nicos los keys
        u_lat = st.number_input(
            "Latitud:", value=6.25, format="%.4f", step=0.01, key=f"u_lat_{key_suffix}"
        )
        u_lon = st.number_input(
            "Longitud:",
            value=-75.56,
            format="%.4f",
            step=0.01,
            key=f"u_lon_{key_suffix}",
        )
        show_loc = st.checkbox(
            "Mostrar en mapa", value=False, key=f"show_loc_{key_suffix}"
        )

        if show_loc:
            st.success(f"üìç Ubicaci√≥n activa:\nLat: {u_lat}\nLon: {u_lon}")
            return (u_lat, u_lon)
        return None

# ==============================================================================
# 0. EST√âTICA UNIFICADA (EL ALEPH)
# ==============================================================================

# --- A. GENERADOR DE POPUPS (Tu dise√±o solicitado) ---
def generar_popup_estacion(row, valor_col='ppt_media'):
    """
    Genera el HTML para el popup de la estaci√≥n con datos estad√≠sticos.
    """
    # Limpieza de strings para evitar errores de comillas
    nombre = str(row.get('nombre', 'Estaci√≥n')).replace("'", "")
    muni = str(row.get('municipio', 'N/A')).replace("'", "")
    
    # Extracci√≥n de valores num√©ricos
    altura = float(row.get('altitud', 0))
    valor = float(row.get(valor_col, 0))
    std = float(row.get('ppt_std', 0))
    anios = int(row.get('n_anios', 0)) # <--- Nuevo campo calculado
    
    html = f"""
    <div style='font-family:sans-serif; font-size:12px; min-width:160px; line-height:1.4;'>
        <b style='color:#1f77b4; font-size:14px'>{nombre}</b>
        <hr style='margin:4px 0; border-top:1px solid #ddd'>
        üìç <b>Mpio:</b> {muni}<br>
        ‚õ∞Ô∏è <b>Altitud:</b> {altura:.0f} msnm<br>
        üíß <b>P. Media:</b> {valor:.0f} mm/a√±o<br>
        üìâ <b>Desv. Std:</b> ¬±{std:.0f} mm<br>
        üìÖ <b>Registro:</b> {anios} a√±os
    </div>
    """
    return html

def generar_popup_bocatoma(row):
    """Popup HTML para Bocatomas (Campos Reales)."""
    nombre = str(row.get('nombre_acu', 'Bocatoma')).replace("'", "")
    fuente = str(row.get('fuente_aba', 'N/A')).replace("'", "")
    # Combinamos Municipio y Vereda
    mpio = str(row.get('municipio', '')).strip()
    vereda = str(row.get('veredas', '')).strip()
    ubicacion = f"{mpio} - {vereda}" if vereda else mpio
    
    tipo = str(row.get('tipo', 'N/A'))
    entidad = str(row.get('entidad_ad', 'N/A'))

    return f"""
    <div style='font-family:sans-serif; font-size:12px; min-width:180px;'>
        <b style='color:#16a085; font-size:14px'>üö∞ {nombre}</b>
        <hr style='margin:4px 0; border-top:1px solid #ddd'>
        üìç <b>Ubicaci√≥n:</b> {ubicacion}<br>
        üåä <b>Fuente:</b> {fuente}<br>
        ‚öôÔ∏è <b>Tipo:</b> {tipo}<br>
        üè¢ <b>Entidad:</b> {entidad}
    </div>
    """

def generar_popup_predio(row):
    """Popup HTML blindado contra may√∫sculas/min√∫sculas."""
    
    # Normalizamos las llaves del row a min√∫sculas para buscar sin errores
    datos_norm = {k.lower(): v for k, v in row.items()}
    
    def get_seguro(col_key, default='N/A'):
        val = datos_norm.get(col_key.lower(), default)
        if val is None or str(val).lower() in ['none', 'nan', 'null', '']:
            return default
        return str(val).strip()

    # Ahora buscamos usando las claves en min√∫scula (coincide con tu tabla)
    nombre = get_seguro('nombre_pre', 'Predio')
    pk = get_seguro('pk_predios')
    anio = get_seguro('a√±o_acuer', '-')
    
    mpio = get_seguro('nomb_mpio')
    vereda = get_seguro('nombre_ver')
    ubicacion = f"{mpio} / {vereda}" if (mpio != 'N/A' or vereda != 'N/A') else "N/A"
    
    embalse = get_seguro('embalse')
    mecanismo = get_seguro('mecanism')
    
    # √Årea
    try:
        # Buscamos 'area_ha' o 'shape_area' por si acaso
        val_area = float(datos_norm.get('area_ha', 0))
        area_txt = f"{val_area:.2f} ha"
    except:
        area_txt = "N/A"

    return f"""
    <div style='font-family:sans-serif; font-size:12px; min-width:200px;'>
        <b style='color:#d35400; font-size:14px'>üè° {nombre}</b>
        <hr style='margin:4px 0; border-top:1px solid #ddd'>
        üîë <b>PK:</b> {pk}<br>
        üìÖ <b>A√±o:</b> {anio}<br>
        üìç <b>Ubicaci√≥n:</b> {ubicacion}<br>
        üíß <b>Embalse:</b> {embalse}<br>
        üìú <b>Mecanismo:</b> {mecanismo}<br>
        üìê <b>√Årea:</b> {area_txt}
    </div>
    """

    # 3. HTML Estructurado
    return f"""
    <div style='font-family:sans-serif; font-size:12px; min-width:220px;'>
        <b style='color:#d35400; font-size:14px'>üè° {nombre_predio}</b>
        <hr style='margin:4px 0; border-top:1px solid #ddd'>
        üîë <b>PK:</b> {pk}<br>
        üìÖ <b>A√±o:</b> {anio}<br>
        üìç <b>Ubicaci√≥n:</b> {ubicacion}<br>
        üíß <b>Embalse:</b> {embalse}<br>
        üìú <b>Mecanismo:</b> {mecanismo}<br>
        üìê <b>√Årea:</b> {area_txt}
    </div>
    """

    # 2. Construcci√≥n del HTML
    return f"""
    <div style='font-family:sans-serif; font-size:12px; min-width:200px;'>
        <b style='color:#d35400; font-size:14px'>üè° {nombre}</b>
        <hr style='margin:4px 0; border-top:1px solid #ddd'>
        üÜî <b>ID Predio:</b> {pk_id}<br>
        üíß <b>Embalse:</b> {embalse}<br>
        üìç <b>Vereda:</b> {vereda}<br>
        üìê <b>√Årea:</b> {area_txt}<br>
        üìú <b>Mecanismo:</b> {mecanismo}
    </div>
    """
    
def _plot_panel_regional(rng, meth, col, tag, u_loc, df_long, gdf_stations):
    """Helper para graficar un panel regional (A o B)."""
    mask = (df_long[Config.YEAR_COL] >= rng[0]) & (df_long[Config.YEAR_COL] <= rng[1])
    df_sub = df_long[mask]
    df_avg = _calcular_promedios_reales(df_sub)

    if df_avg.empty:
        col.warning(f"Sin datos para {rng}")
        return

    if Config.STATION_NAME_COL not in df_avg.columns:
        df_avg = df_avg.reset_index()

    df_m = pd.merge(df_avg, gdf_stations, on=Config.STATION_NAME_COL).dropna(
        subset=["latitude", "longitude"]
    )

    if len(df_m) > 2:
        bounds = [
            df_m.longitude.min() - 0.1,
            df_m.longitude.max() + 0.1,
            df_m.latitude.min() - 0.1,
            df_m.latitude.max() + 0.1,
        ]
        gx, gy, gz = _run_interp(df_m, meth, bounds)

        if gz is not None:
            # Mapa Plotly (Isoyetas)
            fig = go.Figure(
                go.Contour(
                    z=gz.T,
                    x=gx[:, 0],
                    y=gy[0, :],
                    colorscale="Viridis",
                    colorbar=dict(title="mm"),
                    contours=dict(start=0, end=5000, size=200),
                )
            )

            # Estaciones
            fig.add_trace(
                go.Scatter(
                    x=df_m.longitude,
                    y=df_m.latitude,
                    mode="markers",
                    marker=dict(color="black", size=5),
                    text=df_m[Config.STATION_NAME_COL],
                    hoverinfo="text",
                    showlegend=False,
                )
            )

            # --- CAPA USUARIO (Estrella Roja) ---
            if u_loc:
                fig.add_trace(
                    go.Scatter(
                        x=[u_loc[1]],
                        y=[u_loc[0]],
                        mode="markers+text",
                        marker=dict(color="red", size=15, symbol="star"),
                        text=["üìç T√ö"],
                        textposition="top center",
                        name="Tu Ubicaci√≥n",
                    )
                )

            fig.update_layout(
                title=f"Ppt Media ({rng[0]}-{rng[1]})",
                margin=dict(l=0, r=0, b=0, t=30),
                height=350,
            )
            col.plotly_chart(fig, use_container_width=True)

            # Mapa Interactivo (Folium)
            with col.expander(
                f"üîé Ver Mapa Interactivo Detallado ({tag})", expanded=True
            ):
                col.write(
                    "Mapa navegable con detalles por estaci√≥n. Haga clic en los puntos."
                )

                # Centrar mapa en usuario si existe, sino en el centro de los datos
                if u_loc:
                    center_lat, center_lon = u_loc
                    zoom = 10
                else:
                    center_lat = (bounds[2] + bounds[3]) / 2
                    center_lon = (bounds[0] + bounds[1]) / 2
                    zoom = 8

                m = folium.Map(
                    location=[center_lat, center_lon],
                    zoom_start=zoom,
                    tiles="CartoDB positron",
                )

                for _, row in df_m.iterrows():
                    nombre = row[Config.STATION_NAME_COL]
                    lluvia = row[Config.PRECIPITATION_COL]
                    altura = row.get(Config.ALTITUDE_COL, "N/A")
                    muni = row.get(Config.MUNICIPALITY_COL, "N/A")

                    html = f"""
                    <div style='font-family:sans-serif;font-size:13px;min-width:180px'>
                        <h5 style='margin:0; color:#c0392b; border-bottom:1px solid #ccc; padding-bottom:4px'>{nombre}</h5>
                        <div style="margin-top:5px;"><b>Mun:</b> {muni}<br><b>Alt:</b> {altura} m</div>
                        <div style='background-color:#f0f2f6; padding:5px; margin-top:5px; border-radius:4px;'>
                            <b>Ppt Media:</b> {lluvia:,.0f} mm<br>
                        </div>
                    </div>
                    """
                    popup = folium.Popup(
                        folium.IFrame(html, width=220, height=160), max_width=220
                    )
                    folium.CircleMarker(
                        [row["latitude"], row["longitude"]],
                        radius=6,
                        color="blue",
                        fill=True,
                        fill_color="cyan",
                        fill_opacity=0.9,
                        popup=popup,
                        tooltip=f"{nombre}",
                    ).add_to(m)

                # 1. Marcador de Usuario (Si existe)
                if u_loc:
                    folium.Marker(
                        [u_loc[0], u_loc[1]],
                        icon=folium.Icon(color="black", icon="star"),
                        tooltip="Tu Ubicaci√≥n",
                    ).add_to(m)

                # 2. Bot√≥n de Geolocalizaci√≥n (El √≠cono que pediste)
                LocateControl(auto_start=False).add_to(m)
                st_folium(
                    m, height=350, use_container_width=True, key=f"folium_comp_{tag}"
                )

                # Bot√≥n GPS Nativo
                LocateControl(auto_start=False).add_to(m)
                st_folium(
                    m, height=350, use_container_width=True, key=f"fol_comp_{tag}"
                )

@st.cache_data(ttl=3600)
def get_img_as_base64(url):
    """
    Descarga una imagen y la convierte a string Base64.
    Esto permite incrustarla directamente en el HTML, evitando bloqueos de hotlinking.
    """
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Referer": "https://google.com",
    }
    try:
        r = requests.get(url, headers=headers, timeout=10)
        if r.status_code == 200:
            # Codificar a Base64
            encoded = base64.b64encode(r.content).decode()
            return f"data:image/png;base64,{encoded}"
    except Exception as e:
        print(f"Error Base64: {e}")
    return None


def analyze_point_data(lat, lon, df_long, gdf_stations, gdf_municipios, gdf_subcuencas):
    """
    Analiza un punto geogr√°fico:
    1. Toponimia (Municipio/Cuenca).
    2. Datos Hist√≥ricos (Interpolados).
    3. Variables Ambientales (Raster).
    """
    # NOTA: Point ya est√° importado globalmente, no lo redefinimos aqu√≠.
    
    # Importaciones locales seguras (expandidas para evitar error E701)
    try:
        import modules.land_cover as lc
    except ImportError:
        lc = None
        
    try:
        import modules.life_zones as lz
    except ImportError:
        lz = None

    try:
        import pymannkendall as mk
    except ImportError:
        mk = None

    # Configuraci√≥n
    Config = None
    try:
        from modules.config import Config as Cfg
        Config = Cfg
    except Exception:
        pass

    results = {}
    # Usamos Point del scope global
    point_geom = Point(lon, lat)  

    # 1. CONTEXTO GEOGR√ÅFICO
    results["Municipio"] = "Desconocido"
    results["Cuenca"] = "Fuera de cuencas principales"

    try:
        if gdf_municipios is not None and not gdf_municipios.empty:
            matches = gdf_municipios[gdf_municipios.contains(point_geom)]
            if not matches.empty:
                results["Municipio"] = matches.iloc[0].get("nombre", "Sin Nombre")

        if gdf_subcuencas is not None and not gdf_subcuencas.empty:
            matches_c = gdf_subcuencas[gdf_subcuencas.contains(point_geom)]
            if not matches_c.empty:
                results["Cuenca"] = matches_c.iloc[0].get("nombre", "Sin Nombre")
    except Exception as e:
        print(f"Error espacial: {e}")

    # 2. INTERPOLACI√ìN (Simplificada)
    results["Ppt_Media"] = 0
    results["Tendencia"] = 0
    
    try:
        if not gdf_stations.empty:
            # L√≥gica simple de proximidad si no hay interpolaci√≥n compleja
            # Aqu√≠ puedes reactivar tu l√≥gica IDW completa si la necesitas
            pass 
    except Exception:
        pass

    # 3. RASTERS (ALTITUD Y COBERTURA)
    results["Altitud"] = 1500
    results["Cobertura"] = "No disponible"

    try:
        import rasterio
        
        # A. Altitud
        if Config and hasattr(Config, "DEM_FILE_PATH"):
            if os.path.exists(Config.DEM_FILE_PATH):
                try:
                    with rasterio.open(Config.DEM_FILE_PATH) as src:
                        val_gen = src.sample([(lon, lat)])
                        val = next(val_gen)[0]
                        if val > -1000:
                            results["Altitud"] = int(val)
                except Exception:
                    pass

        # B. Cobertura (M√≥dulo Centralizado)
        if Config and hasattr(Config, "LAND_COVER_RASTER_PATH"):
            if lc:
                results["Cobertura"] = lc.get_land_cover_at_point(
                    lat, lon, Config.LAND_COVER_RASTER_PATH
                )
            
    except Exception as e:
        results["Cobertura"] = f"Error: {str(e)}"

    # 4. ZONA DE VIDA
    try:
        if lz and hasattr(lz, "classify_life_zone_alt_ppt"):
            z_id = lz.classify_life_zone_alt_ppt(results["Altitud"], results["Ppt_Media"])
            results["Zona_Vida"] = lz.holdridge_int_to_name_simplified.get(z_id, "Desconocido")
        else:
            results["Zona_Vida"] = "M√≥dulo LZ no disponible"
    except Exception:
        results["Zona_Vida"] = "Error c√°lculo LZ"

    return results


def get_weather_forecast_detailed(lat, lon):
    """
    Obtiene pron√≥stico detallado de Open-Meteo con 9 variables agrometeorol√≥gicas.
    """
    try:
        url = "https://api.open-meteo.com/v1/forecast"
        params = {
            "latitude": lat,
            "longitude": lon,
            "daily": [
                "temperature_2m_max",
                "temperature_2m_min",
                "precipitation_sum",
                "relative_humidity_2m_mean",
                "surface_pressure_mean",
                "et0_fao_evapotranspiration",
                "shortwave_radiation_sum",
                "wind_speed_10m_max",
            ],
            "timezone": "auto",
        }
        response = requests.get(url, params=params, timeout=5)
        data = response.json()

        daily = data.get("daily", {})
        if not daily:
            return pd.DataFrame()

        # Crear DataFrame
        df = pd.DataFrame(
            {
                "Fecha": pd.to_datetime(daily.get("time", [])),
                "T. M√°x (¬∞C)": daily.get("temperature_2m_max", []),
                "T. M√≠n (¬∞C)": daily.get("temperature_2m_min", []),
                "Ppt. (mm)": daily.get("precipitation_sum", []),
                "HR Media (%)": daily.get("relative_humidity_2m_mean", []),
                "Presi√≥n (hPa)": daily.get("surface_pressure_mean", []),
                "ET‚ÇÄ (mm)": daily.get("et0_fao_evapotranspiration", []),
                "Radiaci√≥n SW (MJ/m¬≤)": daily.get("shortwave_radiation_sum", []),
                "Viento M√°x (km/h)": daily.get("wind_speed_10m_max", []),
            }
        )
        return df
    except Exception:
        return pd.DataFrame()


def create_enso_chart(enso_data):
    """
    Genera el gr√°fico avanzado de ENSO con franjas de fondo para las fases (El Ni√±o/La Ni√±a).
    """
    if (
        enso_data is None
        or enso_data.empty
        or Config.ENSO_ONI_COL not in enso_data.columns
    ):
        return go.Figure().update_layout(title="Datos ENSO no disponibles", height=300)

    # Preparar datos
    data = (
        enso_data.copy()
        .sort_values(Config.DATE_COL)
        .dropna(subset=[Config.ENSO_ONI_COL])
    )

    # Definir colores de fondo seg√∫n el valor ONI
    conditions = [data[Config.ENSO_ONI_COL] >= 0.5, data[Config.ENSO_ONI_COL] <= -0.5]
    colors = ["rgba(255, 0, 0, 0.2)", "rgba(0, 0, 255, 0.2)"]
    data["color"] = np.select(conditions, colors, default="rgba(200, 200, 200, 0.2)")

    y_min = data[Config.ENSO_ONI_COL].min() - 0.5
    y_max = data[Config.ENSO_ONI_COL].max() + 0.5

    fig = go.Figure()

    # 1. Barras de Fondo (Fases)
    fig.add_trace(
        go.Bar(
            x=data[Config.DATE_COL],
            y=[y_max - y_min] * len(data),
            base=y_min,
            marker_color=data["color"],
            width=86400000 * 30,  # Ancho aprox de 1 mes en ms
            hoverinfo="skip",
            showlegend=False,
            name="Fase",
        )
    )

    # 2. L√≠nea Principal (ONI)
    fig.add_trace(
        go.Scatter(
            x=data[Config.DATE_COL],
            y=data[Config.ENSO_ONI_COL],
            mode="lines",
            line=dict(color="black", width=2),
            name="Anomal√≠a ONI",
        )
    )

    # 3. L√≠neas de Umbral
    fig.add_hline(
        y=0.5,
        line_dash="dash",
        line_color="red",
        annotation_text="Umbral El Ni√±o (+0.5)",
    )
    fig.add_hline(
        y=-0.5,
        line_dash="dash",
        line_color="blue",
        annotation_text="Umbral La Ni√±a (-0.5)",
    )
    fig.add_hline(y=0, line_width=1, line_color="black")

    # 4. Leyenda Personalizada
    fig.add_trace(
        go.Scatter(
            x=[None],
            y=[None],
            mode="markers",
            marker=dict(symbol="square", size=10, color="rgba(255, 0, 0, 0.5)"),
            name="El Ni√±o",
        )
    )
    fig.add_trace(
        go.Scatter(
            x=[None],
            y=[None],
            mode="markers",
            marker=dict(symbol="square", size=10, color="rgba(0, 0, 255, 0.5)"),
            name="La Ni√±a",
        )
    )
    fig.add_trace(
        go.Scatter(
            x=[None],
            y=[None],
            mode="markers",
            marker=dict(symbol="square", size=10, color="rgba(200, 200, 200, 0.5)"),
            name="Neutral",
        )
    )

    fig.update_layout(
        title="Fases del Fen√≥meno ENSO y Anomal√≠a ONI (Hist√≥rico)",
        yaxis_title="Anomal√≠a ONI (¬∞C)",
        xaxis_title="Fecha",
        height=500,
        hovermode="x unified",
        yaxis_range=[y_min, y_max],
        barmode="overlay",
        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
    )
    return fig


# 1. FUNCIONES AUXILIARES DE PARSEO Y DATOS
# -----------------------------------------------------------------------------


def parse_spanish_date_visualizer(x):
    """
    Funci√≥n de rescate para fechas en espa√±ol dentro del visualizador.
    Convierte 'ene-70', 'feb-90' a datetime real.
    """
    if pd.isna(x) or str(x).strip() == "": return pd.NaT
    if isinstance(x, pd.Timestamp): return x
    
    x_str = str(x).lower().strip()
    
    # Mapa de traducci√≥n
    trans = {
        "ene": "Jan", "feb": "Feb", "mar": "Mar", "abr": "Apr",
        "may": "May", "jun": "Jun", "jul": "Jul", "ago": "Aug",
        "sep": "Sep", "oct": "Oct", "nov": "Nov", "dic": "Dec"
    }
    
    for es, en in trans.items():
        if es in x_str:
            x_str = x_str.replace(es, en)
            break
            
    try:
        # Intento 1: Formato corto 'Jan-70'
        return pd.to_datetime(x_str, format="%b-%y")
    except:
        try:
            # Intento 2: Est√°ndar
            return pd.to_datetime(x_str)
        except:
            return pd.NaT

# 2. FUNCIONES PRINCIPALES DE VISUALIZACI√ìN
# -----------------------------------------------------------------------------
# -----------------------------------------------------------------------------
# NUEVA FUNCI√ìN: CONEXI√ìN CON IRI (COLUMBIA UNIVERSITY)
# -----------------------------------------------------------------------------
try:
    from modules.iri_api import (fetch_iri_data, process_iri_plume,
                                 process_iri_probabilities)
except ImportError:
    # Evita que la app se rompa si el archivo iri_api.py a√∫n no se ha creado o cargado
    fetch_iri_data = None


# NUEVA FUNCI√ìN: VISUALIZACI√ìN DEL PRON√ìSTICO OFICIAL IRI/CPC
# Columbia University
# -----------------------------------------------------------------------------
def display_iri_forecast_tab():
    st.subheader("üåé Pron√≥stico Oficial ENSO (IRI - Columbia University)")

    # --- SECCI√ìN EDUCATIVA (NUEVA CAJA DESPLEGABLE) ---
    with st.expander(
        "üìö Conceptos, Metodolog√≠a e Importancia (Pron√≥stico ENSO - IRI)",
        expanded=False,
    ):
        st.markdown(
            """
        Este m√≥dulo se conecta directamente a los servidores del **International Research Institute for Climate and Society (IRI)**.
        Los datos se actualizan mensualmente (aprox. el d√≠a 19) y representan el est√°ndar global para la predicci√≥n de El Ni√±o/La Ni√±a.
        1. Definici√≥n
        El **Pron√≥stico ENSO del IRI** (International Research Institute for Climate and Society) es el est√°ndar global para monitorear el fen√≥meno El Ni√±o-Oscilaci√≥n del Sur. Recopila y armoniza las predicciones de m√°s de 20 instituciones cient√≠ficas de todo el mundo (NASA, NOAA, JMA, ECMWF, etc.).

        2. Metodolog√≠a
        El pron√≥stico se basa en la regi√≥n **Ni√±o 3.4** (Pac√≠fico Ecuatorial Central) y combina dos tipos de modelos:
        * **ü§ñ Modelos Din√°micos:** Usan supercomputadoras para simular las leyes f√≠sicas del oc√©ano y la atm√≥sfera (ej. NCEP CFSv2, ECMWF). Son mejores para predicciones a largo plazo.
        * **üìà Modelos Estad√≠sticos:** Usan patrones hist√≥ricos y matem√°ticas para proyectar el futuro. Son eficientes para el corto plazo.

        3. Interpretaci√≥n de los Gr√°ficos
        * **üìâ La "Pluma" (Spaghetti Plot):** Muestra la incertidumbre. Cada l√≠nea es una opini√≥n cient√≠fica distinta.
            * **L√≠nea Negra Gruesa:** Es el promedio de todos los modelos (Consenso). Suele ser el predictor m√°s confiable.
            * **Umbrales:** Si el promedio supera **+0.5¬∞C**, se prev√© **El Ni√±o**. Si baja de **-0.5¬∞C**, se prev√© **La Ni√±a**.
        * **üìä Probabilidades:** Muestra el porcentaje de certeza de que ocurra cada evento (Ni√±o, Ni√±a o Neutral) en cada trimestre venidero.

        4. Utilidad en Colombia
        El ENSO es el principal modulador del clima en Colombia:
        * üî• **El Ni√±o:** Generalmente asociado a disminuci√≥n de lluvias, sequ√≠as y altas temperaturas.
        * üíß **La Ni√±a:** Generalmente asociada a aumento de lluvias, inundaciones y deslizamientos.

        5. Fuente Oficial
        Datos provistos directamente v√≠a FTP seguro por el [IRI / Columbia University Climate School](https://iri.columbia.edu/our-expertise/climate/forecasts/enso/current/).
        """
        )

    # 1. Verificar credenciales y m√≥dulo
    if fetch_iri_data is None:
        st.error(
            "‚ö†Ô∏è Falta el m√≥dulo 'modules/iri_api.py' o hubo un error al importarlo."
        )
        return

    # 2. Cargar Datos (Pluma y Probabilidades)
    with st.spinner("Conectando con FTP seguro de IRI (Columbia University)..."):
        json_plume = fetch_iri_data("enso_plumes.json")
        json_probs = fetch_iri_data("enso_cpc_prob.json")

    if not json_plume or not json_probs:
        st.warning(
            "No se pudieron cargar los datos. Verifica tu conexi√≥n a internet o las credenciales en '.streamlit/secrets.toml'."
        )
        return

    # 3. Procesar Datos
    plume_data = process_iri_plume(json_plume)
    df_probs = process_iri_probabilities(json_probs)

    if not plume_data or df_probs.empty:
        st.error("Datos recibidos pero con formato inesperado o vac√≠os.")
        return

    # --- VISUALIZACI√ìN ---
    tab_plume, tab_prob = st.tabs(
        ["üìâ Pluma de Modelos (SST)", "üìä Probabilidades (%)"]
    )

    # GR√ÅFICO 1: PLUMA DE MODELOS (Plume Plot)
    with tab_plume:
        # T√≠tulo descriptivo con fecha
        forecast_date_str = f"{plume_data['month_idx']+1}/{plume_data['year']}"
        st.markdown(f"**Emisi√≥n del Pron√≥stico:** {forecast_date_str}")

        fig = go.Figure()
        seasons = plume_data["seasons"]

        # Umbrales
        fig.add_shape(
            type="line",
            x0=seasons[0],
            x1=seasons[-1],
            y0=0.5,
            y1=0.5,
            line=dict(color="red", width=1, dash="dash"),
            name="Umbral Ni√±o",
        )
        fig.add_shape(
            type="line",
            x0=seasons[0],
            x1=seasons[-1],
            y0=-0.5,
            y1=-0.5,
            line=dict(color="blue", width=1, dash="dash"),
            name="Umbral Ni√±a",
        )

        all_values = []
        for model in plume_data["models"]:
            color = (
                "rgba(100, 200, 100, 0.6)"
                if model["type"] == "Statistical"
                else "rgba(150, 150, 150, 0.6)"
            )

            # Recortar valores
            y_vals = model["values"][: len(seasons)]

            fig.add_trace(
                go.Scatter(
                    x=seasons,
                    y=y_vals,
                    mode="lines",
                    name=model["name"],
                    line=dict(color=color, width=1),
                    showlegend=True,  # <--- CAMBIO: Leyenda visible para cada modelo
                    hoverinfo="name+y",
                )
            )
            all_values.append(y_vals)

        # --- CORRECCI√ìN MATEM√ÅTICA Y PROMEDIO ---
        try:
            # 1. Encontrar longitud m√°xima
            max_len = max(len(v) for v in all_values) if all_values else 0

            # 2. Limpiar matriz: Convertir 'None' a 'np.nan' y rellenar huecos
            clean_matrix = []
            for v in all_values:
                # Convertimos None -> np.nan (float)
                row_clean = [val if val is not None else np.nan for val in v]
                # Rellenamos si falta longitud
                padding = [np.nan] * (max_len - len(row_clean))
                clean_matrix.append(row_clean + padding)

            # 3. Crear array float expl√≠cito (evita el error de tipos mixtos)
            arr = np.array(clean_matrix, dtype=float)

            # 4. Calcular promedio ignorando NaNs
            avg_vals = np.nanmean(arr, axis=0)[: len(seasons)]

            fig.add_trace(
                go.Scatter(
                    x=seasons,
                    y=avg_vals,
                    mode="lines+markers",
                    name="PROMEDIO MULTIMODELO",
                    line=dict(color="black", width=4),
                    marker=dict(size=8),
                    showlegend=True,
                )
            )
        except Exception as e:
            st.warning(f"No se pudo calcular la l√≠nea de promedio: {e}")

        fig.update_layout(
            title=f"Predicci√≥n Anomal√≠a SST - Ni√±o 3.4 (Emisi√≥n: {forecast_date_str})",  # <--- CAMBIO: Fecha en t√≠tulo
            yaxis_title="Anomal√≠a de Temperatura (¬∞C)",
            xaxis_title="Trimestre",
            height=600,
            hovermode="x unified",
            showlegend=True,
            legend=dict(  # <--- CAMBIO: Configuraci√≥n de leyenda a la derecha
                yanchor="top",
                y=1,
                xanchor="left",
                x=1.02,
                font=dict(size=10),
                traceorder="normal",
            ),
            margin=dict(r=150),  # Margen derecho para que quepa la leyenda
        )
        st.plotly_chart(fig)
        st.caption(
            "üî¥ Umbral El Ni√±o (+0.5¬∞C) | üîµ Umbral La Ni√±a (-0.5¬∞C). L√≠neas grises: Modelos Din√°micos. L√≠neas verdes: Estad√≠sticos."
        )

    # GR√ÅFICO 2: PROBABILIDADES
    with tab_prob:
        st.markdown(
            f"##### Probabilidad Oficial (Emisi√≥n: {plume_data['month_idx']+1}/{plume_data['year']})"
        )
        colors = {"La Ni√±a": "#00008B", "Neutral": "#808080", "El Ni√±o": "#DC143C"}

        fig_bar = go.Figure()
        for evento in ["La Ni√±a", "Neutral", "El Ni√±o"]:
            fig_bar.add_trace(
                go.Bar(
                    x=df_probs["Trimestre"],
                    y=df_probs[evento],
                    name=evento,
                    marker_color=colors[evento],
                    text=df_probs[evento].apply(lambda x: f"{x}%"),
                    textposition="auto",
                )
            )

        fig_bar.update_layout(
            barmode="stack",
            title=f"Consenso Probabil√≠stico CPC/IRI ({plume_data['year']})",
            yaxis_title="Probabilidad (%)",
            height=500,
            yaxis=dict(range=[0, 100]),
            legend=dict(
                orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1
            ),
        )
        st.plotly_chart(fig_bar, use_container_width=True)
        st.dataframe(df_probs.set_index("Trimestre"))


# CENTRO DE MONITOREO Y TIEMPO REAL (DASHBOARD)
# -----------------------------------------------------------------------------
def display_realtime_dashboard(df_long, gdf_stations, gdf_filtered, **kwargs):
    st.header("üö® Centro de Monitoreo y Tiempo Real")

    tab_fc, tab_sat, tab_alert = st.tabs(
        ["üå¶Ô∏è Pron√≥stico Semanal", "üõ∞Ô∏è Sat√©lite en Vivo", "üìä Alertas Hist√≥ricas"]
    )

    # --- SUB-PESTA√ëA 1: PRON√ìSTICO COMPLETO ---
    with tab_fc:
        if gdf_filtered is None or gdf_filtered.empty:
            st.warning("‚ö†Ô∏è Seleccione al menos una estaci√≥n en el men√∫ lateral.")
            return

        # Selector de Estaci√≥n
        estaciones_list = sorted(gdf_filtered[Config.STATION_NAME_COL].unique())
        sel_st = st.selectbox("Estaci√≥n para Pron√≥stico:", estaciones_list)

        if sel_st:
            st_dat = gdf_filtered[gdf_filtered[Config.STATION_NAME_COL] == sel_st].iloc[
                0
            ]

            # Intentar obtener pron√≥stico
            df_forecast = pd.DataFrame()
            try:
                # Importamos aqu√≠ para evitar ciclos si no se usa
                from modules.openmeteo_api import get_weather_forecast_detailed

                with st.spinner("Consultando modelos meteorol√≥gicos globales..."):
                    lat = (
                        st_dat["latitude"]
                        if "latitude" in st_dat
                        else st_dat.geometry.y
                    )
                    lon = (
                        st_dat["longitude"]
                        if "longitude" in st_dat
                        else st_dat.geometry.x
                    )
                    df_forecast = get_weather_forecast_detailed(lat, lon)
            except Exception as e:
                st.error(f"Error consultando pron√≥stico: {e}")

            if not df_forecast.empty:
                # 1. TARJETAS DE RESUMEN (HOY)
                td = df_forecast.iloc[0]  # Datos de hoy/ahora
                c1, c2, c3, c4 = st.columns(4)
                c1.metric(
                    "üå°Ô∏è T. M√°x/M√≠n",
                    f"{td.get('T. M√°x (¬∞C)', '--')}/{td.get('T. M√≠n (¬∞C)', '--')}¬∞C",
                )
                c2.metric("üåßÔ∏è Lluvia Hoy", f"{td.get('Ppt. (mm)', 0):.1f} mm")
                c3.metric("üå¨Ô∏è Viento M√°x", f"{td.get('Viento M√°x (km/h)', 0):.1f} km/h")
                c4.metric(
                    "‚òÄÔ∏è Radiaci√≥n", f"{td.get('Radiaci√≥n SW (MJ/m¬≤)', 0):.1f} MJ/m¬≤"
                )

                # 2. GR√ÅFICO PRINCIPAL (Climograma)
                st.markdown("#### üå°Ô∏è Temperatura y Precipitaci√≥n (7 D√≠as)")

                fig = make_subplots(specs=[[{"secondary_y": True}]])

                # Lluvia (Barras - Eje Derecha)
                fig.add_trace(
                    go.Bar(
                        x=df_forecast["Fecha"],
                        y=df_forecast["Ppt. (mm)"],
                        name="Lluvia (mm)",
                        marker_color="#4682B4",
                        opacity=0.6,
                    ),
                    secondary_y=True,
                )

                # Temperatura (L√≠neas - Eje Izquierda)
                fig.add_trace(
                    go.Scatter(
                        x=df_forecast["Fecha"],
                        y=df_forecast["T. M√°x (¬∞C)"],
                        name="T. M√°x",
                        line=dict(color="#FF4500", width=2),
                    ),
                    secondary_y=False,
                )

                fig.add_trace(
                    go.Scatter(
                        x=df_forecast["Fecha"],
                        y=df_forecast["T. M√≠n (¬∞C)"],
                        name="T. M√≠n",
                        line=dict(color="#1E90FF", width=2),
                        fill="tonexty",  # Relleno entre lineas
                    ),
                    secondary_y=False,
                )

                # Layout Ajustado para evitar cortes
                fig.update_layout(
                    height=450,
                    hovermode="x unified",
                    legend=dict(
                        orientation="h",  # Horizontal
                        yanchor="bottom",
                        y=1.02,  # Arriba del gr√°fico
                        xanchor="right",
                        x=1,
                    ),
                    margin=dict(l=50, r=50, t=50, b=50),
                )

                # Ejes
                fig.update_yaxes(
                    title_text="Temperatura (¬∞C)", secondary_y=False, showgrid=True
                )
                fig.update_yaxes(
                    title_text="Precipitaci√≥n (mm)",
                    secondary_y=True,
                    showgrid=False,
                    range=[0, max(df_forecast["Ppt. (mm)"].max() * 3, 10)],
                )

                st.plotly_chart(fig)

                # 3. GR√ÅFICOS SECUNDARIOS
                st.markdown("#### üçÉ Condiciones Atmosf√©ricas")
                col_g1, col_g2 = st.columns(2)

                with col_g1:
                    # Humedad y Presi√≥n
                    fig_atm = make_subplots(specs=[[{"secondary_y": True}]])
                    fig_atm.add_trace(
                        go.Scatter(
                            x=df_forecast["Fecha"],
                            y=df_forecast["HR Media (%)"],
                            name="Humedad",
                            line=dict(color="teal"),
                        ),
                        secondary_y=False,
                    )
                    fig_atm.add_trace(
                        go.Scatter(
                            x=df_forecast["Fecha"],
                            y=df_forecast.get(
                                "Presi√≥n (hPa)", [1013] * len(df_forecast)
                            ),
                            name="Presi√≥n",
                            line=dict(color="purple", dash="dot"),
                        ),
                        secondary_y=True,
                    )

                    fig_atm.update_layout(
                        title="Humedad y Presi√≥n",
                        height=350,
                        legend=dict(orientation="h", y=-0.2),
                    )
                    fig_atm.update_yaxes(title_text="HR (%)", secondary_y=False)
                    fig_atm.update_yaxes(
                        title_text="hPa", secondary_y=True, showgrid=False
                    )
                    st.plotly_chart(fig_atm, use_container_width=True)

                with col_g2:
                    # Energ√≠a y Agua (Radiaci√≥n + ET0)
                    fig_nrg = make_subplots(specs=[[{"secondary_y": True}]])
                    fig_nrg.add_trace(
                        go.Bar(
                            x=df_forecast["Fecha"],
                            y=df_forecast["Radiaci√≥n SW (MJ/m¬≤)"],
                            name="Radiaci√≥n",
                            marker_color="gold",
                        ),
                        secondary_y=False,
                    )
                    fig_nrg.add_trace(
                        go.Scatter(
                            x=df_forecast["Fecha"],
                            y=df_forecast["ET‚ÇÄ (mm)"],
                            name="Evapotranspiraci√≥n",
                            line=dict(color="green"),
                        ),
                        secondary_y=True,
                    )

                    fig_nrg.update_layout(
                        title="Energ√≠a y Ciclo del Agua",
                        height=350,
                        legend=dict(orientation="h", y=-0.2),
                    )
                    fig_nrg.update_yaxes(title_text="MJ/m¬≤", secondary_y=False)
                    fig_nrg.update_yaxes(
                        title_text="mm", secondary_y=True, showgrid=False
                    )
                    st.plotly_chart(fig_nrg, use_container_width=True)

                # 4. TABLA DETALLADA
                with st.expander("Ver Tabla de Datos Completa"):
                    st.dataframe(df_forecast)
            else:
                st.info(
                    "No se pudo obtener el pron√≥stico para esta ubicaci√≥n. Intente m√°s tarde."
                )

    # --- SUB-PESTA√ëA 2: SAT√âLITE (ESTABILIZADA) ---
    with tab_sat:
        st.subheader("Observaci√≥n Satelital")

        # Controles
        c_sat1, c_sat2 = st.columns([1, 3])
        with c_sat1:
            sat_mode = st.radio(
                "Modo:",
                ["Animaci√≥n (Visible)", "Mapa Interactivo (Lluvia/Nubes)"],
                index=1,
            )
            show_stations_sat = st.checkbox("Mostrar Estaciones", value=True)

        with c_sat2:
            if sat_mode == "Animaci√≥n (Visible)":
                # GIF Oficial NOAA (GeoColor) - Muy estable
                st.image(
                    "https://cdn.star.nesdis.noaa.gov/GOES16/ABI/GIFS/GOES16-ABI-GEOCOLOR-1000x1000.gif",
                    caption="GOES-16 GeoColor (Tiempo Real)",
                    use_column_width=True,
                )
            else:
                # Mapa Interactivo
                try:
                    # Usamos OpenStreetMap por estabilidad, centrado en la zona de inter√©s
                    m = folium.Map(
                        location=[6.2, -75.5], zoom_start=7, tiles="OpenStreetMap"
                    )

                    # Capa de Radar de Lluvia (RainViewer - Cobertura Global y R√°pida)
                    folium.TileLayer(
                        tiles="https://tile.rainviewer.com/nowcast/now/256/{z}/{x}/{y}/2/1_1.png",
                        attr="RainViewer",
                        name="Radar de Lluvia (Tiempo Real)",
                        overlay=True,
                        opacity=0.7,
                    ).add_to(m)

                    # Capa de Nubes (Infrarrojo) - Opcional, si RainViewer falla
                    folium.TileLayer(
                        tiles="https://mesonet.agron.iastate.edu/cache/tile.py/1.0.0/goes-east-ir-4km-900913/{z}/{x}/{y}.png",
                        attr="IEM/NOAA",
                        name="Nubes Infrarrojo",
                        overlay=True,
                        opacity=0.5,
                        show=False,  # Oculta por defecto para no saturar
                    ).add_to(m)

                    # Mostrar Estaciones (Lo que pediste recuperar)
                    if (
                        show_stations_sat
                        and gdf_filtered is not None
                        and not gdf_filtered.empty
                    ):
                        for _, row in gdf_filtered.dropna(
                            subset=["latitude", "longitude"]
                        ).iterrows():
                            folium.CircleMarker(
                                location=[row["latitude"], row["longitude"]],
                                radius=3,
                                color="red",
                                fill=True,
                                fill_opacity=1,
                                tooltip=row[Config.STATION_NAME_COL],
                            ).add_to(m)

                    # --- GEOLOCALIZADOR NATIVO DE FOLIUM ---
                    LocateControl(auto_start=False).add_to(
                        m
                    )  # <--- AQU√ç EST√Å EL BOT√ìN DE GPS

                    folium.LayerControl().add_to(m)
                    st_folium(m, height=600, width="100%")
                    st.caption(
                        "üîµ Radar: RainViewer. ‚òÅÔ∏è Nubes: GOES-16. | üìç Usa el bot√≥n de GPS en el mapa para ubicarte."
                    )
                except Exception as e:
                    st.error(f"Error cargando el mapa satelital: {e}")

    # --- SUB-PESTA√ëA 3: ALERTAS ---
    with tab_alert:
        if df_long is not None:
            umb = st.slider("Umbral (mm):", 0, 1000, 300)
            alts = df_long[df_long[Config.PRECIPITATION_COL] > umb]
            st.metric("Eventos Extremos", len(alts))
            if not alts.empty:
                st.dataframe(
                    alts.sort_values(Config.PRECIPITATION_COL, ascending=False).head(
                        100
                    ),
                )


def display_spatial_distribution_tab(
    user_loc, interpolacion, df_long, df_complete, gdf_stations, gdf_filtered,
    gdf_municipios, gdf_subcuencas, gdf_predios, df_enso, stations_for_analysis,
    df_anual_melted, df_monthly_filtered, analysis_mode, selected_regions,
    selected_municipios, selected_months, year_range, start_date, end_date, **kwargs
):
    import streamlit as st
    import folium
    from folium import plugins
    from folium.plugins import MarkerCluster, Fullscreen, LocateControl
    from streamlit_folium import st_folium
    import pandas as pd

    # Inicializar estado
    if "selected_point" not in st.session_state:
        st.session_state.selected_point = None

    st.markdown("### üó∫Ô∏è Distribuci√≥n Espacial y An√°lisis Puntual")
    
    # --- PANEL DE CONFIGURACI√ìN DE ETIQUETAS (SOLUCI√ìN DEFINITIVA) ---
    # Esto permite al usuario corregir manualmente si sale "Antioquia" o "Cuenca"
    with st.expander("‚öôÔ∏è Configuraci√≥n de Etiquetas (Tooltips)", expanded=False):
        c1, c2, c3 = st.columns(3)
        
        # Selector para MUNICIPIOS
        col_muni_show = None
        if gdf_municipios is not None and not gdf_municipios.empty:
            cols_m = gdf_municipios.columns.tolist()
            # Intentamos pre-seleccionar MPIO_CNMBR si existe
            idx_m = next((i for i, c in enumerate(cols_m) if c in ['MPIO_CNMBR', 'nombre_municipio', 'NOMBRE_MPI']), 0)
            col_muni_show = c1.selectbox("üè∑Ô∏è Etiqueta Municipios:", cols_m, index=idx_m, key="sel_tooltip_muni")
        
        # Selector para CUENCAS
        col_cuenca_show = None
        if gdf_subcuencas is not None and not gdf_subcuencas.empty:
            cols_c = gdf_subcuencas.columns.tolist()
            # Intentamos pre-seleccionar N-NSS3, SUBC_LBL o NOMBRE
            idx_c = next((i for i, c in enumerate(cols_c) if c in ['N-NSS3', 'SUBC_LBL', 'nom_cuenca', 'NOMBRE']), 0)
            col_cuenca_show = c2.selectbox("üè∑Ô∏è Etiqueta Cuencas:", cols_c, index=idx_c, key="sel_tooltip_cuenca")

        # Selector para PREDIOS
        col_predio_show = None
        if gdf_predios is not None and not gdf_predios.empty:
            cols_p = gdf_predios.columns.tolist()
            idx_p = next((i for i, c in enumerate(cols_p) if c in ['NOMBRE_PRE', 'nombre_predio']), 0)
            col_predio_show = c3.selectbox("üè∑Ô∏è Etiqueta Predios:", cols_p, index=idx_p, key="sel_tooltip_predio")

    tab_mapa, tab_avail, tab_series = st.tabs(["üìç Mapa Interactivo", "üìä Disponibilidad", "üìÖ Series Anuales"])

    # --- PESTA√ëA 1: MAPA INTERACTIVO ---
    with tab_mapa:
        # 1. Configuraci√≥n de Vista
        c_zoom, c_manual = st.columns([2, 1])
        location_center = [6.5, -75.5] # Default Antioquia
        zoom_level = 8

        with c_zoom:
            escala = st.radio("üîé Zoom R√°pido:", ["Colombia", "Antioquia", "Regi√≥n Actual"], horizontal=True)
            if escala == "Colombia": location_center, zoom_level = [4.57, -74.29], 6
            elif escala == "Antioquia": location_center, zoom_level = [7.0, -75.5], 8
            elif escala == "Regi√≥n Actual" and not gdf_filtered.empty:
                try:
                    # Calcular centroide
                    minx, miny, maxx, maxy = gdf_filtered.total_bounds
                    location_center = [(miny + maxy) / 2, (minx + maxx) / 2]
                    zoom_level = 9
                except: pass
        
        with c_manual:
            with st.expander("üìç Ingresar Coordenadas", expanded=False):
                lat_in = st.number_input("Latitud", value=float(location_center[0]), format="%.5f")
                lon_in = st.number_input("Longitud", value=float(location_center[1]), format="%.5f")
                if st.button("Analizar Coordenadas"):
                    st.session_state.selected_point = {"lat": lat_in, "lng": lon_in}

        # 2. CREACI√ìN DEL MAPA
        m = folium.Map(location=location_center, zoom_start=zoom_level, control_scale=True)

        # Capas y Fondos
        folium.TileLayer('cartodbpositron', name='Mapa Claro (Default)').add_to(m)
        folium.TileLayer('openstreetmap', name='Callejero (OSM)').add_to(m)
        try:
            folium.TileLayer(
                tiles='https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}',
                attr='Esri', name='Sat√©lite (Esri)'
            ).add_to(m)
        except: pass

        # Plugins
        plugins.LocateControl(auto_start=False, position="topleft").add_to(m)
        plugins.Fullscreen(position='topright').add_to(m)
        plugins.Geocoder(position='topright').add_to(m)

        # --- CAPA MUNICIPIOS (Usando Selector Manual) ---
        if gdf_municipios is not None and not gdf_municipios.empty:
            folium.GeoJson(
                gdf_municipios,
                name="Municipios",
                style_function=lambda x: {'fillColor': '#95a5a6', 'color': 'white', 'weight': 0.5, 'fillOpacity': 0.1},
                tooltip=folium.GeoJsonTooltip(
                    fields=[col_muni_show] if col_muni_show else [], 
                    aliases=['Municipio:'],
                    localize=True
                ) if col_muni_show else None
            ).add_to(m)

        # --- CAPA CUENCAS (Usando Selector Manual) ---
        if gdf_subcuencas is not None and not gdf_subcuencas.empty:
            folium.GeoJson(
                gdf_subcuencas,
                name="Subcuencas",
                style_function=lambda x: {
                    'fillColor': '#3498db', 
                    'color': '#2980b9', 
                    'weight': 1.5, 
                    'fillOpacity': 0.1
                },
                highlight_function=lambda x: {'weight': 3, 'color': '#e74c3c', 'fillOpacity': 0.3},
                tooltip=folium.GeoJsonTooltip(
                    fields=[col_cuenca_show] if col_cuenca_show else [],
                    aliases=['Cuenca:'],
                    style="font-size: 14px; font-weight: bold; color: #2980b9;"
                ) if col_cuenca_show else None
            ).add_to(m)

        # --- CAPA PREDIOS (Usando Selector Manual) ---
        if gdf_predios is not None and not gdf_predios.empty:
            try:
                # Determinar si es punto o pol√≠gono
                geom_type = gdf_predios.geometry.iloc[0].geom_type
                
                tooltip_obj = folium.GeoJsonTooltip(
                    fields=[col_predio_show] if col_predio_show else [],
                    aliases=['Predio:'],
                    localize=True
                ) if col_predio_show else None

                if geom_type == 'Point':
                    folium.GeoJson(
                        gdf_predios,
                        name="Predios",
                        marker=folium.CircleMarker(radius=6, fill_color="orange", fill_opacity=0.9, color="white", weight=1),
                        tooltip=tooltip_obj
                    ).add_to(m)
                else: # Polygon / MultiPolygon
                    folium.GeoJson(
                        gdf_predios,
                        name="Predios",
                        style_function=lambda x: {'fillColor': 'orange', 'color': 'darkorange', 'weight': 1, 'fillOpacity': 0.4},
                        tooltip=tooltip_obj
                    ).add_to(m)
            except Exception as e:
                print(f"Error dibujando predios: {e}")

        # --- CAPA ESTACIONES (Cluster) ---
        marker_cluster = MarkerCluster(name="Estaciones (Agrupadas)").add_to(m)

        # 1. PRE-C√ÅLCULO DE ESTAD√çSTICAS
        stats_cache = {}
        if not df_long.empty:
            try:
                # Detectar columna de c√≥digo
                from modules.config import Config # Importar dentro para evitar error circular
                
                col_cod_long = next((c for c in ['Codigo', 'CODIGO', 'id_estacion', 'station_code'] if c in df_long.columns), df_long.columns[0])
                
                # Agrupamos por estaci√≥n (Optimizado)
                grp = df_long.groupby(col_cod_long)[Config.PRECIPITATION_COL]
                medias = grp.mean()
                conteos = grp.count()
                
                for cod_stat, val_media in medias.items():
                    anios = conteos[cod_stat] / 12
                    stats_cache[str(cod_stat)] = {
                        'media': f"{val_media:.1f} mm/mes",
                        'hist': f"{anios:.1f} a√±os"
                    }
            except Exception as e:
                print(f"Nota: Estad√≠sticas b√°sicas no calculadas: {e}")

        # 2. FUNCI√ìN DE B√öSQUEDA FLEXIBLE
        def get_fuzzy_col(row, aliases, default="N/A"):
            row_cols_lower = {c.lower(): c for c in row.index}
            for alias in aliases:
                for col_lower, col_real in row_cols_lower.items():
                    if alias in col_lower:
                        val = row[col_real]
                        return str(val) if pd.notna(val) else default
            return default

        # BUCLE DE ESTACIONES
        if not gdf_filtered.empty:
            # Importar Config localmente si es necesario
            try: from modules.config import Config
            except: pass
            
            for _, row in gdf_filtered.iterrows():
                try:
                    # Datos b√°sicos
                    nom = str(row.get('nom_est', 'Estaci√≥n'))
                    mun = str(row.get('municipio', 'Desconocido'))
                    alt = str(row.get('alt_est', 0))
                    
                    # ID y Subcuenca
                    cod = get_fuzzy_col(row, ['codigo', 'id', 'serial', 'cod'], 'Sin ID')
                    cue = get_fuzzy_col(row, ['subcuenca', 'cuenca', 'szh', 'vertiente', 'micro', 'zona'], 'N/A')
                    
                    # Estad√≠sticas desde cache
                    stat_data = stats_cache.get(cod, {'media': 'N/A', 'hist': 'N/A'})
                    if stat_data['media'] == 'N/A':
                        try: stat_data = stats_cache.get(str(int(float(cod))), {'media': 'N/A', 'hist': 'N/A'})
                        except: pass

                    precip = stat_data['media']
                    anios = stat_data['hist']

                    # HTML Popup
                    html_content = f"""
                    <div style="font-family: Arial, sans-serif; width: 260px; font-size: 12px;">
                        <h4 style="margin: 0; color: #2c3e50; border-bottom: 2px solid #3498db; padding-bottom: 4px;">{nom}</h4>
                        <div style="margin-top: 5px; color: #7f8c8d; font-size: 11px;"><b>ID:</b> {cod}</div>
                        <br>
                        <table style="width: 100%; border-collapse: collapse;">
                            <tr style="border-bottom: 1px solid #eee;"><td><b>üìç Municipio:</b></td><td style="text-align:right;">{mun}</td></tr>
                            <tr style="border-bottom: 1px solid #eee;"><td><b>‚õ∞Ô∏è Altitud:</b></td><td style="text-align:right;">{alt} m</td></tr>
                            <tr style="border-bottom: 1px solid #eee;"><td><b>üíß Subcuenca:</b></td><td style="text-align:right;">{cue}</td></tr>
                            <tr style="border-bottom: 1px solid #eee;"><td><b>üåßÔ∏è P. Media:</b></td><td style="text-align:right;">{precip}</td></tr>
                            <tr><td><b>üìÖ Hist√≥rico:</b></td><td style="text-align:right;">{anios}</td></tr>
                        </table>
                        <div style="margin-top: 10px; text-align: center; background-color: #f0f8ff; padding: 5px; border-radius: 4px;">
                            <i style="color: #2980b9; font-size: 11px;">üëâ Clic para ver gr√°ficas abajo</i>
                        </div>
                    </div>
                    """
                    
                    iframe = folium.IFrame(html_content, width=280, height=240)
                    popup = folium.Popup(iframe, max_width=280)

                    folium.Marker(
                        [row.geometry.y, row.geometry.x],
                        tooltip=f"{nom}",
                        popup=popup,
                        icon=folium.Icon(color="blue", icon="cloud", prefix='fa')
                    ).add_to(marker_cluster)
                
                except Exception:
                    continue
        
        # Control de capas
        folium.LayerControl().add_to(m)

        st.markdown("üëÜ **Haz clic en un marcador para ver detalles o en cualquier punto del mapa para ver el pron√≥stico.**")

        
        # Renderizar mapa
        map_output = st_folium(m, width=None, height=600, returned_objects=["last_clicked"])

        # L√≥gica de Clic
        if map_output and map_output.get("last_clicked"):
            coords = map_output["last_clicked"]
            st.session_state.selected_point = {"lat": coords["lat"], "lng": coords["lng"]}

        # 3. DASHBOARD DE PRON√ìSTICO
        if st.session_state.selected_point:
            lat = float(st.session_state.selected_point["lat"])
            lng = float(st.session_state.selected_point["lng"])
            
            st.markdown("---")
            st.subheader(f"üìç An√°lisis Puntual: {lat:.4f}, {lng:.4f}")
            
            # Verificaci√≥n segura de la funci√≥n externa
            if 'get_weather_forecast_detailed' in globals() or callable(kwargs.get('get_weather_forecast_detailed')):
                func_forecast = kwargs.get('get_weather_forecast_detailed') or globals().get('get_weather_forecast_detailed')
                
                with st.spinner("Conectando con sat√©lites meteorol√≥gicos..."):
                    try:
                        fc = func_forecast(lat, lng)
                    except:
                        fc = None
                    
                    if fc is not None and not fc.empty:
                        # A. M√âTRICAS
                        hoy = fc.iloc[0]
                        m1, m2, m3, m4, m5 = st.columns(5)
                        m1.metric("üå°Ô∏è Temp", f"{(hoy['T. M√°x (¬∞C)']+hoy['T. M√≠n (¬∞C)'])/2:.1f}¬∞C")
                        m2.metric("üåßÔ∏è Lluvia", f"{hoy['Ppt. (mm)']} mm")
                        m3.metric("üíß Humedad", f"{hoy['HR Media (%)']}%")
                        m4.metric("üí® Viento", f"{hoy['Viento M√°x (km/h)']} km/h")
                        m5.metric("‚òÄÔ∏è Radiaci√≥n", f"{hoy['Radiaci√≥n SW (MJ/m¬≤)']} MJ/m¬≤")
                        
                        # B. GR√ÅFICOS
                        with st.expander("üìà Ver Gr√°ficos Detallados (7 D√≠as)", expanded=True):
                            # 1. Temperatura y Lluvia
                            fig = make_subplots(specs=[[{"secondary_y": True}]])
                            fig.add_trace(go.Bar(x=fc['Fecha'], y=fc['Ppt. (mm)'], name="Lluvia", marker_color='blue', opacity=0.5), secondary_y=True)
                            fig.add_trace(go.Scatter(x=fc['Fecha'], y=fc['T. M√°x (¬∞C)'], name="M√°x", line=dict(color='red')), secondary_y=False)
                            fig.add_trace(go.Scatter(x=fc['Fecha'], y=fc['T. M√≠n (¬∞C)'], name="M√≠n", line=dict(color='cyan'), fill='tonexty'), secondary_y=False)
                            fig.update_layout(title="Temperatura y Precipitaci√≥n", height=350, hovermode="x unified")
                            st.plotly_chart(fig, use_container_width=True)

                            # 2. Atm√≥sfera y Energ√≠a
                            c_g1, c_g2 = st.columns(2)
                            
                            with c_g1: # Atm√≥sfera
                                fig_atm = make_subplots(specs=[[{"secondary_y": True}]])
                                fig_atm.add_trace(go.Scatter(x=fc["Fecha"], y=fc["HR Media (%)"], name="Humedad %", line=dict(color="teal")), secondary_y=False)
                                fig_atm.add_trace(go.Scatter(x=fc["Fecha"], y=fc["Presi√≥n (hPa)"], name="Presi√≥n", line=dict(color="purple", dash="dot")), secondary_y=True)
                                fig_atm.update_layout(title="Atm√≥sfera", height=300, hovermode="x unified")
                                st.plotly_chart(fig_atm, use_container_width=True)

                            with c_g2: # Energ√≠a
                                fig_nrg = make_subplots(specs=[[{"secondary_y": True}]])
                                fig_nrg.add_trace(go.Bar(x=fc["Fecha"], y=fc["Radiaci√≥n SW (MJ/m¬≤)"], name="Radiaci√≥n", marker_color="orange"), secondary_y=False)
                                fig_nrg.add_trace(go.Scatter(x=fc["Fecha"], y=fc["ET‚ÇÄ (mm)"], name="ET‚ÇÄ", line=dict(color="green")), secondary_y=True)
                                fig_nrg.update_layout(title="Energ√≠a", height=300, hovermode="x unified")
                                st.plotly_chart(fig_nrg, use_container_width=True)

                        # C. TABLA
                        with st.expander("üìã Ver Tabla de Datos", expanded=False):
                            st.dataframe(fc)
                    else:
                        st.warning("‚ö†Ô∏è No se pudo obtener el pron√≥stico.")
            else:
                st.info("El m√≥dulo de pron√≥stico no est√° vinculado en este contexto.")

    # ==========================================
    # PESTA√ëA 2: DISPONIBILIDAD
    # ==========================================
    with tab_avail:
        c_title, c_sel = st.columns([2, 1])
        with c_title:
            st.markdown("#### üìä Inventario y Continuidad de Datos")
        with c_sel:
            data_view_mode = st.radio(
                "Vista de Datos:",
                ["Observados (Con huecos)", "Interpolados (Simulaci√≥n)"],
                horizontal=True,
                label_visibility="collapsed",
            )

        if df_long is not None and not df_long.empty:
            df_to_plot = df_long.copy()

            if data_view_mode == "Interpolados (Simulaci√≥n)":
                if interpolacion == "No":
                    with st.spinner("Simulando relleno de datos..."):
                        try:
                            from modules.data_processor import complete_series
                            df_to_plot = complete_series(df_to_plot)
                        except ImportError:
                            st.warning("M√≥dulo de interpolaci√≥n no disponible.")
                else:
                    st.info("Los datos ya est√°n interpolados globalmente.")

            avail = (
                df_to_plot[df_to_plot[Config.PRECIPITATION_COL].notna()]
                .groupby([Config.STATION_NAME_COL, Config.YEAR_COL])[Config.PRECIPITATION_COL]
                .count()
                .reset_index()
            )
            avail.rename(columns={Config.PRECIPITATION_COL: "Meses con Datos"}, inplace=True)

            all_years = list(range(int(avail[Config.YEAR_COL].min()), int(avail[Config.YEAR_COL].max()) + 1))
            all_stations = avail[Config.STATION_NAME_COL].unique()

            full_idx = pd.MultiIndex.from_product([all_stations, all_years], names=[Config.STATION_NAME_COL, Config.YEAR_COL])
            avail_full = avail.set_index([Config.STATION_NAME_COL, Config.YEAR_COL]).reindex(full_idx, fill_value=0).reset_index()

            title_chart = "Continuidad de Informaci√≥n"
            
            # FIX: use_container_width deprecation fix
            fig_avail = px.density_heatmap(
                avail_full,
                x=Config.YEAR_COL,
                y=Config.STATION_NAME_COL,
                z="Meses con Datos",
                nbinsx=len(all_years),
                nbinsy=len(all_stations),
                color_continuous_scale=[(0, "white"), (0.01, "#ffcccc"), (0.5, "#ffaa00"), (1.0, "#006400")],
                range_color=[0, 12],
                title=title_chart,
                height=max(400, len(all_stations) * 20),
            )
            fig_avail.update_layout(xaxis_title="A√±o", yaxis_title="Estaci√≥n", coloraxis_colorbar=dict(title="Meses"), xaxis=dict(dtick=1), yaxis=dict(dtick=1))
            st.plotly_chart(fig_avail, use_container_width=True)

            # M√©tricas
            c1, c2, c3 = st.columns(3)
            total_months = len(all_years) * 12
            actual_months = avail["Meses con Datos"].sum()
            completeness = (actual_months / (len(all_stations) * total_months)) * 100 if len(all_stations) > 0 else 0

            c1.metric("Total Estaciones", len(all_stations))
            c2.metric("Rango de A√±os", f"{min(all_years)} - {max(all_years)}")
            c3.metric("Completitud Global", f"{completeness:.1f}%")

            with st.expander("Ver Tabla de Disponibilidad", expanded=False):
                pivot_avail = avail_full.pivot(index=Config.STATION_NAME_COL, columns=Config.YEAR_COL, values="Meses con Datos")
                st.dataframe(pivot_avail.style.background_gradient(cmap="Greens", vmin=0, vmax=12).format("{:.0f}"))
        else:
            st.warning("No hay datos cargados.")

    # --- PESTA√ëA 3: SERIES ANUALES ---
    with tab_series:
        st.markdown("##### üìà Series Hist√≥ricas")
        if df_anual_melted is not None and not df_anual_melted.empty:
            fig = px.line(
                df_anual_melted, 
                x=Config.YEAR_COL, 
                y=Config.PRECIPITATION_COL, 
                color=Config.STATION_NAME_COL,
                title="Precipitaci√≥n Anual por Estaci√≥n"
            )
            st.plotly_chart(fig, use_container_width=True)
            
            with st.expander("Ver Datos en Tabla"):
                pivot_anual = df_anual_melted.pivot(
                    index=Config.YEAR_COL,
                    columns=Config.STATION_NAME_COL,
                    values=Config.PRECIPITATION_COL
                )
                st.dataframe(pivot_anual)
        else:
            st.warning("No hay datos suficientes para graficar.")


# =============================================================================
# 2. FUNCI√ìN MAESTRA DE GR√ÅFICOS (FUSI√ìN: VIEJO + NUEVO üèóÔ∏è)
# =============================================================================
def display_graphs_tab(
    df_monthly_filtered, 
    df_anual_melted, 
    stations_for_analysis, 
    gdf_stations=None,      
    gdf_subcuencas=None,    
    **kwargs
):
    st.subheader("üìä An√°lisis Gr√°fico Detallado")

    if df_monthly_filtered is None or df_monthly_filtered.empty:
        st.warning("No hay datos para mostrar.")
        return

    # --- 1. DETECCI√ìN COLUMNAS ---
    col_anio = 'A√±o'
    col_valor = 'valor'
    col_estacion = 'id_estacion'

    if df_anual_melted is not None and not df_anual_melted.empty:
        col_anio = find_col(df_anual_melted, ['A√±o', 'year', 'anio']) or 'A√±o'
        col_valor = find_col(df_anual_melted, ['valor', 'value', 'precipitacion']) or 'valor'
        col_estacion = find_col(df_anual_melted, ['id_estacion', 'codigo', 'station', 'nombre']) or 'id_estacion'

    # --- 2. PREPARACI√ìN DATOS ---
    if "Mes" not in df_monthly_filtered.columns:
        df_monthly_filtered["Mes"] = df_monthly_filtered["fecha"].dt.month
    if "A√±o" not in df_monthly_filtered.columns:
        df_monthly_filtered["A√±o"] = df_monthly_filtered["fecha"].dt.year
    
    # CR√çTICO: MES_NUM para ordenar
    df_monthly_filtered['MES_NUM'] = df_monthly_filtered['fecha'].dt.month

    meses_orden = {1: 'Ene', 2: 'Feb', 3: 'Mar', 4: 'Abr', 5: 'May', 6: 'Jun', 
                   7: 'Jul', 8: 'Ago', 9: 'Sep', 10: 'Oct', 11: 'Nov', 12: 'Dic'}
    
    if "Nombre_Mes" not in df_monthly_filtered.columns:
        df_monthly_filtered["Nombre_Mes"] = df_monthly_filtered["Mes"].map(meses_orden)

    # --- ESTRUCTURA DE PESTA√ëAS (RESTAURADA SEG√öN TU RESPALDO) ---
    tab_names = [
        "1. Serie Anual",
        "2. Ranking Multianual",
        "3. Serie Mensual",
        "4. Ciclo Anual (Promedio)",
        "5. Distribuci√≥n de Frecuencias", # RESTAURADO
        "6. An√°lisis Estacional Detallado", # RESTAURADO (Spaghetti+Box)
        "7. Comparativa Multiescalar"
    ]
    tabs = st.tabs(tab_names)

    # --- TAB 1: SERIE ANUAL ---
    with tabs[0]:
        st.markdown("##### Precipitaci√≥n Total Anual")
        if df_anual_melted is not None:
            fig_anual = px.line(
                df_anual_melted, x=col_anio, y=col_valor, color=col_estacion, markers=True,
                labels={col_valor: "Lluvia (mm)", col_anio: "A√±o"}
            )
            st.plotly_chart(fig_anual, use_container_width=True)
            st.session_state["report_fig_anual"] = fig_anual
            st.download_button("üì• CSV Anual", df_anual_melted.to_csv(index=False).encode("utf-8"), "anual.csv")

    # --- TAB 2: RANKING MULTIANUAL (RESTAURADO: ORDENAMIENTO) ---
    with tabs[1]:
        st.markdown("##### Ranking de Precipitaci√≥n Media")
        if df_anual_melted is not None:
            avg_ppt = df_anual_melted.groupby(col_estacion)[col_valor].mean().reset_index()
            lbl_val = "Precipitaci√≥n Media (mm)"
            avg_ppt.rename(columns={col_valor: lbl_val}, inplace=True)

            c_sort, _ = st.columns([1, 2])
            with c_sort:
                sort_opt = st.radio("Ordenar:", ["Mayor a Menor", "Menor a Mayor", "Alfab√©tico"], horizontal=True)

            if sort_opt == "Mayor a Menor": avg_ppt = avg_ppt.sort_values(lbl_val, ascending=False)
            elif sort_opt == "Menor a Mayor": avg_ppt = avg_ppt.sort_values(lbl_val, ascending=True)
            else: avg_ppt = avg_ppt.sort_values(col_estacion)

            fig_rank = px.bar(avg_ppt, x=col_estacion, y=lbl_val, color=lbl_val, color_continuous_scale='Blues', text_auto=".0f")
            st.plotly_chart(fig_rank, use_container_width=True)
            st.session_state["report_fig_ranking"] = fig_rank

    # --- TAB 3: SERIE MENSUAL (RESTAURADO: CHECKBOXES) ---
    with tabs[2]:
        st.markdown("##### Serie Hist√≥rica Mensual")
        col_opts, col_chart = st.columns([1, 4])
        with col_opts:
            show_regional = st.checkbox("Ver Promedio Regional", value=False)
            show_markers = st.checkbox("Mostrar Puntos", value=False)

        with col_chart:
            fig_mensual = px.line(
                df_monthly_filtered, x='fecha', y='valor', color='id_estacion',
                markers=show_markers, title="Precipitaci√≥n Mensual"
            )
            if show_regional:
                reg_mean = df_monthly_filtered.groupby('fecha')['valor'].mean().reset_index()
                fig_mensual.add_trace(go.Scatter(
                    x=reg_mean['fecha'], y=reg_mean['valor'], mode="lines",
                    name="PROMEDIO REGIONAL", line=dict(color="black", width=3, dash="dash")
                ))
            st.plotly_chart(fig_mensual, use_container_width=True)

    # --- TAB 4: CICLO ANUAL (RESTAURADO: COMPARACI√ìN A√ëO) ---
    with tabs[3]:
        st.markdown("##### R√©gimen de Lluvias (Ciclo Promedio)")
        # 1. Calcular promedio
        ciclo = df_monthly_filtered.groupby(['Mes', 'Nombre_Mes', 'id_estacion'])['valor'].mean().reset_index().sort_values('Mes')
        
        # 2. Selector A√±o (Mejorado)
        years_avail = sorted(df_monthly_filtered['A√±o'].unique(), reverse=True)
        year_comp = st.selectbox("Comparar con A√±o espec√≠fico:", [None] + years_avail, key="ciclo_year_comp")

        fig_ciclo = px.line(
            ciclo, x='Nombre_Mes', y='valor', color='id_estacion', markers=True,
            title="Ciclo Anual Promedio"
        )
        
        # 3. Traza de comparaci√≥n
        if year_comp:
            df_year = df_monthly_filtered[df_monthly_filtered['A√±o'] == year_comp].sort_values('Mes')
            for est in df_year['id_estacion'].unique():
                df_y_st = df_year[df_year['id_estacion'] == est]
                fig_ciclo.add_trace(go.Scatter(
                    x=df_y_st['Nombre_Mes'], y=df_y_st['valor'],
                    mode='lines+markers', name=f"{est} ({year_comp})",
                    line=dict(dash='dot', width=2), marker=dict(symbol='x')
                ))

        st.plotly_chart(fig_ciclo, use_container_width=True)
        st.session_state["report_fig_ciclo"] = fig_ciclo

    # --- TAB 5: DISTRIBUCI√ìN (RESTAURADO TOTALMENTE üéª) ---
    with tabs[4]:
        st.markdown("##### An√°lisis Estad√≠stico de Distribuci√≥n")
        c1, c2, c3 = st.columns(3)
        with c1:
            data_src = st.radio("Datos:", ["Anual (Totales)", "Mensual (Detalle)"], horizontal=True)
        with c2:
            chart_typ = st.radio("Gr√°fico:", ["Viol√≠n", "Histograma", "ECDF"], horizontal=True)
        with c3:
            sort_ord = st.selectbox("Orden:", ["Alfab√©tico", "Mayor a Menor"])

        df_plot = df_anual_melted if "Anual" in data_src else df_monthly_filtered
        
        # Ordenar categor√≠as
        cat_orders = {}
        if sort_ord != "Alfab√©tico":
            medians = df_plot.groupby(col_estacion)[col_valor].median()
            order_list = medians.sort_values(ascending=False).index.tolist()
            cat_orders = {col_estacion: order_list}

        if "Viol√≠n" in chart_typ:
            fig_dist = px.violin(df_plot, x=col_estacion, y=col_valor, color=col_estacion, box=True, points="all", category_orders=cat_orders)
        elif "Histograma" in chart_typ:
            fig_dist = px.histogram(df_plot, x=col_valor, color=col_estacion, marginal="box", barmode="overlay", category_orders=cat_orders)
        else:
            fig_dist = px.ecdf(df_plot, x=col_valor, color=col_estacion)

        fig_dist.update_layout(height=600, showlegend=(chart_typ != "Viol√≠n"))
        st.plotly_chart(fig_dist, use_container_width=True)

    # -------------------------------------------------------------------------
    # TAB 5: AN√ÅLISIS ESTACIONAL DETALLADO (CORREGIDO üîß)
    # -------------------------------------------------------------------------
    with tabs[5]:
        st.markdown("#### üìÖ Ciclo Anual Comparativo (Spaghetti Plot)")
        
        # Selector de Estaci√≥n
        sel_st_detail = st.selectbox("Analizar Estaci√≥n:", stations_for_analysis, key="st_detail_seasonal")

        if sel_st_detail:
            # üî• CORRECCI√ìN CLAVE: Usamos 'col_estacion' detectada, no 'id_estacion' fija
            df_st = df_monthly_filtered[df_monthly_filtered[col_estacion] == sel_st_detail].copy()
            
            # Aseguramos orden num√©rico para que el gr√°fico no salga loco
            if 'MES_NUM' not in df_st.columns:
                df_st['MES_NUM'] = df_st['fecha'].dt.month
            df_st = df_st.sort_values('MES_NUM')

            c_hl, c_type = st.columns([1, 1])
            with c_hl:
                # Detectamos columna de a√±o
                c_anio_local = find_col(df_st, ['A√±o', 'year', 'anio']) or 'A√±o'
                years = sorted(df_st[c_anio_local].unique(), reverse=True)
                hl_year = st.selectbox("Resaltar A√±o:", [None] + list(years), key="hl_year_seasonal")
            with c_type:
                chart_mode = st.radio("Visualizaci√≥n:", ["L√≠neas (Spaghetti)", "Cajas (Variabilidad)"], horizontal=True)

            if chart_mode == "L√≠neas (Spaghetti)":
                fig_multi = go.Figure()
                for yr in years:
                    df_y = df_st[df_st[c_anio_local] == yr].sort_values("MES_NUM")
                    
                    color, width, opacity, show_leg = "rgba(200, 200, 200, 0.4)", 1, 0.5, False
                    if hl_year and yr == hl_year:
                        color, width, opacity, show_leg = "red", 4, 1.0, True
                    
                    fig_multi.add_trace(go.Scatter(
                        x=df_y["Nombre_Mes"], y=df_y[col_valor], mode="lines",
                        name=str(yr), line=dict(color=color, width=width), opacity=opacity, showlegend=show_leg
                    ))
                
                # Promedio
                clim = df_st.groupby("MES_NUM")[col_valor].mean().sort_index()
                # Reconstruir nombres de meses ordenados
                meses_mapa = {1: 'Ene', 2: 'Feb', 3: 'Mar', 4: 'Abr', 5: 'May', 6: 'Jun', 7: 'Jul', 8: 'Ago', 9: 'Sep', 10: 'Oct', 11: 'Nov', 12: 'Dic'}
                names_clim = [meses_mapa.get(m, str(m)) for m in clim.index]
                
                fig_multi.add_trace(go.Scatter(
                    x=names_clim, y=clim.values, mode="lines+markers",
                    name="Promedio Hist√≥rico", line=dict(color="black", width=3, dash="dot")
                ))
                fig_multi.update_xaxes(categoryorder='array', categoryarray=list(meses_mapa.values()), title="Mes")
                st.plotly_chart(fig_multi, use_container_width=True)
            
            else: # Cajas
                fig_box = px.box(
                    df_st, x="Nombre_Mes", y=col_valor, color="Nombre_Mes", points="all",
                    category_orders={"Nombre_Mes": ["Ene", "Feb", "Mar", "Abr", "May", "Jun", "Jul", "Ago", "Sep", "Oct", "Nov", "Dic"]}
                )
                fig_box.update_layout(showlegend=False)
                st.plotly_chart(fig_box, use_container_width=True)

            # Tabla comparativa
            if hl_year:
                st.markdown(f"###### üîé Detalle: A√±o {hl_year} vs Promedio Hist√≥rico")
                
                # 1. Definir los datos del A√±o Seleccionado
                # Forzamos una copia para no alterar el original
                df_year_select = df_st[df_st[c_anio_local] == hl_year].copy()
                
                if df_year_select.empty:
                    st.warning(f"No hay datos registrados para el a√±o {hl_year}.")
                else:
                    # 2. Estandarizaci√≥n de √çndice (La Clave Estructural üîë)
                    # Convertimos MES_NUM a entero expl√≠cito en ambos lados para garantizar el cruce
                    df_year_select['MES_NUM'] = df_year_select['MES_NUM'].astype(int)
                    serie_anio = df_year_select.set_index("MES_NUM")[col_valor]
                    
                    # Calculamos el promedio y tambi√©n aseguramos su √≠ndice como entero
                    df_promedio = df_st.groupby("MES_NUM")[col_valor].mean()
                    df_promedio.index = df_promedio.index.astype(int)
                    
                    # 3. Fusi√≥n Expl√≠cita (Merge)
                    # Unimos usando el √≠ndice entero. 'inner' solo muestra meses que existen en el a√±o seleccionado.
                    comp_df = pd.DataFrame({
                        "A√±o Seleccionado": serie_anio,
                        "Promedio Hist√≥rico": df_promedio
                    }).dropna() # Eliminamos cualquier desajuste

                    if comp_df.empty:
                         st.info("No se pudieron alinear los meses del a√±o seleccionado con el promedio.")
                    else:
                        # 4. C√°lculos y Formato
                        comp_df["Diferencia (%)"] = (
                            (comp_df["A√±o Seleccionado"] - comp_df["Promedio Hist√≥rico"]) 
                            / comp_df["Promedio Hist√≥rico"]
                        ) * 100

                        # Mapeo de nombres de meses
                        meses_mapa = {1: 'Ene', 2: 'Feb', 3: 'Mar', 4: 'Abr', 5: 'May', 6: 'Jun', 
                                      7: 'Jul', 8: 'Ago', 9: 'Sep', 10: 'Oct', 11: 'Nov', 12: 'Dic'}
                        comp_df.index = comp_df.index.map(meses_mapa)

                        # Mostrar tabla
                        st.dataframe(comp_df.style.format("{:.1f}").background_gradient(subset=["Diferencia (%)"], cmap="RdYlGn"))

    # --- TAB 7: COMPARATIVA MULTIESCALAR ---
    with tabs[6]:
        # Llamada a la funci√≥n externa blindada
        # Pasamos None en el primer argumento para activar el bypass SQL
        # gdf_stations y gdf_subcuencas vienen de los argumentos de la funci√≥n display_graphs_tab
        display_multiscale_tab(None, gdf_stations, gdf_subcuencas)
            
def display_weekly_forecast_tab(stations_for_analysis, gdf_filtered, **kwargs):
    """Muestra el pron√≥stico semanal para una estaci√≥n seleccionada."""
    st.subheader("üå¶Ô∏è Pron√≥stico a 7 D√≠as (Open-Meteo)")

    if not stations_for_analysis:
        st.warning("Seleccione estaciones en el panel lateral primero.")
        return

    selected_station = st.selectbox(
        "Seleccionar Estaci√≥n:", stations_for_analysis, key="wk_cast_sel"
    )

    if selected_station and gdf_filtered is not None:
        station_data = gdf_filtered[
            gdf_filtered[Config.STATION_NAME_COL] == selected_station
        ]
        if not station_data.empty:
            # Obtener lat/lon
            if "latitude" in station_data.columns:
                lat = station_data.iloc[0]["latitude"]
                lon = station_data.iloc[0]["longitude"]
            else:
                lat = station_data.iloc[0].geometry.y
                lon = station_data.iloc[0].geometry.x

            df = get_weather_forecast_simple(lat, lon)
            if not df.empty:
                st.dataframe(df)

                fig = go.Figure()
                fig.add_trace(
                    go.Scatter(
                        x=df["Fecha"],
                        y=df["Temp. M√°x (¬∞C)"],
                        name="M√°x",
                        line=dict(color="red"),
                    )
                )
                fig.add_trace(
                    go.Scatter(
                        x=df["Fecha"],
                        y=df["Temp. M√≠n (¬∞C)"],
                        name="M√≠n",
                        line=dict(color="blue"),
                    )
                )
                st.plotly_chart(fig)
            else:
                st.error("No se pudo obtener el pron√≥stico.")


def display_satellite_imagery_tab(gdf_filtered):
    """
    Muestra im√°genes satelitales en tiempo real.
    Versi√≥n Robusta: Descarga segura de im√°genes y mapas ligeros.
    """
    st.subheader("üõ∞Ô∏è Monitoreo Satelital (Tiempo Real)")

    tab_map, tab_anim = st.tabs(
        ["üó∫Ô∏è Mapa de Nubes (Interactivo)", "‚ñ∂Ô∏è Animaci√≥n (√öltimas Horas)"]
    )

    # --- TAB 1: MAPA INTERACTIVO ---
    with tab_map:
        col_map, col_info = st.columns([3, 1])
        with col_map:
            try:
                # Centrar mapa
                if gdf_filtered is not None and not gdf_filtered.empty:
                    if "latitude" not in gdf_filtered.columns:
                        gdf_filtered["latitude"] = gdf_filtered.geometry.y
                        gdf_filtered["longitude"] = gdf_filtered.geometry.x
                    center_lat = gdf_filtered["latitude"].mean()
                    center_lon = gdf_filtered["longitude"].mean()
                else:
                    center_lat, center_lon = 6.0, -75.0

                m = folium.Map(location=[center_lat, center_lon], zoom_start=6)

                # 1. Base: CartoDB Positron (Carga muy r√°pido y es limpia)
                folium.TileLayer(
                    tiles="CartoDB positron",
                    attr="CartoDB",
                    name="Mapa Base Claro",
                    overlay=False,
                ).add_to(m)

                # 2. Overlay: Nubes (GOES-16 IR) - NASA GIBS
                # Usamos una URL WMS est√°ndar que suele ser muy compatible
                folium.raster_layers.WmsTileLayer(
                    url="https://gibs.earthdata.nasa.gov/wms/epsg4326/best/wms.cgi",
                    name="Nubes (Infrarrojo)",
                    layers="GOES-East_ABI_Band13_Clean_Infrared",
                    fmt="image/png",
                    transparent=True,
                    opacity=0.5,
                    attr="NASA GIBS",
                ).add_to(m)

                # 3. Estaciones
                if gdf_filtered is not None and not gdf_filtered.empty:
                    from folium.plugins import MarkerCluster

                    mc = MarkerCluster(name="Estaciones").add_to(m)
                    for _, row in gdf_filtered.iterrows():
                        folium.CircleMarker(
                            location=[row["latitude"], row["longitude"]],
                            radius=4,
                            color="blue",
                            fill=True,
                            fill_color="cyan",
                            fill_opacity=0.8,
                            popup=row.get(Config.STATION_NAME_COL, "Estaci√≥n"),
                        ).add_to(mc)

                folium.LayerControl().add_to(m)
                st_folium(m, height=500, use_container_width=True)

            except Exception as e:
                st.error(f"Error cargando mapa: {e}")

        with col_info:
            st.info(
                """
            **Capas:**
            1. **Fondo:** CartoDB (Ligero).
            2. **Nubes:** Infrarrojo GOES-16.
            """
            )

    # --- TAB 2: ANIMACI√ìN (GIF NOAA - Descarga Segura) ---
    with tab_anim:
        st.markdown("#### üé¨ Animaci√≥n GeoColor (Sector Norte de Suram√©rica)")

        # URL Oficial NOAA (Northern South America)
        url_gif = "https://cdn.star.nesdis.noaa.gov/GOES16/ABI/SECTOR/nsa/GEOCOLOR/GOES16-NSA-GEOCOLOR-1000x1000.gif"

        with st.spinner("Descargando animaci√≥n de la NOAA..."):
            gif_data = fetch_secure_content(url_gif)

        if gif_data:
            st.image(
                gif_data,
                caption="Animaci√≥n GeoColor (Tiempo Real)",
                width=700,
            )
        else:
            st.error("‚ö†Ô∏è No se pudo descargar la animaci√≥n autom√°ticamente.")
            st.markdown(
                f"[Haga clic aqu√≠ para verla directamente en la NOAA]({url_gif})"
            )


def display_advanced_maps_tab(df_long, gdf_stations, matrices, grid, mask, gdf_zona, gdf_buffer, gdf_predios, gdf_bocatomas=None, gdf_municipios=None):
    """
    Interfaz: Selectores + Mapa.
    """
    # 1. Panel de Control Visual
    opciones = sorted(list(matrices.keys()))
    
    c1, c2, c3 = st.columns([3, 2, 2])
    
    with c1:
        # Selector de Capa (Precipitaci√≥n, Elevaci√≥n, etc.)
        capa_sel = st.selectbox("Capa a Visualizar:", opciones)
    
    with c2:
        # --- AQU√ç EST√Å EL SELECTOR DE ESCALAS DE COLOR QUE PEDISTE ---
        paletas = ["Spectral_r", "viridis", "RdYlBu", "YlGnBu", "terrain", "magma", "jet", "coolwarm", "Greys", "Blues", "Reds"]
        
        # Inteligencia para sugerir la mejor paleta por defecto
        idx_def = 0
        if 'Elevaci√≥n' in capa_sel: idx_def = paletas.index('terrain')
        elif 'Precipitaci√≥n' in capa_sel: idx_def = paletas.index('Spectral_r')
        elif 'Temperatura' in capa_sel: idx_def = paletas.index('RdYlBu')
        elif 'Erosi√≥n' in capa_sel: idx_def = paletas.index('Reds')
        
        cmap_user = st.selectbox("Paleta de Color:", paletas, index=idx_def)
    
    with c3:
        opacidad = st.slider("Opacidad:", 0.0, 1.0, 0.7)
    
    # 2. Generaci√≥n del Mapa
    grid_z = matrices[capa_sel]
    
    m = generar_mapa_interactivo(
        grid_data=grid_z,
        bounds=gdf_buffer.total_bounds,
        gdf_stations=gdf_stations,
        gdf_zona=gdf_zona,
        gdf_buffer=gdf_buffer,
        gdf_predios=gdf_predios,
        gdf_bocatomas=gdf_bocatomas,
        gdf_municipios=gdf_municipios,
        nombre_capa=capa_sel,
        cmap_name=cmap_user, # <--- Pasamos la elecci√≥n del usuario al mapa
        opacidad=opacidad
    )
    
    st_folium(m, use_container_width=True, height=600)



# PESTA√ëA DE PRON√ìSTICO CLIM√ÅTICO (INDICES + GENERADOR)

def display_climate_forecast_tab(df_enso, **kwargs):
    # --- AGREGAR ESTAS IMPORTACIONES AL INICIO DE LA FUNCI√ìN ---
    import plotly.graph_objects as go  # <--- ESTA ES LA QUE FALTA
    from prophet import Prophet
    import pandas as pd
    import streamlit as st

    st.title("üîÆ Pron√≥stico Clim√°tico & Fen√≥menos Globales")
  
    # --- 1. LIMPIEZA DE DATOS (FECHAS Y N√öMEROS) ---
    if df_enso is not None and not df_enso.empty:
        # Copia de seguridad
        df_enso = df_enso.copy()
        
        # A. ARREGLO DE FECHAS (Ya lo ten√≠amos)
        col_fecha_enso = next((c for c in df_enso.columns if 'fecha' in c.lower()), None)
        if col_fecha_enso:
            df_enso[Config.DATE_COL] = df_enso[col_fecha_enso].apply(parse_spanish_date_visualizer)
            df_enso = df_enso.dropna(subset=[Config.DATE_COL])
            df_enso = df_enso.sort_values(Config.DATE_COL)

        # B. ARREGLO DE N√öMEROS (Versi√≥n Definitiva) üî¢
        # Convertimos todo a min√∫sculas para comparar
        cols_indices = [c for c in df_enso.columns if c.lower() in ['oni', 'anomalia_oni', 'soi', 'iod', 'mei']]
        
        for col in cols_indices:
            # Forzamos conversi√≥n: Texto -> Reemplazar Coma -> N√∫mero
            # Si ya es n√∫mero, el .astype(str) lo protege temporalmente para el replace
            try:
                df_enso[col] = pd.to_numeric(
                    df_enso[col].astype(str).str.replace(',', '.', regex=False), 
                    errors='coerce'
                )
            except Exception as e:
                print(f"Error convirtiendo columna {col}: {e}")


    # -------------------------------------------------------------------------
    # 1. CONFIGURACI√ìN DE PESTA√ëAS Y DATOS EXTERNOS
    # -------------------------------------------------------------------------
    tab_hist, tab_iri_plumas, tab_iri_probs, tab_gen = st.tabs([
        "üìú Historia √çndices (ONI/SOI/IOD)",
        "üåç Pron√≥stico Oficial (IRI)",
        "üìä Probabilidad Multimodelo",
        "‚öôÔ∏è Generador Prophet"
    ])
    
    # Cargar datos IRI (Manejo de errores incorporado en fetch_iri_data si existe)
    # Aseg√∫rate de que esta funci√≥n est√© importada o definida
    try:
        json_plumas = fetch_iri_data("enso_plumes.json")
        json_probs = fetch_iri_data("enso_cpc_prob.json")
    except NameError:
        # Fallback si no tienes la funci√≥n definida en este archivo
        json_plumas, json_probs = {}, {}

    # --- CAJA INFORMATIVA (Formato Mejorado) ---
    with st.expander("‚ÑπÔ∏è Gu√≠a T√©cnica: Pron√≥sticos Clim√°ticos e Interpretaci√≥n (IRI/CPC)", expanded=False):
        st.markdown("""
        Este m√≥dulo integra datos del **International Research Institute for Climate and Society (IRI)** y registros hist√≥ricos de la NOAA.
        
        ### 1. ¬øQu√© es el pron√≥stico ENSO?
        Es una predicci√≥n probabil√≠stica sobre las condiciones de El Ni√±o Oscilaci√≥n del Sur (ENSO) basada en la regi√≥n **Ni√±o 3.4** del Pac√≠fico. Combina m√°s de 20 modelos globales:
        * **Din√°micos:** Basados en ecuaciones f√≠sicas de la atm√≥sfera y el oc√©ano (ej. NCEP CFSv2).
        * **Estad√≠sticos:** Basados en patrones hist√≥ricos.

        ### 2. Impacto General en Colombia
        * üî• **El Ni√±o (Fase C√°lida):** Generalmente asociado a disminuci√≥n de lluvias, aumento de temperatura y riesgo de incendios.
        * üíß **La Ni√±a (Fase Fr√≠a):** Generalmente asociada a excesos de lluvia, inundaciones y deslizamientos.

        ### 3. Glosario de T√©rminos
        * **Anomal√≠a:** Diferencia entre el valor actual y el promedio hist√≥rico de largo plazo.
        * **Termoclina:** Capa bajo la superficie del oc√©ano donde la temperatura desciende r√°pidamente; su profundidad es clave para monitorear El Ni√±o.
        * **ONI (Oceanic Ni√±o Index):** Principal indicador para definir eventos de El Ni√±o/La Ni√±a (Media m√≥vil de 3 meses de anomal√≠as en la regi√≥n Ni√±o 3.4).
        * **Convecci√≥n:** Ascenso de aire c√°lido y h√∫medo que forma nubes y lluvias.
        * **Vientos Alisios:** Vientos que soplan de Este a Oeste en el tr√≥pico. Su debilitamiento es una se√±al temprana de El Ni√±o.
        * **Probabilidad:** Certeza estad√≠stica (en %) de que ocurra una fase clim√°tica espec√≠fica en un trimestre dado.
        
        _Fuente de datos primaria: NOAA NCEI & IRI Columbia University._
        """)

    # -------------------------------------------------------------------------
    # PESTA√ëA 1: HISTORIA DE √çNDICES (ONI, SOI, IOD)
    # -------------------------------------------------------------------------
    with tab_hist:
        st.markdown("#### üìâ Evoluci√≥n Hist√≥rica de √çndices Clim√°ticos")
        
        # Validaci√≥n robusta de datos
        if df_enso is not None and not df_enso.empty:
            
            c1, c2 = st.columns([1, 3])
            with c1:
                # Filtrar columnas disponibles para evitar errores si falta alguna
                cols_disponibles = [c for c in [Config.ENSO_ONI_COL, Config.SOI_COL, Config.IOD_COL] if c in df_enso.columns]
                
                if cols_disponibles:
                    idx_sel = st.selectbox("Seleccione √çndice a Visualizar:", cols_disponibles)
                else:
                    st.error("Las columnas de √≠ndices no se encuentran en la base de datos.")
                    idx_sel = None

            if idx_sel:
                # Limpiar datos para el gr√°fico
                d = df_enso.dropna(subset=[idx_sel, Config.DATE_COL]).sort_values(Config.DATE_COL)
                
                if not d.empty:
                    # Gr√°fico Espec√≠fico para ONI (Con colores rojo/azul)
                    if idx_sel == Config.ENSO_ONI_COL:
                        try:
                            # Aseguramos que create_enso_chart exista
                            fig = create_enso_chart(d) 
                            st.plotly_chart(fig, use_container_width=True, key="chart_oni_hist")
                        except Exception as e:
                            st.error(f"Error generando gr√°fico ONI: {e}")
                            st.line_chart(d.set_index(Config.DATE_COL)[idx_sel])
                    
                    # Gr√°fico Gen√©rico para otros √≠ndices (SOI, IOD)
                    else:
                        fig_simple = px.line(
                            d, x=Config.DATE_COL, y=idx_sel, 
                            title=f"Evoluci√≥n Hist√≥rica: {idx_sel}",
                            color_discrete_sequence=["#2c3e50"]
                        )
                        # L√≠nea cero de referencia
                        fig_simple.add_hline(y=0, line_width=1, line_color="red", line_dash="dash", opacity=0.7)
                        fig_simple.update_layout(hovermode="x unified")
                        
                        st.plotly_chart(fig_simple, use_container_width=True, key=f"chart_{idx_sel}_hist")
                else:
                    st.warning(f"La columna '{idx_sel}' existe pero no tiene datos v√°lidos.")
        else:
            # Mensaje amigable cuando no hay datos cargados a√∫n
            st.info("‚ÑπÔ∏è **No hay datos hist√≥ricos cargados.**")
            st.markdown("""
            Para visualizar esta secci√≥n:
            1. Ve al **Panel de Administraci√≥n**.
            2. En la pesta√±a **Carga de Datos**, sube el archivo de √≠ndices clim√°ticos (`indices.csv`).
            3. Aseg√∫rate de incluir columnas como `anomalia_oni`, `soi` o `iod`.
            """)

    # ==========================================
    # PESTA√ëA 2: PRON√ìSTICO OFICIAL (PLUMAS)
    # ==========================================
    with tab_iri_plumas:
        if json_plumas:
            # Mensaje de Fecha
            try:
                last_year = json_plumas["years"][-1]["year"]
                last_month_idx = json_plumas["years"][-1]["months"][-1]["month"]
                meses = [
                    "Ene",
                    "Feb",
                    "Mar",
                    "Abr",
                    "May",
                    "Jun",
                    "Jul",
                    "Ago",
                    "Sep",
                    "Oct",
                    "Nov",
                    "Dic",
                ]
                st.info(
                    f"üìÖ Pron√≥stico de Plumas actualizado a: **{meses[last_month_idx]} {last_year}**"
                )
            except:
                st.info("üìÖ Pron√≥stico Mensual Oficial (Plumas)")

            st.markdown("#### üçù Modelos de Predicci√≥n (Plumas)")
            data_plume = process_iri_plume(json_plumas)

            if data_plume:
                fig_plume = go.Figure()

                # Colecci√≥n de valores para calcular promedio
                all_values = []

                # Variables para controlar la leyenda (que aparezca solo una vez por tipo)
                show_dyn_legend = True
                show_stat_legend = True

                for model in data_plume["models"]:
                    is_dyn = model["type"] == "Dynamical"
                    color = (
                        "rgba(100, 149, 237, 0.6)"
                        if is_dyn
                        else "rgba(255, 165, 0, 0.6)"
                    )  # Azul/Naranja

                    # Nombre gen√©rico para la leyenda
                    legend_group = (
                        "Modelos Din√°micos" if is_dyn else "Modelos Estad√≠sticos"
                    )

                    # Control de visualizaci√≥n en leyenda (solo el primero de cada grupo)
                    show_in_legend = False
                    if is_dyn and show_dyn_legend:
                        show_in_legend = True
                        show_dyn_legend = False
                    elif not is_dyn and show_stat_legend:
                        show_in_legend = True
                        show_stat_legend = False

                    # Guardar valores para promedio
                    vals = model["values"][: len(data_plume["seasons"])]
                    all_values.append(vals)

                    fig_plume.add_trace(
                        go.Scatter(
                            x=data_plume["seasons"],
                            y=model["values"],
                            mode="lines",
                            name=legend_group,  # Nombre agrupado para la leyenda
                            legendgroup=legend_group,  # Agrupar interactividad
                            showlegend=show_in_legend,
                            line=dict(color=color, width=1.5),
                            opacity=0.7,
                            hovertemplate=f"<b>{model['name']}</b><br>%{{y:.2f}} ¬∞C<extra></extra>",  # Nombre real en hover
                        )
                    )

                # --- C√ÅLCULO DE PROMEDIO MULTIMODELO ---
                try:
                    max_len = len(data_plume["seasons"])
                    clean_matrix = []
                    for v in all_values:
                        row = [float(x) if x is not None else np.nan for x in v]
                        if len(row) < max_len:
                            row += [np.nan] * (max_len - len(row))
                        clean_matrix.append(row)

                    avg_vals = np.nanmean(np.array(clean_matrix), axis=0)

                    fig_plume.add_trace(
                        go.Scatter(
                            x=data_plume["seasons"],
                            y=avg_vals,
                            mode="lines+markers",
                            name="PROMEDIO MULTIMODELO",
                            line=dict(color="black", width=4),
                            marker=dict(size=6, color="black"),
                            showlegend=True,
                        )
                    )
                except Exception as e:
                    st.warning(f"Nota: No se pudo calcular el promedio ({e})")

                # Umbrales
                fig_plume.add_hline(
                    y=0.5,
                    line_dash="dash",
                    line_color="red",
                    annotation_text="El Ni√±o (+0.5)",
                )
                fig_plume.add_hline(
                    y=-0.5,
                    line_dash="dash",
                    line_color="blue",
                    annotation_text="La Ni√±a (-0.5)",
                )

                fig_plume.update_layout(
                    title="Anomal√≠a SST Ni√±o 3.4 (Spaghetti Plot)",
                    height=550,
                    xaxis_title="Trimestres M√≥viles",
                    yaxis_title="Anomal√≠a SST (¬∞C)",
                    hovermode="x unified",
                    legend=dict(
                        orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1
                    ),
                )
                st.plotly_chart(
                    fig_plume, use_container_width=True, key="chart_iri_plume"
                )
            else:
                st.warning("Error al procesar la estructura del archivo de plumas.")
        else:
            st.error("‚ö†Ô∏è No se encontr√≥ el archivo `enso_plumes.json` en `data/iri/`.")

    # ==========================================
    # PESTA√ëA 3: PROBABILIDAD MULTIMODELO
    # ==========================================
    with tab_iri_probs:
        if json_probs:
            # Mensaje de Fecha para Probabilidades
            try:
                last_year = json_probs["years"][-1]["year"]
                last_month_idx = json_probs["years"][-1]["months"][-1]["month"]
                meses = [
                    "Ene",
                    "Feb",
                    "Mar",
                    "Abr",
                    "May",
                    "Jun",
                    "Jul",
                    "Ago",
                    "Sep",
                    "Oct",
                    "Nov",
                    "Dic",
                ]
                st.info(
                    f"üìÖ Pron√≥stico de Probabilidades (Consenso CPC/IRI) actualizado a: **{meses[last_month_idx]} {last_year}**"
                )
            except:
                pass

            st.markdown("#### üìä Probabilidad de Eventos (El Ni√±o/La Ni√±a/Neutral)")
            df_probs = process_iri_probabilities(json_probs)

            if df_probs is not None and not df_probs.empty:
                try:
                    # Normalizaci√≥n de columnas
                    df_probs.columns = [str(c).strip() for c in df_probs.columns]

                    # Identificar columna de tiempo
                    col_tiempo = None
                    for nombre in ["Trimestre", "Season", "season", "SEASON"]:
                        if nombre in df_probs.columns:
                            col_tiempo = nombre
                            break

                    if not col_tiempo and len(df_probs.columns) > 0:
                        col_tiempo = df_probs.columns[0]

                    if col_tiempo:
                        if col_tiempo != "Trimestre":
                            df_probs.rename(
                                columns={col_tiempo: "Trimestre"}, inplace=True
                            )

                        # Melt seguro
                        # Buscamos columnas de eventos (ignorando may√∫sculas/min√∫sculas)
                        cols_val = [c for c in df_probs.columns if c != "Trimestre"]

                        df_melt = df_probs.melt(
                            id_vars="Trimestre",
                            value_vars=cols_val,
                            var_name="Evento",
                            value_name="Probabilidad",
                        )

                        # Normalizaci√≥n para colores
                        df_melt["Evento_Norm"] = (
                            df_melt["Evento"]
                            .astype(str)
                            .str.lower()
                            .str.replace(" ", "")
                        )

                        # Mapeo de colores
                        color_map = {
                            "elnino": "#FF4B4B",
                            "el ni√±o": "#FF4B4B",
                            "lanina": "#1C83E1",
                            "la ni√±a": "#1C83E1",
                            "neutral": "#808495",
                        }

                        def get_color(evt_norm):
                            for key, color in color_map.items():
                                if key in evt_norm:
                                    return color
                            return "gray"

                        df_melt["Color"] = df_melt["Evento_Norm"].apply(get_color)

                        fig_probs = px.bar(
                            df_melt,
                            x="Trimestre",
                            y="Probabilidad",
                            color="Evento",
                            color_discrete_map={
                                evt: get_color(evt.lower().replace(" ", ""))
                                for evt in df_melt["Evento"].unique()
                            },
                            text="Probabilidad",
                            barmode="group",
                        )
                        fig_probs.update_traces(
                            texttemplate="%{text:.0f}%", textposition="outside"
                        )
                        fig_probs.update_layout(
                            height=500,
                            yaxis=dict(range=[0, 105]),
                            xaxis_title="Trimestre Pronosticado",
                            legend=dict(
                                orientation="h",
                                yanchor="bottom",
                                y=1.02,
                                xanchor="right",
                                x=1,
                            ),
                        )
                        st.plotly_chart(
                            fig_probs, use_container_width=True, key="chart_iri_probs"
                        )
                    else:
                        st.error("No se pudo identificar la columna de tiempo.")
                except Exception as e:
                    st.error(f"Error generando gr√°fico: {e}")
            else:
                st.warning("DataFrame de probabilidades vac√≠o.")
        else:
            st.error("‚ö†Ô∏è No se encontr√≥ el archivo `enso_cpc_prob.json` en `data/iri/`.")

# ==========================================
    # PESTA√ëA 4: PROPHET (GENERADOR AVANZADO)
    # ==========================================
    with tab_gen:
        st.markdown("#### ü§ñ Generador Prophet (Proyecci√≥n Estad√≠stica Local)")
        
        # 1. Validaci√≥n Inicial de Datos
        if df_enso is None or df_enso.empty:
            st.warning("‚ö†Ô∏è No hay datos hist√≥ricos de √≠ndices clim√°ticos cargados.")
            st.info("Por favor, cargue el archivo de √≠ndices (ONI/SOI) en el Panel de Administraci√≥n para usar esta herramienta.")
        else:
            # 2. Selector de √çndice (Mapeo Inteligente)
            # Buscamos columnas candidatas
            col_oni = next((c for c in df_enso.columns if 'oni' in c.lower() and 'anomalia' in c.lower()), None) or \
                      next((c for c in df_enso.columns if 'oni' in c.lower()), None)
            
            col_soi = next((c for c in df_enso.columns if 'soi' in c.lower()), None)
            col_iod = next((c for c in df_enso.columns if 'iod' in c.lower()), None)
            
            mapa_indices = {
                "ONI (Oceanic Ni√±o Index)": col_oni,
                "SOI (Southern Oscillation)": col_soi,
                "IOD (Indian Ocean Dipole)": col_iod
            }
            
            # Filtramos solo los que existen en la BD
            opciones_validas = {k: v for k, v in mapa_indices.items() if v is not None}
            
            if not opciones_validas:
                st.error("No se encontraron columnas v√°lidas de √≠ndices (ONI, SOI o IOD) en la base de datos.")
            else:
                c_sel, c_mes = st.columns([2, 1])
                with c_sel:
                    selected_label = st.selectbox("√çndice a proyectar:", list(opciones_validas.keys()))
                    target_col = opciones_validas[selected_label]
                with c_mes:
                    months_future = st.slider("Meses a futuro:", 1, 60, 24)

                if st.button("Generar Proyecci√≥n Prophet"):
                    with st.spinner(f"Entrenando modelo para {selected_label}..."):
                        try:
                            # A. Importaci√≥n Diferida (para evitar error si falta la librer√≠a)
                            from prophet import Prophet
                            
                            # B. Preparaci√≥n de Datos
                            df_prophet = df_enso[[Config.DATE_COL, target_col]].copy()
                            df_prophet.columns = ['ds', 'y']
                            
                            # Limpieza robusta
                            df_prophet['y'] = pd.to_numeric(df_prophet['y'], errors='coerce')
                            df_prophet = df_prophet.dropna()
                            
                            # C. Validaci√≥n de Cantidad de Datos (EL ARREGLO CR√çTICO)
                            if len(df_prophet) < 12:
                                st.warning(f"‚ö†Ô∏è Datos insuficientes: Solo se encontraron {len(df_prophet)} meses v√°lidos. Prophet requiere al menos 12 meses de historia.")
                            else:
                                # D. Entrenamiento
                                # Ajustamos changepoint_prior_scale para capturar variabilidad clim√°tica
                                m = Prophet(daily_seasonality=False, weekly_seasonality=False, yearly_seasonality=True, changepoint_prior_scale=0.3)
                                m.fit(df_prophet)

                                # E. Predicci√≥n
                                future = m.make_future_dataframe(periods=months_future, freq='MS')
                                forecast = m.predict(future)

                                # F. Visualizaci√≥n
                                fig = go.Figure()

                                # Historia
                                fig.add_trace(go.Scatter(
                                    x=df_prophet['ds'], y=df_prophet['y'],
                                    mode='lines', name='Historia Real',
                                    line=dict(color='gray', width=1)
                                ))

                                # Proyecci√≥n
                                fig.add_trace(go.Scatter(
                                    x=forecast['ds'], y=forecast['yhat'],
                                    mode='lines', name='Proyecci√≥n',
                                    line=dict(color='#007BFF', width=2)
                                ))

                                # Incertidumbre
                                fig.add_trace(go.Scatter(
                                    x=pd.concat([forecast['ds'], forecast['ds'][::-1]]),
                                    y=pd.concat([forecast['yhat_upper'], forecast['yhat_lower'][::-1]]),
                                    fill='toself', fillcolor='rgba(0,123,255,0.2)',
                                    line=dict(color='rgba(255,255,255,0)'),
                                    hoverinfo="skip", showlegend=False,
                                    name='Incertidumbre'
                                ))

                                fig.update_layout(
                                    title=f"Proyecci√≥n Estad√≠stica: {selected_label}",
                                    xaxis_title="Fecha", yaxis_title="Valor √çndice",
                                    hovermode="x unified",
                                    legend=dict(orientation="h", y=1.1)
                                )

                                st.plotly_chart(fig, use_container_width=True)
                                st.success(f"‚úÖ Proyecci√≥n generada hasta {forecast['ds'].max().strftime('%Y-%m')}")

                        except ImportError:
                            st.error("Librer√≠a 'prophet' no instalada en el servidor.")
                        except Exception as e:
                            st.error(f"Error calculando proyecci√≥n: {e}")
# -----------------------------------------------------------------------------


def display_trends_and_forecast_tab(**kwargs):
    st.subheader("üìâ Tendencias y Pron√≥sticos (Series de Tiempo)")

    # Recuperar datos
    df_monthly = kwargs.get("df_monthly_filtered")
    stations = kwargs.get("stations_for_analysis")
    df_enso = kwargs.get("df_enso")

    if not stations or df_monthly is None or df_monthly.empty:
        st.warning("Seleccione estaciones en el panel lateral.")
        return

    # 1. SELECTOR GLOBAL DE SERIE
    st.markdown("##### Configuraci√≥n de la Serie de Tiempo")
    mode_fc = st.radio(
        "Modo de An√°lisis:",
        ["Estaci√≥n Individual", "Serie Regional (Promedio)"],
        horizontal=True,
        key="fc_mode_selector",
    )

    ts_clean = None
    station_name_title = ""

    try:
        if mode_fc == "Estaci√≥n Individual":
            selected_station = st.selectbox(
                "Seleccionar Estaci√≥n:", stations, key="trend_st"
            )
            if selected_station:
                station_data = (
                    df_monthly[df_monthly[Config.STATION_NAME_COL] == selected_station]
                    .sort_values(Config.DATE_COL)
                    .set_index(Config.DATE_COL)
                )
                full_idx = pd.date_range(
                    start=station_data.index.min(),
                    end=station_data.index.max(),
                    freq="MS",
                )
                ts_clean = (
                    station_data[Config.PRECIPITATION_COL]
                    .reindex(full_idx)
                    .interpolate(method="time")
                    .dropna()
                )
                station_name_title = selected_station
        else:
            station_name_title = "Serie Regional (Promedio)"
            reg_data = df_monthly.groupby(Config.DATE_COL)[
                Config.PRECIPITATION_COL
            ].mean()
            full_idx = pd.date_range(
                start=reg_data.index.min(), end=reg_data.index.max(), freq="MS"
            )
            ts_clean = reg_data.reindex(full_idx).interpolate(method="time").dropna()

        if ts_clean is None or len(ts_clean) < 24:
            st.error(f"Datos insuficientes (<24 meses) para {station_name_title}.")
            return

    except Exception as e:
        st.error(f"Error preparando los datos: {e}")
        return

    # --- PREPARACI√ìN DE REGRESORES EXTERNOS ---
    avail_regs = []
    regressors_df = None

    if df_enso is not None and not df_enso.empty:
        potential_regs = [
            c
            for c in df_enso.columns
            if c in [Config.ENSO_ONI_COL, Config.SOI_COL, Config.IOD_COL]
        ]
        avail_regs = potential_regs
    
    if avail_regs:
        temp_enso = df_enso.copy()
        
        # --- ARREGLO DE FECHAS CR√çTICO ---
        # Si la fecha viene como texto (ej: 'ene-70'), la traducimos antes de convertir
        if temp_enso[Config.DATE_COL].dtype == 'object':
             temp_enso[Config.DATE_COL] = temp_enso[Config.DATE_COL].apply(parse_spanish_date_visualizer)
        
        # Convertir a datetime final (ahora s√≠ funcionar√° porque ya est√° en ingl√©s o formato correcto)
        temp_enso[Config.DATE_COL] = pd.to_datetime(temp_enso[Config.DATE_COL], errors='coerce')
        temp_enso = temp_enso.dropna(subset=[Config.DATE_COL])
        # ---------------------------------

        regressors_df = (
            temp_enso.set_index(Config.DATE_COL)[avail_regs]
            .resample("MS")
            .mean()
            .interpolate()
        )
    # 2. PESTA√ëAS (Mapa de Riesgo MOVIDO a Clima Futuro)
    tabs = st.tabs(
        [
            "üìä Tendencia Mann-Kendall",
            "üîç Descomposici√≥n",
            "üîó Autocorrelaci√≥n",
            "üß† SARIMA",
            "üîÆ Prophet",
            "‚öñÔ∏è Comparaci√≥n Modelos",
        ]
    )

    # --- TAB 1: TENDENCIA MANN-KENDALL (INDEPENDIENTE Y RESTAURADA) ---
    with tabs[0]:
        st.markdown("#### An√°lisis de Tendencia no Param√©trica (Mann-Kendall)")
        st.caption(f"Evaluando serie: **{station_name_title}**")

        try:
            # Mann-Kendall Test Original
            res = mk.original_test(ts_clean)

            # M√©tricas Clave
            c1, c2, c3 = st.columns(3)

            # Interpretaci√≥n visual de la tendencia
            trend_icon = "‚ûñ"
            if res.trend == "increasing":
                trend_icon = "üìà (Aumento)"
            elif res.trend == "decreasing":
                trend_icon = "üìâ (Disminuci√≥n)"

            c1.metric("Direcci√≥n Tendencia", trend_icon)
            c2.metric("Pendiente (Sen)", f"{res.slope:.3f} mm/mes")

            # Interpretaci√≥n de Significancia
            is_significant = res.p < 0.05
            sig_text = (
                "Significativo (Confianza > 95%)"
                if is_significant
                else "No Significativo"
            )
            c3.metric(
                "Significancia Estad√≠stica",
                sig_text,
                delta=f"p-value: {res.p:.4f}",
                delta_color="normal" if is_significant else "off",
            )

            # Gr√°fico Visual
            df_plot = ts_clean.reset_index()
            df_plot.columns = ["Fecha", "Precipitaci√≥n"]

            # L√≠nea de tendencia calculada (y = mx + b)
            # Aproximaci√≥n visual usando √≠ndices num√©ricos para la pendiente
            x_nums = np.arange(len(df_plot))
            y_trend = res.slope * x_nums + res.intercept

            fig = go.Figure()
            fig.add_trace(
                go.Scatter(
                    x=df_plot["Fecha"],
                    y=df_plot["Precipitaci√≥n"],
                    mode="lines",
                    name="Serie Hist√≥rica",
                    line=dict(color="gray", width=1),
                )
            )
            fig.add_trace(
                go.Scatter(
                    x=df_plot["Fecha"],
                    y=y_trend,
                    mode="lines",
                    name="Tendencia de Sen",
                    line=dict(color="red", width=3, dash="dash"),
                )
            )

            fig.update_layout(
                title="Ajuste de Tendencia (Theil-Sen)", hovermode="x unified"
            )
            st.plotly_chart(fig)

            with st.expander("Ver detalles estad√≠sticos completos"):
                st.write(res)

        except Exception as e:
            st.error(f"No se pudo calcular la tendencia: {e}")

    # --- TAB 2: DESCOMPOSICI√ìN ---
    with tabs[1]:
        try:
            decomp = seasonal_decompose(ts_clean, model="additive", period=12)
            fig = go.Figure()
            fig.add_trace(
                go.Scatter(x=ts_clean.index, y=decomp.trend, name="Tendencia (Ciclo)")
            )
            fig.add_trace(
                go.Scatter(x=ts_clean.index, y=decomp.seasonal, name="Estacionalidad")
            )
            fig.add_trace(
                go.Scatter(
                    x=ts_clean.index, y=decomp.resid, name="Residuo", mode="markers"
                )
            )
            fig.update_layout(title="Descomposici√≥n Estacional (Aditiva)", height=500)
            st.plotly_chart(fig)
        except:
            st.warning("Error en descomposici√≥n (datos insuficientes o discontinuos).")

    # --- TAB 3: AUTOCORRELACI√ìN ---
    with tabs[2]:
        try:
            from statsmodels.tsa.stattools import acf, pacf

            nlags = min(24, len(ts_clean) // 2 - 1)
            lag_acf = acf(ts_clean, nlags=nlags)
            lag_pacf = pacf(ts_clean, nlags=nlags)
            c1, c2 = st.columns(2)
            c1.plotly_chart(
                px.bar(x=range(len(lag_acf)), y=lag_acf, title="ACF (Autocorrelaci√≥n)")
            )
            c2.plotly_chart(
                px.bar(x=range(len(lag_pacf)), y=lag_pacf, title="PACF (Parcial)")
            )
        except:
            pass

    # --- TAB 4: SARIMA ---
    with tabs[3]:
        st.markdown("#### Pron√≥stico SARIMA")
        sel_regs = st.multiselect(
            "Usar Regresor Externo (ONI/SOI/IOD):", avail_regs, key="sarima_regs_sel"
        )

        final_reg_df = None
        if sel_regs and regressors_df is not None:
            final_reg_df = (
                regressors_df[sel_regs]
                .reindex(ts_clean.index)
                .fillna(method="ffill")
                .fillna(method="bfill")
            )

        horizon = st.slider("Horizonte (Meses):", 12, 48, 12, key="h_sarima")

        if st.button("Calcular SARIMA"):
            from modules.forecasting import generate_sarima_forecast

            with st.spinner("Calculando SARIMA..."):
                try:
                    ts_in = ts_clean.reset_index()
                    t_size = max(1, min(12, int(len(ts_clean) * 0.2)))
                    _, fc, ci, met, _ = generate_sarima_forecast(
                        ts_in,
                        order=(1, 1, 1),
                        seasonal_order=(1, 1, 1, 12),
                        horizon=horizon,
                        test_size=t_size,
                        regressors=final_reg_df,
                    )
                    st.success(f"Modelo Ajustado. RMSE: {met['RMSE']:.1f}")

                    fig = go.Figure()
                    fig.add_trace(
                        go.Scatter(x=ts_clean.index, y=ts_clean, name="Hist√≥rico")
                    )
                    fig.add_trace(
                        go.Scatter(
                            x=fc.index, y=fc, name="Pron√≥stico", line=dict(color="red")
                        )
                    )
                    if not ci.empty:
                        fig.add_trace(
                            go.Scatter(
                                x=pd.concat(
                                    [pd.Series(ci.index), pd.Series(ci.index)[::-1]]
                                ),
                                y=pd.concat([ci.iloc[:, 0], ci.iloc[:, 1][::-1]]),
                                fill="toself",
                                fillcolor="rgba(255,0,0,0.1)",
                                line=dict(color="rgba(255,255,255,0)"),
                                name="Confianza 95%",
                            )
                        )
                    st.plotly_chart(fig)
                    st.session_state["sarima_res"] = fc
                except Exception as e:
                    st.error(f"Error SARIMA: {e}")

    # --- TAB 5: PROPHET ---
    with tabs[4]:
        st.markdown("#### Pron√≥stico Prophet")
        sel_regs_p = st.multiselect(
            "Usar Regresor Externo (ONI/SOI/IOD):", avail_regs, key="prophet_regs_sel"
        )

        final_reg_p = None
        horizon_p = st.slider("Horizonte (Meses):", 12, 48, 12, key="h_prophet")

        if sel_regs_p and regressors_df is not None:
            try:
                last_date = ts_clean.index.max()
                future_dates = pd.date_range(
                    start=regressors_df.index.min(),
                    periods=len(regressors_df) + horizon_p + 12,
                    freq="MS",
                )
                extended_regs = (
                    regressors_df[sel_regs_p]
                    .reindex(future_dates)
                    .fillna(method="ffill")
                    .fillna(method="bfill")
                )
                final_reg_p = extended_regs.reset_index().rename(
                    columns={"index": "ds", Config.DATE_COL: "ds"}
                )
                if "ds" not in final_reg_p.columns and "date" in final_reg_p.columns:
                    final_reg_p.rename(columns={"date": "ds"}, inplace=True)
                elif "ds" not in final_reg_p.columns:
                    final_reg_p.rename(
                        columns={final_reg_p.columns[0]: "ds"}, inplace=True
                    )
            except Exception as e:
                st.warning(f"No se pudieron preparar regresores: {e}")
                final_reg_p = None

        if st.button("Calcular Prophet"):
            from modules.forecasting import generate_prophet_forecast

            with st.spinner("Calculando Prophet..."):
                try:
                    ts_in = ts_clean.reset_index()
                    ts_in.columns = ["ds", "y"]
                    t_size = max(1, min(12, int(len(ts_clean) * 0.2)))
                    _, fc, met = generate_prophet_forecast(
                        ts_in, horizon_p, test_size=t_size, regressors=final_reg_p
                    )
                    st.success(f"Modelo Ajustado. RMSE: {met['RMSE']:.1f}")

                    fig = go.Figure()
                    fig.add_trace(
                        go.Scatter(x=ts_clean.index, y=ts_clean, name="Hist√≥rico")
                    )
                    fig.add_trace(
                        go.Scatter(
                            x=fc["ds"],
                            y=fc["yhat"],
                            name="Pron√≥stico",
                            line=dict(color="green"),
                        )
                    )
                    fig.add_trace(
                        go.Scatter(
                            x=pd.concat([fc["ds"], fc["ds"][::-1]]),
                            y=pd.concat([fc["yhat_upper"], fc["yhat_lower"][::-1]]),
                            fill="toself",
                            fillcolor="rgba(0,255,0,0.1)",
                            line=dict(color="rgba(255,255,255,0)"),
                            name="Confianza",
                        )
                    )
                    st.plotly_chart(fig)
                    st.session_state["prophet_res"] = fc[["ds", "yhat"]].set_index(
                        "ds"
                    )["yhat"]
                except Exception as e:
                    st.error(f"Error Prophet: {e}")

    # --- TAB 6: COMPARACI√ìN ---
    with tabs[5]:
        s, p = st.session_state.get("sarima_res"), st.session_state.get("prophet_res")
        if s is not None and p is not None:
            fig = go.Figure()
            fig.add_trace(
                go.Scatter(x=s.index, y=s, name="SARIMA", line=dict(color="red"))
            )
            fig.add_trace(
                go.Scatter(x=p.index, y=p, name="Prophet", line=dict(color="green"))
            )
            fig.update_layout(title="Comparativa de Modelos")
            st.plotly_chart(fig)
        else:
            st.info("Ejecute ambos modelos para comparar.")


def display_anomalies_tab(
    df_long, df_monthly_filtered, stations_for_analysis, **kwargs
):
    st.subheader("‚ö†Ô∏è An√°lisis de Anomal√≠as de Precipitaci√≥n")

    df_enso = kwargs.get("df_enso")

    if df_monthly_filtered is None or df_monthly_filtered.empty:
        st.warning("No hay datos de precipitaci√≥n filtrados.")
        return

    # 1. CONFIGURACI√ìN
    st.markdown("#### Configuraci√≥n del An√°lisis")
    col_conf1, col_conf2 = st.columns([1, 2])

    with col_conf1:
        reference_method = st.radio(
            "Calcular anomal√≠a con respecto a:",
            [
                "El promedio de todo el per√≠odo",
                "Una Normal Climatol√≥gica (per√≠odo base fijo)",
            ],
            key="anomaly_ref_method",
        )

    start_base, end_base = None, None

    if reference_method == "Una Normal Climatol√≥gica (per√≠odo base fijo)":
        with col_conf2:
            all_years = sorted(df_long[Config.YEAR_COL].unique())
            if not all_years:
                st.error("No hay datos anuales disponibles.")
                return

            min_y, max_y = all_years[0], all_years[-1]

            def_start = 1991 if 1991 in all_years else min_y
            def_end = 2020 if 2020 in all_years else max_y

            c_start, c_end = st.columns(2)
            start_base = c_start.selectbox(
                "A√±o Inicio Per√≠odo Base:", all_years, index=all_years.index(def_start)
            )
            end_base = c_end.selectbox(
                "A√±o Fin Per√≠odo Base:", all_years, index=all_years.index(def_end)
            )

            if start_base > end_base:
                st.error("El a√±o de inicio debe ser menor al a√±o de fin.")
                return

    # 2. C√ÅLCULO
    with st.spinner("Calculando anomal√≠as..."):
        # A. Definir datos de referencia
        if reference_method == "Una Normal Climatol√≥gica (per√≠odo base fijo)":
            mask_base = (df_long[Config.YEAR_COL] >= start_base) & (
                df_long[Config.YEAR_COL] <= end_base
            )
            df_reference = df_long[mask_base]
            ref_text = f"Normal {start_base}-{end_base}"
        else:
            df_reference = df_long
            ref_text = "Promedio Hist√≥rico Total"

        # B. Serie regional mensual (promedio de estaciones seleccionadas)
        df_regional = (
            df_monthly_filtered.groupby(Config.DATE_COL)[Config.PRECIPITATION_COL]
            .mean()
            .reset_index()
        )
        df_regional[Config.MONTH_COL] = df_regional[Config.DATE_COL].dt.month

        # C. Climatolog√≠a regional
        stations_list = df_monthly_filtered[Config.STATION_NAME_COL].unique()
        df_ref_stations = df_reference[
            df_reference[Config.STATION_NAME_COL].isin(stations_list)
        ]
        climatology = (
            df_ref_stations.groupby(Config.MONTH_COL)[Config.PRECIPITATION_COL]
            .mean()
            .reset_index()
        )
        climatology.rename(
            columns={Config.PRECIPITATION_COL: "clim_mean"}, inplace=True
        )

        # D. Unir y Restar
        df_anom = pd.merge(df_regional, climatology, on=Config.MONTH_COL, how="left")
        df_anom["anomalia"] = df_anom[Config.PRECIPITATION_COL] - df_anom["clim_mean"]

        df_anom["color"] = np.where(df_anom["anomalia"] >= 0, "blue", "red")

    # 3. VISUALIZACI√ìN
    tab_ts, tab_enso, tab_table = st.tabs(
        ["Gr√°fico de Anomal√≠as", "Anomal√≠as por Fase ENSO", "Tabla de Eventos Extremos"]
    )

    # --- A. SERIE TEMPORAL ---
    with tab_ts:
        st.markdown(f"##### Anomal√≠as Mensuales (Ref: {ref_text})")
        fig = go.Figure()
        fig.add_trace(
            go.Bar(
                x=df_anom[Config.DATE_COL],
                y=df_anom["anomalia"],
                marker_color=df_anom["color"],
                name="Anomal√≠a",
            )
        )
        fig.update_layout(
            yaxis_title="Anomal√≠a (mm)",
            xaxis_title="Fecha",
            height=500,
            showlegend=False,
        )
        fig.add_hline(y=0, line_color="black", line_width=1)
        st.plotly_chart(fig)

        csv = df_anom.to_csv(index=False).encode("utf-8")
        st.download_button(
            "üì• Descargar Anomal√≠as (CSV)", csv, "anomalias.csv", "text/csv"
        )

    # --- B. DISTRIBUCI√ìN POR FASE ENSO ---
    with tab_enso:
        st.subheader("Distribuci√≥n por Fase Clim√°tica")
        if df_enso is None or df_enso.empty:
            st.warning("No hay datos ENSO.")
        else:
            c_idx, _ = st.columns([1, 2])
            idx_name = c_idx.selectbox("√çndice:", ["ONI (El Ni√±o)", "SOI", "IOD"])
            idx_col_map = {
                "ONI (El Ni√±o)": Config.ENSO_ONI_COL,
                "SOI": Config.SOI_COL,
                "IOD": Config.IOD_COL,
            }
            target_idx_col = idx_col_map[idx_name]

            if target_idx_col in df_enso.columns:
                enso_clean = df_enso.copy()
                # Parseo seguro de fechas
                if enso_clean[Config.DATE_COL].dtype == "object":
                    enso_clean[Config.DATE_COL] = enso_clean[Config.DATE_COL].apply(
                        parse_spanish_date
                    )
                else:
                    enso_clean[Config.DATE_COL] = pd.to_datetime(
                        enso_clean[Config.DATE_COL], errors="coerce"
                    )

                df_merged = pd.merge(
                    df_anom,
                    enso_clean[[Config.DATE_COL, target_idx_col]],
                    on=Config.DATE_COL,
                    how="inner",
                )

                if not df_merged.empty:
                    if idx_name == "ONI (El Ni√±o)":
                        conds = [
                            df_merged[target_idx_col] >= 0.5,
                            df_merged[target_idx_col] <= -0.5,
                        ]
                        choices = ["El Ni√±o", "La Ni√±a"]
                        colors = {
                            "El Ni√±o": "#d62728",
                            "La Ni√±a": "#1f77b4",
                            "Neutral": "lightgrey",
                        }
                    elif idx_name == "SOI":
                        conds = [
                            df_merged[target_idx_col] <= -7,
                            df_merged[target_idx_col] >= 7,
                        ]
                        choices = ["El Ni√±o", "La Ni√±a"]
                        colors = {
                            "El Ni√±o": "#d62728",
                            "La Ni√±a": "#1f77b4",
                            "Neutral": "lightgrey",
                        }
                    else:
                        conds = [
                            df_merged[target_idx_col] >= 0.4,
                            df_merged[target_idx_col] <= -0.4,
                        ]
                        choices = ["Positivo", "Negativo"]
                        colors = {
                            "Positivo": "#d62728",
                            "Negativo": "#1f77b4",
                            "Neutral": "lightgrey",
                        }

                    df_merged["Fase"] = np.select(conds, choices, default="Neutral")

                    fig_enso = px.box(
                        df_merged,
                        x="Fase",
                        y="anomalia",
                        color="Fase",
                        color_discrete_map=colors,
                        points="all",
                        title=f"Anomal√≠as seg√∫n Fase {idx_name}",
                        category_orders={"Fase": choices + ["Neutral"]},
                    )
                    fig_enso.update_layout(
                        height=600, showlegend=False, yaxis_title="Anomal√≠a (mm)"
                    )
                    fig_enso.add_hline(
                        y=0, line_width=1, line_color="black", line_dash="dot"
                    )
                    st.plotly_chart(fig_enso, use_container_width=True)
                else:
                    st.warning("No hay datos coincidentes.")
            else:
                st.error(f"Columna {target_idx_col} no encontrada.")

    # --- C. TABLA DE EXTREMOS (CORREGIDA) ---
    with tab_table:
        st.subheader("Eventos Extremos")

        # CORRECCI√ìN: Usar variables de Config en lugar de strings fijos
        cols_to_select = [
            Config.DATE_COL,
            Config.PRECIPITATION_COL,
            "clim_mean",
            "anomalia",
        ]
        cols_rename = ["Fecha", "Ppt Real", "Ppt Normal", "Diferencia"]

        c1, c2 = st.columns(2)
        with c1:
            st.markdown("**üî¥ Top 10 Meses M√°s Secos**")
            driest = df_anom.nsmallest(10, "anomalia")[cols_to_select]
            driest.columns = cols_rename
            driest["Fecha"] = driest["Fecha"].dt.strftime("%Y-%m")
            st.dataframe(
                driest.style.format(
                    "{:.1f}", subset=["Ppt Real", "Ppt Normal", "Diferencia"]
                ),
            )

        with c2:
            st.markdown("**üîµ Top 10 Meses M√°s H√∫medos**")
            wettest = df_anom.nlargest(10, "anomalia")[cols_to_select]
            wettest.columns = cols_rename
            wettest["Fecha"] = wettest["Fecha"].dt.strftime("%Y-%m")
            st.dataframe(
                wettest.style.format(
                    "{:.1f}", subset=["Ppt Real", "Ppt Normal", "Diferencia"]
                ),
            )


# FUNCI√ìN ESTAD√çSTICAS (REVISADA Y MEJORADA)
# ==============================================================================
def display_stats_tab(df_long, df_anual_melted, gdf_stations, **kwargs):
    st.subheader("üìä Estad√≠sticas Hidrol√≥gicas Detalladas")

    # Validaci√≥n de datos
    if df_long is None or df_long.empty:
        st.warning("No hay datos mensuales disponibles para calcular estad√≠sticas.")
        return

    # Definici√≥n de Pesta√±as Internas
    # Agregamos la pesta√±a "S√≠ntesis (R√©cords)" que creamos antes
    tab_desc, tab_matriz, tab_sintesis = st.tabs(
        [
            "üìã Resumen Descriptivo",
            "üìÖ Matriz de Disponibilidad",
            "üèÜ S√≠ntesis de R√©cords",
        ]
    )

    # --- PESTA√ëA 1: RESUMEN DESCRIPTIVO ---
    with tab_desc:
        st.markdown("##### Estad√≠sticas Descriptivas por Estaci√≥n (Mensual)")

        # Agrupar y calcular estad√≠sticas b√°sicas
        stats_df = df_long.groupby(Config.STATION_NAME_COL)[
            Config.PRECIPITATION_COL
        ].describe()

        # A√±adir suma total hist√≥rica (√∫til para ver volumen total registrado)
        sum_total = df_long.groupby(Config.STATION_NAME_COL)[
            Config.PRECIPITATION_COL
        ].sum()
        stats_df["Total Hist√≥rico (mm)"] = sum_total

        # Formatear y mostrar
        st.dataframe(stats_df.style.format("{:.1f}"))

        # Bot√≥n de descarga
        st.download_button(
            "üì• Descargar Estad√≠sticas (CSV)",
            stats_df.to_csv().encode("utf-8"),
            "estadisticas_precipitacion.csv",
            "text/csv",
        )

    # --- PESTA√ëA 2: MATRIZ DE DISPONIBILIDAD ---
    with tab_matriz:
        st.markdown("##### Disponibilidad de Datos (Mapa de Calor)")
        st.info(
            "Muestra la densidad de registros por mes. Color m√°s oscuro = M√°s datos."
        )

        try:
            # --- CORRECCI√ìN MATRIZ ---
            # Copiamos para no afectar el original
            df_matrix = df_long.copy()

            # Forzamos la creaci√≥n de una columna 'date' compatible con Pandas
            # Asumiendo que Config.YEAR_COL y Config.MONTH_COL son tus columnas de a√±o y mes
            df_matrix["date"] = pd.to_datetime(
                dict(
                    year=df_matrix[Config.YEAR_COL],
                    month=df_matrix[Config.MONTH_COL],
                    day=1,
                )
            )

            matrix = df_matrix.pivot_table(
                index=df_matrix["date"].dt.year,
                columns=df_matrix["date"].dt.month,
                values=Config.PRECIPITATION_COL,
                aggfunc="count",
            ).fillna(0)

            # Mapa de calor sem√°foro
            fig_matrix = px.imshow(
                matrix,
                labels=dict(x="Mes", y="A√±o", color="N¬∞ Registros"),
                x=[
                    "Ene",
                    "Feb",
                    "Mar",
                    "Abr",
                    "May",
                    "Jun",
                    "Jul",
                    "Ago",
                    "Sep",
                    "Oct",
                    "Nov",
                    "Dic",
                ],
                title="Matriz de Densidad de Datos (Sem√°foro)",
                color_continuous_scale="RdYlGn",  # Rojo a Verde
                aspect="auto",
            )
            fig_matrix.update_layout(height=600)
            st.plotly_chart(fig_matrix, use_container_width=True)

        except Exception as e:
            st.warning(f"No se pudo generar la matriz: {e}")

    # --- PESTA√ëA 3: S√çNTESIS (NUEVA) ---
    with tab_sintesis:
        # Llamamos a la funci√≥n que creamos en el paso anterior
        # Aseg√∫rate de que esta funci√≥n exista en el mismo archivo o est√© importada
        display_statistics_summary_tab(df_long, df_anual_melted, gdf_stations)


def display_correlation_tab(**kwargs):
    st.subheader("üîó An√°lisis de Correlaci√≥n")

    # Recuperar datos
    df_monthly = kwargs.get("df_monthly_filtered")
    df_enso = kwargs.get("df_enso")

    # Validaciones
    if df_monthly is None or df_monthly.empty:
        st.warning("Faltan datos de precipitaci√≥n para el an√°lisis.")
        return

    # Crear pesta√±as
    tab1, tab2 = st.tabs(["Fen√≥menos Globales (ENSO)", "Matriz entre Estaciones"])

    # -------------------------------------------------------------------------
    # PESTA√ëA 1: RELACI√ìN LLUVIA REGIONAL VS ENSO (ONI)
    # -------------------------------------------------------------------------
    with tab1:
        if df_enso is None or df_enso.empty:
            st.warning("No se han cargado datos del √≠ndice ENSO.")
        else:
            st.markdown(
                "##### Correlaci√≥n: √çndice Oce√°nico El Ni√±o (ONI) vs. Precipitaci√≥n"
            )
            st.info(
                "Analiza c√≥mo la temperatura superficial del mar afecta la lluvia en la zona seleccionada."
            )

            try:
                # 1. Preparar copias de datos para no alterar los originales
                ppt_data = df_monthly.copy()
                enso_data = df_enso.copy()

                # 2. Asegurar formato de fecha en Precipitaci√≥n
                ppt_data[Config.DATE_COL] = pd.to_datetime(
                    ppt_data[Config.DATE_COL], errors="coerce"
                )

                # 3. Asegurar formato de fecha en ENSO (Manejo de 'ene-70', etc.)
                # Usamos la funci√≥n auxiliar parse_spanish_date si existe, o l√≥gica inline
                if enso_data[Config.DATE_COL].dtype == "object":
                    # Intento de conversi√≥n directa primero
                    enso_data[Config.DATE_COL] = pd.to_datetime(
                        enso_data[Config.DATE_COL], errors="coerce"
                    )

                    # Si fall√≥ (quedaron NaTs), intentamos el parseo manual de espa√±ol
                    if enso_data[Config.DATE_COL].isnull().any():

                        def manual_spanish_parse(x):
                            if isinstance(x, str):
                                x = x.lower().strip()
                                trans = {
                                    "ene": "Jan",
                                    "feb": "Feb",
                                    "mar": "Mar",
                                    "abr": "Apr",
                                    "may": "May",
                                    "jun": "Jun",
                                    "jul": "Jul",
                                    "ago": "Aug",
                                    "sep": "Sep",
                                    "oct": "Oct",
                                    "nov": "Nov",
                                    "dic": "Dec",
                                }
                                for es, en in trans.items():
                                    if es in x:
                                        x = x.replace(es, en)
                                        break
                                try:
                                    return pd.to_datetime(x, format="%b-%y")
                                except:
                                    return pd.NaT
                            return x

                        # Recargar columna original para parsear
                        enso_original = df_enso.copy()
                        enso_data[Config.DATE_COL] = enso_original[
                            Config.DATE_COL
                        ].apply(manual_spanish_parse)

                # 4. Limpiar fechas nulas en ambos lados
                ppt_data = ppt_data.dropna(subset=[Config.DATE_COL])
                enso_data = enso_data.dropna(subset=[Config.DATE_COL])

                # 5. Calcular Promedio Regional de Lluvia (una sola serie de tiempo)
                regional_ppt = (
                    ppt_data.groupby(Config.DATE_COL)[Config.PRECIPITATION_COL]
                    .mean()
                    .reset_index()
                )

                # 6. Unir las dos series por fecha
                merged = pd.merge(
                    regional_ppt, enso_data, on=Config.DATE_COL, how="inner"
                )

                if len(merged) > 12:
                    c1, c2 = st.columns([2, 1])

                    # Gr√°fico de Dispersi√≥n
                    with c1:
                        if Config.ENSO_ONI_COL in merged.columns:
                            fig = px.scatter(
                                merged,
                                x=Config.ENSO_ONI_COL,
                                y=Config.PRECIPITATION_COL,
                                trendline="ols",
                                title="Dispersi√≥n: ONI vs Lluvia Regional",
                                labels={
                                    Config.ENSO_ONI_COL: "Anomal√≠a ONI (¬∞C)",
                                    Config.PRECIPITATION_COL: "Lluvia Mensual Promedio (mm)",
                                },
                                opacity=0.6,
                            )
                            st.plotly_chart(fig)
                        else:
                            st.warning(
                                f"No se encontr√≥ la columna '{Config.ENSO_ONI_COL}' en los datos ENSO."
                            )

                    # M√©tricas Estad√≠sticas
                    with c2:
                        if Config.ENSO_ONI_COL in merged.columns:
                            corr = merged[Config.ENSO_ONI_COL].corr(
                                merged[Config.PRECIPITATION_COL]
                            )
                            st.markdown("#### Estad√≠sticas")
                            st.metric("Correlaci√≥n (Pearson)", f"{corr:.2f}")

                            if abs(corr) > 0.5:
                                st.success("Existe una **fuerte** correlaci√≥n.")
                            elif abs(corr) > 0.3:
                                st.info("Existe una correlaci√≥n **moderada**.")
                            else:
                                st.warning("La correlaci√≥n es **d√©bil** o inexistente.")

                            st.caption(f"Basado en {len(merged)} meses coincidentes.")
                else:
                    st.warning(
                        "No hay suficientes datos coincidentes en el tiempo entre la Lluvia y el ENSO para calcular la correlaci√≥n."
                    )

            except Exception as e:
                st.error(f"Error en el c√°lculo de correlaci√≥n ENSO: {e}")

    # -------------------------------------------------------------------------
    # PESTA√ëA 2: MATRIZ DE CORRELACI√ìN ENTRE ESTACIONES
    # -------------------------------------------------------------------------
    with tab2:
        st.markdown("##### Matriz de Correlaci√≥n de Precipitaci√≥n entre Estaciones")
        st.info(
            "Muestra qu√© tan similar es el comportamiento de la lluvia entre las diferentes estaciones seleccionadas. (1.0 = Id√©ntico, 0.0 = Sin relaci√≥n)."
        )

        try:
            # 1. Pivotear datos: Fechas en filas, Estaciones en columnas
            # Esto crea una tabla donde cada columna es una estaci√≥n
            df_pivot = df_monthly.pivot_table(
                index=Config.DATE_COL,
                columns=Config.STATION_NAME_COL,
                values=Config.PRECIPITATION_COL,
            )

            # Validar que haya suficientes datos
            if df_pivot.shape[1] < 2:
                st.warning(
                    "Se necesitan al menos 2 estaciones seleccionadas para calcular una matriz de correlaci√≥n."
                )
            else:
                # 2. Calcular Matriz de Correlaci√≥n (Pearson)
                corr_matrix = df_pivot.corr()

                # 3. Heatmap Interactivo
                fig_corr = px.imshow(
                    corr_matrix,
                    text_auto=".2f",
                    aspect="auto",
                    color_continuous_scale="RdBu",  # Rojo a Azul
                    zmin=-1,
                    zmax=1,
                    title="Mapa de Calor de Correlaciones",
                )
                fig_corr.update_layout(height=700)
                st.plotly_chart(fig_corr, use_container_width=True)

                # 4. Bot√≥n de Descarga (CSV)
                csv_corr = corr_matrix.to_csv().encode("utf-8")
                st.download_button(
                    label="üì• Descargar Matriz de Correlaci√≥n (CSV)",
                    data=csv_corr,
                    file_name="matriz_correlacion_estaciones.csv",
                    mime="text/csv",
                    key="dl_corr_matrix",
                )

        except Exception as e:
            st.error(f"Error generando la matriz de correlaci√≥n: {e}")


def display_enso_tab(**kwargs):
    st.subheader("üåä Fen√≥meno ENSO (El Ni√±o - Oscilaci√≥n del Sur)")

    # Recuperamos el DataFrame hist√≥rico que viene de la base de datos
    df_enso = kwargs.get("df_enso")

    # CREAMOS LAS PESTA√ëAS
    # 1. Pron√≥stico Oficial (Nuevo, datos del IRI)
    # 2. Hist√≥rico ONI (Tu gr√°fico original que funciona bien)
    tab_iri, tab_historico = st.tabs(
        ["üîÆ Pron√≥stico Oficial (IRI/CPC)", "üìú Hist√≥rico ONI"]
    )

    # ---------------------------------------------------------
    # PESTA√ëA 1: PRON√ìSTICO IRI (NUEVO - DATOS LOCALES)
    # ---------------------------------------------------------
    with tab_iri:
        st.info(
            "‚ÑπÔ∏è Datos oficiales del IRI (International Research Institute for Climate and Society) - Columbia University. Actualizaci√≥n Mensual."
        )

        # Cargar datos desde archivos locales
        json_plumas = fetch_iri_data("enso_plumes.json")
        json_probs = fetch_iri_data("enso_iri_prob.json")

        if json_plumas and json_probs:
            col1, col2 = st.columns(2)

            # A. Gr√°fico de Plumas
            with col1:
                st.markdown("#### üçù Modelos de Predicci√≥n (Plumas)")
                data_plume = process_iri_plume(json_plumas)

                if data_plume:
                    fig_plume = go.Figure()
                    seasons = data_plume["seasons"]

                    for model in data_plume["models"]:
                        is_dynamic = model["type"] == "Dynamical"
                        color = (
                            "rgba(100, 149, 237, 0.6)"
                            if is_dynamic
                            else "rgba(255, 165, 0, 0.6)"
                        )
                        name_prefix = "Din√°mico" if is_dynamic else "Estad√≠stico"

                        fig_plume.add_trace(
                            go.Scatter(
                                x=seasons,
                                y=model["values"],
                                mode="lines",
                                name=f"{name_prefix}: {model['name']}",
                                line=dict(color=color, width=1.5),
                                opacity=0.7,
                                showlegend=False,
                                hovertemplate=f"<b>{model['name']}</b><br>%{{y:.2f}} ¬∞C<extra></extra>",
                            )
                        )

                    fig_plume.add_hline(
                        y=0.5,
                        line_dash="dash",
                        line_color="red",
                        annotation_text="El Ni√±o",
                    )
                    fig_plume.add_hline(
                        y=-0.5,
                        line_dash="dash",
                        line_color="blue",
                        annotation_text="La Ni√±a",
                    )
                    fig_plume.add_hline(y=0, line_color="black", opacity=0.3)

                    fig_plume.update_layout(
                        yaxis_title="Anomal√≠a SST (¬∞C)",
                        xaxis_title="Trimestres",
                        height=450,
                        margin=dict(l=40, r=40, t=40, b=40),
                        hovermode="x unified",
                    )
                    st.plotly_chart(fig_plume, use_container_width=True)
                else:
                    st.warning("Error procesando plumas.")

            # B. Gr√°fico de Probabilidades
            with col2:
                st.markdown("#### üìä Probabilidad Multimodelo")
                df_probs = process_iri_probabilities(json_probs)

                if df_probs is not None and not df_probs.empty:
                    df_melt = df_probs.melt(
                        id_vars="Trimestre",
                        var_name="Evento",
                        value_name="Probabilidad",
                    )
                    color_map = {
                        "El Ni√±o": "#FF4B4B",
                        "La Ni√±a": "#1C83E1",
                        "Neutral": "#808495",
                    }

                    fig_probs = px.bar(
                        df_melt,
                        x="Trimestre",
                        y="Probabilidad",
                        color="Evento",
                        color_discrete_map=color_map,
                        text="Probabilidad",
                        barmode="group",
                    )
                    fig_probs.update_traces(
                        texttemplate="%{text:.0f}%", textposition="outside"
                    )
                    fig_probs.update_layout(
                        yaxis_title="Probabilidad (%)",
                        yaxis=dict(range=[0, 105]),
                        height=450,
                        legend=dict(
                            orientation="h",
                            yanchor="bottom",
                            y=1.02,
                            xanchor="right",
                            x=1,
                        ),
                    )
                    st.plotly_chart(fig_probs, use_container_width=True)
                else:
                    st.warning("Error procesando probabilidades.")
        else:
            st.error(
                "‚ö†Ô∏è No se encontraron los archivos JSON en `data/iri/`. Verifica que los hayas subido."
            )

    # ---------------------------------------------------------
    # PESTA√ëA 2: HIST√ìRICO ONI (USANDO TU FUNCI√ìN ORIGINAL)
    # ---------------------------------------------------------
    with tab_historico:
        st.markdown("#### üìâ √çndice Oce√°nico del Ni√±o (ONI) - Hist√≥rico")

        if df_enso is not None and not df_enso.empty:
            # Limpieza b√°sica de fechas para asegurar que el gr√°fico funcione
            data = df_enso.copy()

            # Intento de conversi√≥n de fechas seguro
            if data[Config.DATE_COL].dtype == "object":
                try:
                    # Intentamos usar pd.to_datetime directo primero
                    data[Config.DATE_COL] = pd.to_datetime(
                        data[Config.DATE_COL], errors="coerce"
                    )
                except:
                    pass

            data = data.dropna(subset=[Config.DATE_COL])

            if Config.ENSO_ONI_COL in data.columns:
                # AQU√ç LLAMAMOS A TU FUNCI√ìN PRESERVADA
                fig_oni = create_enso_chart(data)
                st.plotly_chart(fig_oni, use_container_width=True)
            else:
                st.warning(
                    f"No se encontr√≥ la columna '{Config.ENSO_ONI_COL}' en los datos."
                )
        else:
            st.info("No hay datos hist√≥ricos cargados.")


def display_life_zones_tab(df_long, gdf_stations, gdf_subcuencas=None, user_loc=None, **kwargs):
    """
    Visualizador de Zonas de Vida (Adaptado para Nube/Supabase).
    Recibe los archivos raster como objetos BytesIO en **kwargs.
    """
    import streamlit as st
    import numpy as np
    import pandas as pd
    import plotly.graph_objects as go
    from math import cos, radians
    # Aseg√∫rate de importar tu m√≥dulo de l√≥gica
    from modules import life_zones as lz
    from modules.config import Config

    user_loc = kwargs.get("user_loc", user_loc)
    
    # --- 1. EXTRACCI√ìN DE RECURSOS EN MEMORIA ---
    # Ya no usamos rutas de disco, recuperamos los bytes que pasamos desde el main
    dem_file = kwargs.get("dem_file")
    ppt_file = kwargs.get("ppt_file")

    st.subheader("üå± Zonas de Vida (Sistema Holdridge)")

    # --- SECCI√ìN EDUCATIVA (Mantenida intacta) ---
    with st.expander("üìö Conceptos, Metodolog√≠a e Importancia (Sistema Holdridge)"):
        st.markdown(
            """
        <div style="font-size: 13px; line-height: 1.4;">
            <p><strong>Metodolog√≠a:</strong> Clasificaci√≥n ecol√≥gica basada en el cruce de Temperatura (estimada por Altura) y Precipitaci√≥n anual.</p>
            Pisos Altitudinales: (Altuta vs Temperatura)
            1. PISO NIVAL (> 4500 msnm , <-1.5C): 1. Nieves perpetuas y roca desnuda.
            2. PISO ALPINO / SUPERP√ÅRAMO (3800 - 4500 msnm , >-1.5C): Tundra pluvial o h√∫meda. Vegetaci√≥n escasa, transici√≥n a nieve.
            3. PISO SUBALPINO / P√ÅRAMO (3000 - 3800 msnm , 1.5-3C): Ecosistema estrat√©gico. baja temperatura, ET reducida, excedentes de agua.
            4. PISO MONTANO (2000 - 3000 msnm , 3-6C): Bosques de niebla y alto andinos. [13, 14, 15]
            5. PISO MONTANO BAJO (1000 - 2000 msnm , 6-12C): Alta biodiversidad, temperaturas moderadas y precipitaciones significativas.
            5. PISO PREMONTANO (1000 - 2000 msnm , 12-24C): Zona cafetera t√≠pica.
            6. PISO TROPICAL (BASAL) (h < 1000 msnm , T > 24C).

            Provincias de Humedad:
            A. SECO: (ET>ppt), Deficit hidrico, stress hidrico
            B. HUMEDO: (ppt > 1,2 ET), equilibrio o excedente hidrico
            c. MUY HUMEDO: (ppt > 2 ET), exceso hidrico
            C. Pluvial: Exceso extremo de lluvia (Choc√≥).
        </div>
        """,
            unsafe_allow_html=True,
        )

    tab_raster, tab_puntos, tab_vector = st.tabs(
        ["üó∫Ô∏è Mapa Raster", "üìç Puntos (Estaciones)", "üìê Descarga Vectorial"]
    )

    # --- PESTA√ëA 1: MAPA RASTER ---
    with tab_raster:
        col1, col2 = st.columns(2)
        with col1:
            res_option = st.select_slider(
                "Resoluci√≥n:",
                options=["Baja (R√°pido)", "Media", "Alta (Lento)"],
                value="Baja (R√°pido)",
            )
            downscale = (
                8 if "Baja" in res_option else (4 if "Media" in res_option else 1)
            )

        with col2:
            use_mask = st.checkbox("Recortar por Cuenca Seleccionada", value=True)

        basin_geom = None
        if use_mask:
            # L√≥gica de prioridades de m√°scara
            res_basin = st.session_state.get("basin_res")
            if res_basin and res_basin.get("ready"):
                basin_geom = res_basin.get("gdf_cuenca", res_basin.get("gdf_union"))
                st.success(f"‚úÖ M√°scara activa: {res_basin.get('names', 'Cuenca Espec√≠fica')}")
            elif gdf_subcuencas is not None and not gdf_subcuencas.empty:
                basin_geom = gdf_subcuencas
                st.info("‚ÑπÔ∏è Usando todas las subcuencas (Regional).")
            else:
                st.warning("‚ö†Ô∏è No se detect√≥ ninguna geometr√≠a para recortar.")

        if st.button("Generar Mapa de Zonas de Vida"):
            # --- VALIDACI√ìN CR√çTICA (NUBE) ---
            if not dem_file or not ppt_file:
                st.error("‚ùå Error: No se han cargado los mapas base desde Supabase.")
                st.info("Por favor verifica que los archivos .tif est√©n subidos en el Panel de Administraci√≥n.")
            else:
                with st.spinner("Generando mapa clasificado (Procesando en Memoria)..."):
                    try:
                        # Llamamos a la l√≥gica enviando los OBJETOS EN MEMORIA (BytesIO)
                        lz_arr, profile, dynamic_legend, color_map = (
                            lz.generate_life_zone_map(
                                dem_file,   # BytesIO
                                ppt_file,   # BytesIO
                                mask_geometry=basin_geom,
                                downscale_factor=downscale,
                            )
                        )

                        if lz_arr is not None:
                            # Guardar en sesi√≥n
                            st.session_state.lz_raster_result = lz_arr
                            st.session_state.lz_profile = profile
                            st.session_state.lz_names = dynamic_legend
                            st.session_state.lz_colors = color_map

                            # VISUALIZACI√ìN
                            h, w = lz_arr.shape
                            transform = profile["transform"]
                            dx, dy = transform.a, transform.e
                            x0, y0 = transform.c, transform.f

                            xs = np.linspace(x0, x0 + dx * w, w)
                            ys = np.linspace(y0, y0 + dy * h, h)
                            xx, yy = np.meshgrid(xs, ys)

                            lat_flat = yy.flatten()
                            lon_flat = xx.flatten()
                            z_flat = lz_arr.flatten()
                            mask = z_flat > 0

                            if not np.any(mask):
                                st.warning("El mapa se gener√≥ pero est√° vac√≠o (revise la m√°scara).")
                            else:
                                lat_clean = lat_flat[mask]
                                lon_clean = lon_flat[mask]
                                z_clean = z_flat[mask]
                                center_lat = np.mean(lat_clean)
                                center_lon = np.mean(lon_clean)

                                # C√°lculo de √Årea Aprox
                                meters_deg = 111132.0
                                px_area_ha = (
                                    abs(dx * meters_deg * cos(radians(center_lat)))
                                    * abs(dy * meters_deg)
                                ) / 10000.0

                                colors_hex = [color_map.get(v, "#808080") for v in z_clean]
                                hover_text = [f"{dynamic_legend.get(v, 'ID '+str(v))}" for v in z_clean]

                                fig = go.Figure(
                                    go.Scattermapbox(
                                        lat=lat_clean,
                                        lon=lon_clean,
                                        mode="markers",
                                        marker=go.scattermapbox.Marker(
                                            size=8 if downscale > 4 else 5,
                                            color=colors_hex,
                                            opacity=0.75,
                                        ),
                                        text=hover_text,
                                        hovertemplate="%{text}<extra></extra>",
                                    )
                                )

                                if user_loc:
                                    fig.add_trace(go.Scattermapbox(
                                        lat=[user_loc[0]], lon=[user_loc[1]],
                                        mode="markers+text",
                                        marker=go.scattermapbox.Marker(size=15, color="black", symbol="star"),
                                        text=["üìç T√ö EST√ÅS AQU√ç"], textposition="top center"
                                    ))

                                fig.update_layout(
                                    mapbox_style="carto-positron",
                                    mapbox=dict(center=dict(lat=center_lat, lon=center_lon), zoom=9),
                                    height=600,
                                    margin={"r": 0, "t": 0, "l": 0, "b": 0},
                                    showlegend=False,
                                )
                                st.plotly_chart(fig)

                                # Tabla de Resultados
                                unique, counts = np.unique(z_clean, return_counts=True)
                                data = [
                                    {
                                        "Zona": dynamic_legend.get(v, str(v)),
                                        "Ha": c * px_area_ha,
                                        "%": c / counts.sum() * 100,
                                    }
                                    for v, c in zip(unique, counts)
                                ]
                                st.dataframe(
                                    pd.DataFrame(data)
                                    .sort_values("%", ascending=False)
                                    .style.format({"Ha": "{:,.1f}", "%": "{:.1f}%"})
                                )

                                # Descarga TIFF
                                tiff = lz.get_raster_bytes(lz_arr, profile)
                                if tiff:
                                    st.download_button(
                                        "üì• Descargar TIFF", tiff, "zonas_vida.tif", "image/tiff"
                                    )

                    except Exception as e:
                        st.error(f"Error visualizando: {e}")

    # --- PESTA√ëA 2: PUNTOS (ESTACIONES) ---
    with tab_puntos:
        df_anual = kwargs.get("df_anual_melted")
        
        # Validaci√≥n inicial
        if df_anual is None or gdf_stations is None or gdf_stations.empty:
            st.warning("‚ö†Ô∏è Datos insuficientes para el an√°lisis de estaciones.")
        else:
            try:
                # 1. PREPARACI√ìN DE COORDENADAS (PARCHE DE COMPATIBILIDAD)
                # Plotly prefiere 'latitude'/'longitude'. La BD nueva trae 'latitud'/'longitud'.
                # Aseguramos que existan las columnas en ingl√©s para el merge y el mapa.
                gdf_plot = gdf_stations.copy()
                
                # Mapeo Latitud
                if 'latitude' not in gdf_plot.columns:
                    if 'latitud' in gdf_plot.columns: gdf_plot['latitude'] = gdf_plot['latitud']
                    elif 'geometry' in gdf_plot.columns: gdf_plot['latitude'] = gdf_plot.geometry.y
                
                # Mapeo Longitud
                if 'longitude' not in gdf_plot.columns:
                    if 'longitud' in gdf_plot.columns: gdf_plot['longitude'] = gdf_plot['longitud']
                    elif 'geometry' in gdf_plot.columns: gdf_plot['longitude'] = gdf_plot.geometry.x

                # 2. C√ÅLCULO DE PRECIPITACI√ìN MEDIA
                # Agrupamos por estaci√≥n para obtener el promedio hist√≥rico
                ppt_media = (
                    df_anual.groupby(Config.STATION_NAME_COL)[Config.PRECIPITATION_COL]
                    .mean()
                    .reset_index()
                )

                # 3. UNI√ìN DE DATOS (MERGE)
                # Unimos la lluvia media con los metadatos (altura y coordenadas)
                cols_to_merge = [Config.STATION_NAME_COL, Config.ALTITUDE_COL, "latitude", "longitude"]
                # Filtramos solo las columnas que realmente existen para evitar KeyError
                cols_available = [c for c in cols_to_merge if c in gdf_plot.columns]
                
                merged = pd.merge(
                    ppt_media,
                    gdf_plot[cols_available],
                    on=Config.STATION_NAME_COL,
                    how='inner'
                )

                # 4. CLASIFICACI√ìN HOLDRIDGE PUNTUAL
                def get_zone_data(row):
                    # Usamos .get() para evitar errores si falta la columna
                    alt = row.get(Config.ALTITUDE_COL, 0)
                    ppt = row.get(Config.PRECIPITATION_COL, 0)
                    
                    # Clasificar
                    z_id = lz.classify_life_zone_alt_ppt(alt, ppt)
                    
                    return pd.Series([
                        lz.holdridge_int_to_name_simplified.get(z_id, "Desconocido"),
                        lz.holdridge_colors.get(z_id, "#808080")
                    ])

                if not merged.empty:
                    merged[["Zona de Vida", "Color"]] = merged.apply(get_zone_data, axis=1)

                    # 5. MAPA INTERACTIVO
                    fig_map = px.scatter_mapbox(
                        merged,
                        lat="latitude",
                        lon="longitude",
                        color="Zona de Vida",
                        size=Config.PRECIPITATION_COL,
                        hover_name=Config.STATION_NAME_COL,
                        hover_data={Config.ALTITUDE_COL: True, Config.PRECIPITATION_COL: ':.1f'},
                        zoom=8,
                        mapbox_style="carto-positron",
                        title="Clasificaci√≥n Bioclim√°tica por Estaci√≥n",
                        color_discrete_map={v: k for k, v in lz.holdridge_colors.items()} # Intento de mapeo inverso si es necesario, sino Plotly asigna auto
                    )
                    
                    # A√±adir ubicaci√≥n del usuario si existe
                    if user_loc:
                        fig_map.add_trace(go.Scattermapbox(
                            lat=[user_loc[0]],
                            lon=[user_loc[1]],
                            mode="markers+text",
                            marker=go.scattermapbox.Marker(size=12, color="black", symbol="star"),
                            text=["üìç T√ö"],
                            textposition="top center",
                            name="Tu Ubicaci√≥n"
                        ))

                    st.plotly_chart(fig_map, use_container_width=True)

                    # Tabla de Resumen
                    cols_table = [Config.STATION_NAME_COL, "Zona de Vida", Config.PRECIPITATION_COL, Config.ALTITUDE_COL]
                    st.dataframe(merged[[c for c in cols_table if c in merged.columns]])
                
                else:
                    st.warning("No se pudieron cruzar los datos de lluvia con las coordenadas de las estaciones.")

            except Exception as e:
                st.error(f"Error generando an√°lisis de puntos: {e}")

    # --- PESTA√ëA 3: VECTORIAL (TU C√ìDIGO ORIGINAL - FUNCIONAL) ---
    with tab_vector:
        st.info("üõ†Ô∏è Herramienta para convertir el mapa raster generado a pol√≠gonos (GeoJSON) para uso en SIG.")

        # Verificamos si el raster existe en session_state (generado en Pesta√±a 1)
        if "lz_raster_result" not in st.session_state or st.session_state.lz_raster_result is None:
            st.warning("‚ö†Ô∏è Primero debes generar el mapa en la pesta√±a 'Mapa Raster'.")
        else:
            if st.button("Generar Pol√≠gonos (Vectorizar)"):
                with st.spinner("Convirtiendo p√≠xeles a vectores..."):
                    try:
                        gdf_vec = lz.vectorize_raster_to_gdf(
                            st.session_state.lz_raster_result,
                            st.session_state.lz_profile["transform"],
                            st.session_state.lz_profile["crs"],
                        )

                        if not gdf_vec.empty:
                            st.success(f"‚úÖ Vectorizaci√≥n completada: {len(gdf_vec)} pol√≠gonos.")
                            
                            # Mostrar previa
                            st.dataframe(gdf_vec.drop(columns="geometry").head())

                            # Bot√≥n de Descarga
                            geojson_data = gdf_vec.to_json()
                            st.download_button(
                                label="üì• Descargar GeoJSON",
                                data=geojson_data,
                                file_name="zonas_vida_vectorial.geojson",
                                mime="application/json",
                            )
                        else:
                            st.error("El proceso no gener√≥ pol√≠gonos v√°lidos.")
                    except Exception as e:
                        st.error(f"Error en vectorizaci√≥n: {e}")

def display_drought_analysis_tab(df_long, gdf_stations, **kwargs):
    """
    M√≥dulo de Extremos: Incluye An√°lisis Temporal (Series) y Espacial (Vulnerabilidad IVC).
    """
    import plotly.graph_objects as go
    import pandas as pd
    import numpy as np
    from scipy import stats
    from scipy.interpolate import griddata
    from modules.config import Config
    import matplotlib
    import matplotlib.pyplot as plt
    from shapely.geometry import LineString
    import geopandas as gpd
    import tempfile
    import os
    import shutil

    # Configuraci√≥n backend para evitar errores de hilos en servidor
    matplotlib.use('Agg')

    # --- HELPERS INTERNOS PARA DESCARGAS EN ESTE M√ìDULO ---
    def vectorizar_grid(gx, gy, gz, levels=10, crs="EPSG:4326"):
        """Convierte la matriz numpy actual en l√≠neas vectoriales para descarga."""
        try:
            fig, ax = plt.subplots()
            contour = ax.contour(gx, gy, gz, levels=levels)
            plt.close(fig)
            lines, values = [], []
            for collection in contour.collections:
                z_val = 0
                try: z_val = collection.level
                except: pass
                for path in collection.get_paths():
                    if len(path.vertices) >= 2:
                        lines.append(LineString(path.vertices))
                        values.append(z_val)
            if not lines: return None
            return gpd.GeoDataFrame({"valor": values, "geometry": lines}, crs=crs)
        except: return None

    st.subheader("üåä An√°lisis de Extremos y Vulnerabilidad Clim√°tica")
    st.info("Evaluaci√≥n integral: Series temporales de extremos y Mapas de Vulnerabilidad Clim√°tica (IVC).")

    stations_filtered = kwargs.get("stations_for_analysis", [])
    if df_long is None or df_long.empty or not stations_filtered:
        st.warning("No hay datos o estaciones seleccionadas.")
        return

    # Tabs Principales
    tabs = st.tabs([
        "üìâ √çndices (SPI/SPEI)",
        "üìä Frecuencia (Gumbel)",
        "üìè Umbrales",
        "üî• Vulnerabilidad (IVC)",
    ])

    options = ["Serie Regional (Promedio)"] + sorted(stations_filtered)

    # ==============================================================================
    # CONFIGURACI√ìN COM√öN PARA AN√ÅLISIS TEMPORAL (Tabs 0, 1, 2)
    # ==============================================================================
    with st.expander("üìç Configuraci√≥n de Estaci√≥n (Para SPI, Gumbel y Umbrales)", expanded=False):
        selected_station = st.selectbox("Seleccionar Estaci√≥n:", options, key="extremes_station_sel")

    # Preparaci√≥n de datos temporal
    if selected_station == "Serie Regional (Promedio)":
        df_subset = df_long[df_long[Config.STATION_NAME_COL].isin(stations_filtered)]
        df_station = df_subset.groupby(Config.DATE_COL)[Config.PRECIPITATION_COL].mean().reset_index()
        alt = 1500
    else:
        df_station = df_long[df_long[Config.STATION_NAME_COL] == selected_station].copy()
        try:
            alt = gdf_stations[gdf_stations[Config.STATION_NAME_COL] == selected_station].iloc[0][Config.ALTITUDE_COL]
        except: alt = 1500

    df_station = df_station.sort_values(by=Config.DATE_COL).set_index(Config.DATE_COL)
    ts_ppt = df_station[Config.PRECIPITATION_COL].resample("MS").sum()

    # --- TAB 1: SPI / SPEI ---
    with tabs[0]:
        c1, c2 = st.columns(2)
        idx_type = c1.radio("√çndice:", ["SPI (Lluvia)", "SPEI (Balance)"], horizontal=True)
        scale = c2.selectbox("Escala (Meses):", [1, 3, 6, 12, 24], index=2)
        try:
            series_idx = None
            if "SPI" in idx_type:
                from modules.analysis import calculate_spi
                series_idx = calculate_spi(ts_ppt, window=scale)
            else:
                from modules.analysis import calculate_spei
                t_series = pd.Series([28 - (0.006 * float(alt))] * len(ts_ppt), index=ts_ppt.index)
                series_idx = calculate_spei(ts_ppt, t_series, window=scale)

            if series_idx is not None and not series_idx.dropna().empty:
                df_vis = pd.DataFrame({"Val": series_idx})
                df_vis["Color"] = np.where(df_vis["Val"] >= 0, "blue", "red")
                fig = go.Figure()
                fig.add_trace(go.Bar(x=df_vis.index, y=df_vis["Val"], marker_color=df_vis["Color"], name=idx_type))
                fig.add_hline(y=-1.5, line_dash="dash", line_color="red")
                fig.update_layout(title=f"Evoluci√≥n {idx_type}-{scale} ({selected_station})", height=400)
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.warning("Datos insuficientes.")
        except Exception as e: st.error(f"Error: {e}")

    # --- TAB 2: FRECUENCIA (GUMBEL) ---
    with tabs[1]:
        from modules.analysis import calculate_return_periods
        df_g = df_station.reset_index()
        df_g[Config.STATION_NAME_COL] = selected_station
        df_g[Config.YEAR_COL] = df_g[Config.DATE_COL].dt.year
        res_df, debug_data = calculate_return_periods(df_g, selected_station)
        if res_df is not None:
            c1, c2 = st.columns([1, 2])
            with c1: st.dataframe(res_df.style.format({"Ppt M√°xima Esperada (mm)": "{:.1f}"}))
            with c2:
                tr = np.linspace(1.01, 100, 100)
                ppt_plot = stats.gumbel_r.ppf(1 - (1/tr), *debug_data["params"])
                fig = go.Figure()
                fig.add_trace(go.Scatter(x=tr, y=ppt_plot, name="Gumbel", line=dict(color="red")))
                fig.update_layout(xaxis_title="Per√≠odo Retorno", yaxis_title="Ppt M√°x (mm)", xaxis_type="log", height=400)
                st.plotly_chart(fig, use_container_width=True)
        else: st.warning("Datos insuficientes (min 10 a√±os).")

    # --- TAB 3: UMBRALES ---
    with tabs[2]:
        c1, c2 = st.columns(2)
        p_l = c1.slider("Percentil Bajo:", 1, 20, 10)
        p_h = c2.slider("Percentil Alto:", 80, 99, 90)
        df_station["Mes"] = df_station.index.month
        clim = df_station.groupby("Mes")[Config.PRECIPITATION_COL].quantile([p_l/100, 0.5, p_h/100]).unstack()
        clim.columns = ["low", "median", "high"]
        fig = go.Figure()
        months = ["Ene", "Feb", "Mar", "Abr", "May", "Jun", "Jul", "Ago", "Sep", "Oct", "Nov", "Dic"]
        fig.add_trace(go.Scatter(x=months, y=clim["high"], name=f"P{p_h}", line=dict(color="blue")))
        fig.add_trace(go.Scatter(x=months, y=clim["median"], name="Mediana", line=dict(color="green", dash="dot")))
        fig.add_trace(go.Scatter(x=months, y=clim["low"], name=f"P{p_l}", line=dict(color="red")))
        st.plotly_chart(fig, use_container_width=True)

    # ==============================================================================
    # TAB 4: VULNERABILIDAD CLIM√ÅTICA (IVC) - ACTUALIZADO Y PERSISTENTE
    # ==============================================================================
    with tabs[3]:
        # 1. ENCABEZADO Y PRON√ìSTICO ENSO
        st.markdown("#### üó∫Ô∏è √çndice de Vulnerabilidad a la Variabilidad Clim√°tica (IVC)")
        
        # Caja de Pron√≥stico ENSO (Solicitud #5)
        st.warning("""
        üì¢ **Pron√≥stico ENSO (Pr√≥ximos 6 Meses):**
        Seg√∫n el √∫ltimo reporte del IRI/CPC, existe una **Probabilidad del 60% de condiciones de La Ni√±a** hacia el final del a√±o, 
        lo que incrementar√≠a el riesgo de excesos h√≠dricos en la regi√≥n Andina. Se recomienda monitorear los boletines oficiales del IDEAM.
        """)

        # 2. METODOLOG√çA DESPLEGABLE (Solicitud #2 y #4)
        with st.expander("‚ÑπÔ∏è Ver Metodolog√≠a Detallada y Ecuaciones", expanded=False):
            st.markdown("""
            **Premisa:** El desabastecimiento h√≠drico se asocia a zonas c√°lidas y secas. El exceso, a zonas fr√≠as y h√∫medas.
            
            Para construir el √≠ndice adimensional **IVC (0-100)**:
            
            1.  **Parametrizaci√≥n de Temperatura ($IT$):**
                $$ IT = 100 \\times \\left( \\frac{T}{T_{max}} \\right) $$
                *Donde $T$ es la temperatura estimada ($28 - 0.006 \\cdot Altitud$).*
            
            2.  **Parametrizaci√≥n de Escorrent√≠a ($IESD$):**
                Se usa el balance de Turc para hallar la Escorrent√≠a Superficial Directa ($ESD = P - ETR$).
                $$ IESD = 100 \\times \\left( \\frac{ESD_{max} - ESD}{ESD_{max}} \\right) $$
                *Nota: Esta f√≥rmula invierte la escala (Menor agua = Mayor valor de √≠ndice).*
            
            3.  **√çndice Final ($IVC$):**
                $$ IVC = \\frac{IT + IESD}{2} $$
            
            **Interpretaci√≥n:**
            * üî¥ **Rojo (80-100):** Vulnerabilidad Cr√≠tica (Alta T, Baja ESD).
            * üü¢ **Verde (0-40):** Vulnerabilidad Baja (Baja T, Alta ESD).
            """)

        # 3. CONTROLES
        c_ctrl1, c_ctrl2 = st.columns(2)
        year_range_ivc = c_ctrl1.slider("Periodo Clim√°tico:", 1980, 2025, (2000, 2020), key="ivc_slider")
        res_grid = c_ctrl2.select_slider("Resoluci√≥n:", options=["Baja", "Media", "Alta"], value="Media")
        grid_density = 50j if res_grid == "Baja" else 80j if res_grid == "Media" else 100j

        # 4. L√ìGICA DE C√ÅLCULO CON PERSISTENCIA (Solicitud #1 - Arreglo del reinicio)
        if st.button("‚ö° Calcular Mapa de Vulnerabilidad (IVC)"):
            with st.spinner("Realizando √°lgebra de mapas..."):
                # A. Preparar Datos
                mask = (df_long[Config.YEAR_COL] >= year_range_ivc[0]) & (df_long[Config.YEAR_COL] <= year_range_ivc[1])
                df_filtered = df_long[mask]
                df_p = df_filtered.groupby(Config.STATION_NAME_COL)[Config.PRECIPITATION_COL].mean().reset_index()
                df_map = pd.merge(df_p, gdf_stations, on=Config.STATION_NAME_COL).dropna(subset=["latitude", "longitude"])
                if Config.ALTITUDE_COL not in df_map.columns: df_map[Config.ALTITUDE_COL] = 1500

                if len(df_map) < 4:
                    st.error("Se requieren al menos 4 estaciones.")
                else:
                    # B. Interpolaci√≥n y √Ålgebra
                    points = df_map[["longitude", "latitude"]].values
                    minx, miny = df_map.longitude.min(), df_map.latitude.min()
                    maxx, maxy = df_map.longitude.max(), df_map.latitude.max()
                    gx, gy = np.mgrid[minx:maxx:grid_density, miny:maxy:grid_density]

                    grid_p = griddata(points, df_map[Config.PRECIPITATION_COL].values, (gx, gy), method='linear')
                    grid_alt = griddata(points, df_map[Config.ALTITUDE_COL].values, (gx, gy), method='linear')

                    # Variables F√≠sicas
                    grid_t = np.maximum(28 - (0.006 * grid_alt), 0)
                    
                    # Turc
                    l_t = 300 + (25 * grid_t) + (0.05 * grid_t**3)
                    with np.errstate(divide='ignore', invalid='ignore'):
                        grid_etr = grid_p / np.sqrt(0.9 + (grid_p / l_t)**2)
                    grid_etr = np.minimum(grid_etr, grid_p)
                    grid_esd = grid_p - grid_etr

                    # √çndices Normalizados
                    t_max = np.nanmax(grid_t)
                    grid_it = 100 * (grid_t / t_max)
                    
                    esd_max = np.nanmax(grid_esd) if np.nanmax(grid_esd) > 0 else 1
                    grid_iesd = 100 * ((esd_max - grid_esd) / esd_max)
                    
                    grid_ivc = (grid_it + grid_iesd) / 2

                    # GUARDAR EN SESSION STATE (EL SECRETO)
                    st.session_state['ivc_results'] = {
                        'ready': True,
                        'gx': gx, 'gy': gy,
                        'grid_ivc': grid_ivc,
                        'grid_it': grid_it,
                        'grid_iesd': grid_iesd,
                        'grid_esd': grid_esd, # Para ver valor real
                        'grid_p': grid_p,     # Para ver valor real
                        'grid_t': grid_t,     # Para ver valor real
                        'df_pts': df_map
                    }

        # 5. VISUALIZACI√ìN DESDE MEMORIA (Solicitud #1 y #3)
        if st.session_state.get('ivc_results', {}).get('ready'):
            res = st.session_state['ivc_results']
            
            # Selector de Capa
            layer = st.radio("Capa a visualizar:", 
                             ["IVC (Vulnerabilidad Final)", "IT (√çndice Temperatura)", "IESD (√çndice D√©ficit)", "Variables Reales (P, T, Q)"],
                             horizontal=True)
            
            # L√≥gica de visualizaci√≥n
            z_data, title, colors, zmin, zmax = None, "", "", 0, 100
            
            if layer == "IVC (Vulnerabilidad Final)":
                z_data, title, colors = res['grid_ivc'], "√çndice de Vulnerabilidad (IVC)", "RdYlGn_r"
            elif layer == "IT (√çndice Temperatura)":
                z_data, title, colors = res['grid_it'], "√çndice de Temperatura (IT)", "OrRd"
            elif layer == "IESD (√çndice D√©ficit)":
                z_data, title, colors = res['grid_iesd'], "√çndice de D√©ficit de Escorrent√≠a (IESD)", "YlOrRd"
            else:
                # Sub-selector para variables reales
                sub_layer = st.selectbox("Seleccionar Variable F√≠sica:", ["Precipitaci√≥n (mm)", "Temperatura (¬∞C)", "Escorrent√≠a (mm)"])
                if "Precipitaci√≥n" in sub_layer:
                    z_data, title, colors = res['grid_p'], "Precipitaci√≥n Media (mm)", "Blues"
                    zmax = np.nanmax(res['grid_p'])
                elif "Temperatura" in sub_layer:
                    z_data, title, colors = res['grid_t'], "Temperatura Media (¬∞C)", "Thermal"
                    zmax = np.nanmax(res['grid_t'])
                else:
                    z_data, title, colors = res['grid_esd'], "Escorrent√≠a Superficial (mm)", "Teal"
                    zmax = np.nanmax(res['grid_esd'])

            # Estad√≠sticas Min/Max (Solicitud #3)
            st.markdown(f"**Estad√≠sticas de la capa: {title}**")
            c_min, c_max = st.columns(2)
            c_min.metric("M√≠nimo", f"{np.nanmin(z_data):.1f}")
            c_max.metric("M√°ximo", f"{np.nanmax(z_data):.1f}")

            # Mapa
            fig_map = go.Figure(data=go.Contour(
                z=z_data.T, x=res['gx'][:, 0], y=res['gy'][0, :],
                colorscale=colors, colorbar=dict(title="Valor"),
                contours=dict(start=zmin, end=zmax, size=(zmax-zmin)/15 if zmax>zmin else 1),
                zmin=zmin, zmax=zmax
            ))
            fig_map.add_trace(go.Scatter(
                x=res['df_pts'].longitude, y=res['df_pts'].latitude, mode='markers',
                marker=dict(color='black', size=4), name='Estaciones'
            ))
            fig_map.update_layout(title=title, height=550, margin=dict(l=20, r=20, t=40, b=20))
            st.plotly_chart(fig_map, use_container_width=True)

            # Descarga del Mapa (Solicitud #3)
            if st.button(f"‚¨áÔ∏è Preparar Descarga de {layer}"):
                gdf_iso = vectorizar_grid(res['gx'], res['gy'], z_data, levels=15)
                if gdf_iso is not None:
                    json_data = gdf_iso.to_json()
                    st.download_button(
                        label=f"üíæ Descargar GeoJSON ({layer})",
                        data=json_data,
                        file_name=f"mapa_{layer.split()[0].lower()}.geojson",
                        mime="application/json"
                    )
                else:
                    st.warning("No se pudo vectorizar esta capa para descarga.")


# FUNCI√ìN CLIMA FUTURO (MAPA RIESGO MEJORADO + SIMULADOR)
# ==============================================================================
def display_climate_scenarios_tab(**kwargs):
    st.subheader("üå°Ô∏è Clima Futuro y Vulnerabilidad (CMIP6 / Riesgo)")

    # Recuperamos datos
    df_anual = kwargs.get("df_anual_melted")
    gdf_stations = kwargs.get("gdf_stations")

    # Intentamos recuperar la cuenca para recorte y SU NOMBRE
    basin_geom = None
    basin_name = "Regional (Todas las Estaciones)"  # Nombre por defecto

    res_basin = st.session_state.get("basin_res")
    if res_basin and res_basin.get("ready"):
        basin_geom = res_basin.get("gdf_cuenca", res_basin.get("gdf_union"))
        # Intentamos obtener el nombre si existe en el diccionario
        if "names" in res_basin:
            basin_name = f"Cuenca: {res_basin['names']}"
        elif "name" in res_basin:
            basin_name = f"Cuenca: {res_basin['name']}"

    tab_risk, tab_cmip6 = st.tabs(
        [
            "üó∫Ô∏è Mapa de Riesgo (Tendencias Hist√≥ricas)",
            "üåç Simulador de Cambio Clim√°tico (CMIP6)",
        ]
    )

    # --- TAB 1: MAPA DE RIESGO (MEJORADO VISUALMENTE) ---
    with tab_risk:
        st.markdown("#### Vulnerabilidad H√≠drica: Tendencias de Precipitaci√≥n")
        st.caption(f"**Zona de An√°lisis:** {basin_name}")  # Mostramos el nombre aqu√≠

        with st.expander("‚ÑπÔ∏è Acerca de este Mapa de Riesgo", expanded=False):
            st.markdown(
                """
            Este mapa muestra la **tendencia espacial hist√≥rica** de la lluvia interpolando la pendiente de Sen (Mann-Kendall).
            * **Objetivo:** Identificar zonas que se est√°n secando (Vulnerables) o humedeciendo.
            * **Interpretaci√≥n:**
                * **Azul:** Zonas donde la lluvia est√° aumentando.
                * **Rojo:** Zonas donde la lluvia est√° disminuyendo (Riesgo de Sequ√≠a).
            * **Metodolog√≠a:** Se calcula la tendencia para cada estaci√≥n con >10 a√±os de datos y se interpola espacialmente.
            """
            )

        c1, c2 = st.columns(2)
        use_mask = c1.checkbox(
            "Recortar por Cuenca Seleccionada", value=True, key="risk_mask_cb"
        )

        if st.button("Generar Mapa de Vulnerabilidad"):
            with st.spinner("Interpolando tendencias regionales..."):
                trend_data = []
                if df_anual is not None:
                    stations_pool = df_anual[Config.STATION_NAME_COL].unique()
                    for stn in stations_pool:
                        sub = df_anual[df_anual[Config.STATION_NAME_COL] == stn]
                        if len(sub) > 10:
                            try:
                                res = mk.original_test(sub[Config.PRECIPITATION_COL])
                                if gdf_stations is not None:
                                    loc = gdf_stations[
                                        gdf_stations[Config.STATION_NAME_COL] == stn
                                    ]
                                    if not loc.empty:
                                        iloc = loc.iloc[0]
                                        muni = (
                                            iloc[Config.MUNICIPALITY_COL]
                                            if Config.MUNICIPALITY_COL in iloc
                                            else "Desconocido"
                                        )
                                        trend_data.append(
                                            {
                                                "lat": iloc["latitude"],
                                                "lon": iloc["longitude"],
                                                "slope": res.slope,
                                                "trend": res.trend,
                                                "p": res.p,
                                                "name": stn,
                                                "municipio": muni,
                                            }
                                        )
                            except:
                                pass

                if len(trend_data) >= 4:
                    df_trend = pd.DataFrame(trend_data)

                    # Interpolaci√≥n
                    grid_res = 200j
                    grid_x, grid_y = np.mgrid[
                        df_trend.lon.min() - 0.1 : df_trend.lon.max() + 0.1 : grid_res,
                        df_trend.lat.min() - 0.1 : df_trend.lat.max() + 0.1 : grid_res,
                    ]

                    from scipy.interpolate import griddata

                    grid_z = griddata(
                        df_trend[["lon", "lat"]].values,
                        df_trend["slope"].values,
                        (grid_x, grid_y),
                        method="cubic",
                    )

                    # M√°scara Geom√©trica (Recorte)
                    if use_mask and basin_geom is not None:
                        try:
                            from shapely.geometry import Point
                            from shapely.prepared import prep

                            poly = (
                                basin_geom.unary_union
                                if hasattr(basin_geom, "unary_union")
                                else basin_geom
                            )
                            prep_poly = prep(poly)

                            flat_x = grid_x.flatten()
                            flat_y = grid_y.flatten()
                            flat_z = grid_z.flatten()

                            # Optimizaci√≥n: Solo verificar puntos que no son NaN (ahorra tiempo si griddata ya puso NaNs afuera del convex hull)
                            mask_array = np.isnan(flat_z)  # True donde ya es NaN

                            # Verificamos los puntos v√°lidos
                            valid_indices = np.where(~mask_array)[0]
                            for idx in valid_indices:
                                if not prep_poly.contains(
                                    Point(flat_x[idx], flat_y[idx])
                                ):
                                    flat_z[idx] = np.nan

                            grid_z = flat_z.reshape(grid_x.shape)
                        except Exception as e:
                            st.warning(f"No se pudo recortar visualmente: {e}")

                    fig = go.Figure()

                    # Mapa de Calor / Contornos
                    fig.add_trace(
                        go.Contour(
                            z=grid_z.T,
                            x=grid_x[:, 0],
                            y=grid_y[0, :],
                            colorscale="RdBu",
                            colorbar=dict(
                                title="Tendencia (mm/a√±o)",
                                titleside="right",
                                thickness=15,
                                len=0.7,  # Hacemos la barra un poco m√°s corta para que no choque
                            ),
                            zmid=0,
                            opacity=0.8,
                            contours=dict(showlines=False),
                            connectgaps=False,
                        )
                    )

                    # Puntos de Estaciones (MEJORADOS VISUALMENTE)
                    # Usamos color de relleno amarillo p√°lido para resaltar sobre azul/rojo
                    # Borde negro siempre visible
                    # Grosor de borde indica significancia
                    df_trend["line_width"] = df_trend["p"].apply(
                        lambda x: 2 if x < 0.05 else 1
                    )

                    fig.add_trace(
                        go.Scatter(
                            x=df_trend.lon,
                            y=df_trend.lat,
                            mode="markers",
                            text=df_trend.apply(
                                lambda r: f"<b>{r['name']}</b><br>Mun: {r['municipio']}<br>Pendiente: {r['slope']:.2f}<br>Sig: {'S√≠' if r['p']<0.05 else 'No'}",
                                axis=1,
                            ),
                            marker=dict(
                                size=10,
                                color="#FFFFE0",  # LightYellow (Resalta sobre oscuros)
                                line=dict(
                                    width=df_trend["line_width"],
                                    color="black",  # Borde negro para contraste
                                ),
                            ),
                            name="Estaciones",
                        )
                    )

                    # Borde de la Cuenca
                    if basin_geom is not None:
                        try:
                            poly = (
                                basin_geom.unary_union
                                if hasattr(basin_geom, "unary_union")
                                else basin_geom
                            )
                            if poly.geom_type == "Polygon":
                                x, y = poly.exterior.xy
                                fig.add_trace(
                                    go.Scatter(
                                        x=list(x),
                                        y=list(y),
                                        mode="lines",
                                        line=dict(color="black", width=2),
                                        name="L√≠mite Cuenca",
                                    )
                                )
                            elif poly.geom_type == "MultiPolygon":
                                for i, p in enumerate(poly.geoms):
                                    x, y = p.exterior.xy
                                    fig.add_trace(
                                        go.Scatter(
                                            x=list(x),
                                            y=list(y),
                                            mode="lines",
                                            line=dict(color="black", width=2),
                                            showlegend=(i == 0),
                                            name="L√≠mite Cuenca",
                                        )
                                    )
                        except:
                            pass

                    # Configuraci√≥n de Layout (LEYENDA AJUSTADA)
                    fig.update_layout(
                        title=f"Tendencia Espacial de Precipitaci√≥n<br><sup>{basin_name}</sup>",  # T√≠tulo con subt√≠tulo de cuenca
                        xaxis_title="Longitud",
                        yaxis_title="Latitud",
                        height=650,  # Un poco m√°s alto
                        yaxis=dict(scaleanchor="x", scaleratio=1),
                        legend=dict(
                            orientation="h",
                            yanchor="top",
                            y=-0.1,  # Movemos la leyenda DEBAJO del gr√°fico
                            xanchor="center",
                            x=0.5,
                        ),
                        margin=dict(
                            l=20, r=20, t=60, b=80
                        ),  # M√°s margen abajo para la leyenda
                    )
                    st.plotly_chart(fig)

                    c_d1, c_d2 = st.columns(2)
                    with c_d1:
                        geojson = df_trend.to_json(orient="records")
                        st.download_button(
                            "üì• Descargar Puntos (JSON)",
                            geojson,
                            "tendencias_puntos.json",
                            "application/json",
                        )
                    with c_d2:
                        flat_x = grid_x.flatten()
                        flat_y = grid_y.flatten()
                        flat_z = grid_z.flatten()
                        df_grid = pd.DataFrame(
                            {"lon": flat_x, "lat": flat_y, "tendencia": flat_z}
                        ).dropna()
                        csv_grid = df_grid.to_csv(index=False).encode("utf-8")
                        st.download_button(
                            "üì• Descargar Grilla (CSV)",
                            csv_grid,
                            "tendencias_grilla.csv",
                            "text/csv",
                        )
                else:
                    st.warning("Datos insuficientes para interpolar.")

    # --- TAB 2: SIMULADOR CMIP6 (MANTENIDO IGUAL) ---
    with tab_cmip6:
        # (El c√≥digo del simulador se mantiene id√©ntico al bloque anterior que ya funcionaba)
        st.subheader("Simulador de Cambio Clim√°tico (Escenarios CMIP6)")
        st.info(
            "Proyecci√≥n de anomal√≠as climatol√≥gicas para la regi√≥n Andina (Horizonte 2040-2060)."
        )

        # 1. Caja Informativa
        with st.expander(
            "üìö Conceptos Clave: Escenarios SSP y Modelos CMIP6 (IPCC AR6)",
            expanded=False,
        ):
            st.markdown(
                """
            **üîç Anatom√≠a del C√≥digo: {Escenario} = {SSP(X)} - {Y.Y}**
            Combina la **Trayectoria Social (SSP 1-5)** con el **Forzamiento Radiativo (W/m¬≤)** al 2100.

            **üìâ Escenarios "Tier 1" (Proyecciones):**
            * **SSP1-2.6 (Sostenibilidad):** "Ruta Verde". Emisiones cero neto a 2050. Escenario optimista (<2¬∞C).
            * **SSP2-4.5 (Camino Medio):** Tendencias actuales. Progreso desigual. Escenario de planificaci√≥n "realista" (~2.7¬∞C).
            * **SSP3-7.0 (Rivalidad Regional):** Nacionalismo y baja cooperaci√≥n. Muy peligroso (~3.6¬∞C a 4¬∞C).
            * **SSP5-8.5 (Desarrollo F√≥sil):** "La Autopista". Crecimiento r√°pido basado en carb√≥n/petr√≥leo. El peor caso (>4.4¬∞C).

            ---
            **üõ†Ô∏è Nota para Ingenier√≠a:**
            Use **SSP2-4.5** para planificaci√≥n est√°ndar. Use **SSP5-8.5** solo para **pruebas de estr√©s** en infraestructura cr√≠tica (validar resiliencia ante eventos extremos in√©ditos).
            """
            )

        scenarios_db = {
            "SSP1-2.6 (Sostenibilidad)": {
                "temp": 1.6,
                "ppt_anual": 5.2,
                "desc": "Escenario optimista...",
            },
            "SSP2-4.5 (Camino Medio)": {
                "temp": 2.1,
                "ppt_anual": -2.5,
                "desc": "Escenario intermedio...",
            },
            "SSP3-7.0 (Rivalidad Regional)": {
                "temp": 2.8,
                "ppt_anual": -8.4,
                "desc": "Escenario pesimista...",
            },
            "SSP5-8.5 (Desarrollo F√≥sil)": {
                "temp": 3.4,
                "ppt_anual": -12.1,
                "desc": "Peor escenario...",
            },
        }

        st.markdown("##### üéõÔ∏è Ajuste Manual de Escenarios (Simulaci√≥n)")
        c_sim1, c_sim2 = st.columns(2)
        with c_sim1:
            delta_temp = st.slider(
                "Aumento de Temperatura (¬∞C):",
                0.0,
                5.0,
                1.5,
                0.1,
                help="Simular aumento de temperatura.",
            )
        with c_sim2:
            delta_ppt = st.slider(
                "Cambio en Precipitaci√≥n (%):",
                -30,
                30,
                -5,
                1,
                help="Simular cambio porcentual.",
            )

        if st.button("üöÄ Simular Escenario Futuro"):
            et_increase = delta_temp * 3
            water_balance_change = delta_ppt - et_increase
            st.metric(
                "Impacto Estimado en Balance H√≠drico",
                f"{water_balance_change:.1f}%",
                delta="D√©ficit H√≠drico" if water_balance_change < 0 else "Excedente",
                delta_color="inverse",
            )
            st.caption(f"Nota: Aumento de ET estimado: {et_increase:.1f}%.")

        st.divider()

        st.markdown("##### üìä Comparativa de Escenarios Oficiales vs. Simulaci√≥n")
        c_sel, c_sort = st.columns([2, 1])
        with c_sel:
            selected_scenarios = st.multiselect(
                "Seleccionar Escenarios:",
                list(scenarios_db.keys()),
                default=list(scenarios_db.keys()),
            )
        with c_sort:
            sort_order = st.selectbox(
                "Ordenar Gr√°fico:",
                ["Ascendente ‚¨ÜÔ∏è", "Descendente ‚¨áÔ∏è", "Nombre Escenario"],
            )

        if selected_scenarios:
            plot_data = []
            for sc in selected_scenarios:
                row = scenarios_db[sc]
                plot_data.append(
                    {
                        "Escenario": sc,
                        "Anomal√≠a Temperatura (¬∞C)": row["temp"],
                        "Anomal√≠a Precipitaci√≥n (%)": row["ppt_anual"],
                        "Tipo": "Oficial",
                    }
                )

            plot_data.append(
                {
                    "Escenario": "Mi Simulaci√≥n (Manual)",
                    "Anomal√≠a Temperatura (¬∞C)": delta_temp,
                    "Anomal√≠a Precipitaci√≥n (%)": delta_ppt,
                    "Tipo": "Usuario",
                }
            )

            df_sim = pd.DataFrame(plot_data)

            if "Ascendente" in sort_order:
                df_sim = df_sim.sort_values(
                    "Anomal√≠a Precipitaci√≥n (%)", ascending=True
                )
            elif "Descendente" in sort_order:
                df_sim = df_sim.sort_values(
                    "Anomal√≠a Precipitaci√≥n (%)", ascending=False
                )
            else:
                df_sim = df_sim.sort_values("Escenario")

            c_g1, c_g2 = st.columns(2)
            with c_g1:
                fig_ppt = px.bar(
                    df_sim,
                    y="Escenario",
                    x="Anomal√≠a Precipitaci√≥n (%)",
                    color="Anomal√≠a Precipitaci√≥n (%)",
                    title="Anomal√≠a Precipitaci√≥n (%)",
                    color_continuous_scale="RdBu",
                    text_auto=".1f",
                    orientation="h",
                )
                fig_ppt.add_vline(x=0, line_width=1, line_color="black")
                st.plotly_chart(fig_ppt, use_container_width=True)
            with c_g2:
                fig_temp = px.bar(
                    df_sim,
                    y="Escenario",
                    x="Anomal√≠a Temperatura (¬∞C)",
                    color="Anomal√≠a Temperatura (¬∞C)",
                    title="Aumento Temperatura (¬∞C)",
                    color_continuous_scale="YlOrRd",
                    text_auto=".1f",
                    orientation="h",
                )
                st.plotly_chart(fig_temp, use_container_width=True)

            st.markdown("##### üìã Detalles de Escenarios")
            st.dataframe(
                df_sim[
                    [
                        "Escenario",
                        "Anomal√≠a Precipitaci√≥n (%)",
                        "Anomal√≠a Temperatura (¬∞C)",
                        "Tipo",
                    ]
                ],
            )
        else:
            st.warning("Seleccione escenarios para comparar.")


def display_station_table_tab(**kwargs):
    st.subheader("üìã Tabla Detallada de Datos")

    # Podemos mostrar los datos mensuales o anuales
    df_monthly = kwargs.get("df_monthly_filtered")

    if df_monthly is not None and not df_monthly.empty:
        st.write(f"Mostrando {len(df_monthly)} registros filtrados.")

        # Formatear fecha para que se vea bonita
        df_show = df_monthly.copy()
        df_show["Fecha"] = df_show[Config.DATE_COL].dt.strftime("%Y-%m-%d")

        # Selecci√≥n de columnas limpias
        cols = ["Fecha", Config.STATION_NAME_COL, Config.PRECIPITATION_COL]
        st.dataframe(df_show[cols])

        # Bot√≥n de descarga
        csv = df_show[cols].to_csv(index=False).encode("utf-8")
        st.download_button(
            "üì• Descargar CSV",
            csv,
            "datos_precipitacion.csv",
            "text/csv",
            key="download-csv",
        )
    else:
        st.warning("No hay datos para mostrar.")


# LAND_COVER (Coberturas)
def display_land_cover_analysis_tab(df_long, gdf_stations, **kwargs):
    st.subheader("üåø An√°lisis de Cobertura del Suelo y Escenarios")

    # 1. Configuraci√≥n
    Config = None
    try:
        from modules.config import Config as Cfg
        Config = Cfg
    except: pass
    
    raster_path = "data/Cob25m_WGS84.tif"
    if Config and hasattr(Config, "LAND_COVER_RASTER_PATH"):
        raster_path = Config.LAND_COVER_RASTER_PATH

    # 2. Control de Vista
    res_basin = st.session_state.get("basin_res")
    has_basin_data = res_basin and res_basin.get("ready")
    
    col_ctrl, col_info = st.columns([1, 2])
    with col_ctrl:
        idx = 1 if has_basin_data else 0
        view_mode = st.radio("üìç Modo Visualizaci√≥n:", ["Regional", "Cuenca"], index=idx, horizontal=True)
    
    gdf_mask = None
    basin_name = "Regional (Antioquia)"
    ppt_anual = 2000
    area_cuenca_km2 = None 
    
    if view_mode == "Cuenca":
        if has_basin_data:
            gdf_mask = res_basin.get("gdf_cuenca", res_basin.get("gdf_union"))
            basin_name = res_basin.get("names", "Cuenca Actual")
            bal = res_basin.get("bal", {})
            ppt_anual = bal.get("P", 2000)
            morph = res_basin.get("morph", {})
            area_cuenca_km2 = morph.get("area_km2", 0)
            with col_info:
                st.success(f"Analizando: **{basin_name}**")
        else:
            st.warning("‚ö†Ô∏è No hay cuenca delimitada. Cambiando a modo Regional.")
            view_mode = "Regional"

    # 3. Procesamiento
    try:
        import modules.land_cover as lc
        
        # Procesar Raster (lc.process_land_cover_raster ya maneja proyecciones internamente gracias a nuestro fix anterior)
        scale = 10 if view_mode == "Regional" else 1
        data, transform, crs, nodata = lc.process_land_cover_raster(
            raster_path, gdf_mask=gdf_mask, scale_factor=scale
        )
        
        if data is None:
            st.error("Error cargando mapa. Verifica el archivo raster o la superposici√≥n con la cuenca.")
            return

        # C√°lculo Estad√≠stico
        df_res, area_total_km2 = lc.calculate_land_cover_stats(
            data, transform, crs, nodata, manual_area_km2=area_cuenca_km2
        )

        # 4. Visualizaci√≥n
        tab_map, tab_stat, tab_sim = st.tabs(["üó∫Ô∏è Mapa Interactivo", "üìä Tabla & Gr√°ficos", "üéõÔ∏è Simulador SCS-CN"])

        with tab_map:
            c_tools, c_map = st.columns([1, 4])
            with c_tools:
                st.markdown("##### Opciones")
                use_hover = st.checkbox("üîç Activar Hover", value=False, help="Muestra nombres al pasar el mouse.")
                show_legend = st.checkbox("üìù Leyenda", value=True)
                
                tiff_bytes = lc.get_tiff_bytes(data, transform, crs, nodata)
                if tiff_bytes:
                    st.download_button("üì• Bajar Mapa (TIFF)", tiff_bytes, "cobertura.tif", "image/tiff")

            with c_map:
                from rasterio.transform import array_bounds
                from pyproj import Transformer
                import folium
                from folium import plugins 
                from streamlit_folium import st_folium

                # Bounds
                h, w = data.shape
                minx, miny, maxx, maxy = array_bounds(h, w, transform)
                
                # Transformar bounds a Lat/Lon para centrar el mapa
                transformer = Transformer.from_crs(crs, "EPSG:4326", always_xy=True)
                lon_min, lat_min = transformer.transform(minx, miny)
                lon_max, lat_max = transformer.transform(maxx, maxy)
                bounds = [[lat_min, lon_min], [lat_max, lon_max]]
                center = [(lat_min+lat_max)/2, (lon_min+lon_max)/2]

                # --- CREACI√ìN DEL MAPA ---
                m = folium.Map(location=center, zoom_start=12 if view_mode=="Cuenca" else 8, tiles="CartoDB positron")
                
                plugins.Fullscreen(
                    position='topright', title='Pantalla completa',
                    title_cancel='Salir', force_separate_button=True
                ).add_to(m)

                # --- LEYENDA HTML DIN√ÅMICA ---
                if show_legend and not df_res.empty:
                    legend_html = lc.generate_legend_html() # Usamos la del m√≥dulo si existe, o construimos manual
                    # Si prefieres la manual que ten√≠as, mantenla, pero aqu√≠ uso una l√≥gica simplificada
                    if not hasattr(lc, 'generate_legend_html'):
                         # Fallback a tu l√≥gica manual si la funci√≥n no est√° en lc
                         pass 
                    else:
                         m.get_root().html.add_child(folium.Element(lc.generate_legend_html()))

                # CAPA 1: IMAGEN (Raster)
                img_url = lc.get_raster_img_b64(data, nodata)
                if img_url:
                    folium.raster_layers.ImageOverlay(
                        image=img_url, bounds=bounds, opacity=0.75, name="Cobertura"
                    ).add_to(m)

                # CAPA 2: INTERACTIVA (Vectorial)
                if use_hover:
                    with st.spinner("Generando capa interactiva..."):
                        scale_vec = 50 if view_mode == "Regional" else 1
                        # Re-procesar para hover si es regional (downsampling)
                        if view_mode == "Regional":
                            d_hov, t_hov, _, _ = lc.process_land_cover_raster(raster_path, gdf_mask=None, scale_factor=scale_vec)
                            gdf_vec = lc.vectorize_raster_optimized(d_hov, t_hov, crs, nodata)
                        else:
                            gdf_vec = lc.vectorize_raster_optimized(data, transform, crs, nodata)
                        
                        if not gdf_vec.empty:
                            folium.GeoJson(
                                gdf_vec,
                                style_function=lambda x: {'fillColor': '#ffffff', 'color': 'none', 'fillOpacity': 0},
                                tooltip=folium.GeoJsonTooltip(fields=['Cobertura'], aliases=['Tipo:']),
                                name="Hover Info"
                            ).add_to(m)

                # --- CORRECCI√ìN CR√çTICA: PROYECCI√ìN DE LA M√ÅSCARA ---
                if view_mode == "Cuenca" and gdf_mask is not None:
                    try:
                        # Asegurar que la m√°scara est√© en Lat/Lon para que Folium la muestre
                        gdf_mask_viz = gdf_mask.to_crs(epsg=4326) if gdf_mask.crs.to_string() != "EPSG:4326" else gdf_mask
                        folium.GeoJson(
                            gdf_mask_viz, 
                            style_function=lambda x: {'color': 'black', 'fill': False, 'weight': 2},
                            name="L√≠mite Cuenca"
                        ).add_to(m)
                    except Exception as e:
                        print(f"Error proyectando m√°scara: {e}")

                # --- INTERVENCI√ìN 2: CAPAS DE VULNERABILIDAD (Con b√∫squeda segura) ---
                
                # Intentar buscar las capas en kwargs o session_state
                gdf_inc = kwargs.get('gdf_amenaza_incendios', st.session_state.get('gdf_amenaza_incendios'))
                gdf_agr = kwargs.get('gdf_aptitud_agricola', st.session_state.get('gdf_aptitud_agricola'))

                # Capa Incendios
                if gdf_inc is not None and not gdf_inc.empty:
                    try:
                        gdf_inc_viz = gdf_inc.to_crs(epsg=4326) # Reproyectar siempre por seguridad
                        folium.GeoJson(
                            data=gdf_inc_viz,
                            name='Amenaza Incendios',
                            style_function=lambda x: {
                                'fillColor': '#e74c3c' if x['properties'].get('riesgo') == 'Alto' else '#f1c40f',
                                'color': 'black', 'weight': 0.5, 'fillOpacity': 0.6
                            },
                            tooltip="Riesgo Incendio: " + folium.features.GeoJsonTooltip(fields=['riesgo'])
                        ).add_to(m)
                    except Exception as e: print(f"Error capa incendios: {e}")

                # Capa Agr√≠cola
                if gdf_agr is not None and not gdf_agr.empty:
                    try:
                        gdf_agr_viz = gdf_agr.to_crs(epsg=4326) # Reproyectar siempre por seguridad
                        folium.GeoJson(
                            data=gdf_agr_viz,
                            name='Aptitud Agr√≠cola',
                            show=False, 
                            style_function=lambda x: {
                                'fillColor': '#2ecc71', 'color': 'black', 'weight': 0.5, 'fillOpacity': 0.5
                            }
                        ).add_to(m)
                    except Exception as e: print(f"Error capa agr√≠cola: {e}")
                
                folium.LayerControl().add_to(m)
                st_folium(m, height=600, use_container_width=True, key="map_lc_final")

        with tab_stat:
            c1, c2 = st.columns([1, 1])
            with c1:
                st.dataframe(df_res[["ID", "Cobertura", "√Årea (km¬≤)", "%"]].style.format({"√Årea (km¬≤)": "{:.2f}", "%": "{:.1f}"}))
                csv = df_res.to_csv(index=False).encode('utf-8')
                st.download_button("üì• Descargar CSV", csv, "stats_coberturas.csv", "text/csv")
            with c2:
                import plotly.express as px
                fig = px.pie(df_res, values="√Årea (km¬≤)", names="Cobertura", color="Cobertura", 
                             color_discrete_map={r["Cobertura"]: r["Color"] for _, r in df_res.iterrows()}, hole=0.4)
                st.plotly_chart(fig)

        with tab_sim:
            if view_mode == "Cuenca":
                st.info("Simula cambios de uso del suelo.")
                with st.expander("‚öôÔ∏è Configuraci√≥n CN", expanded=False):
                    cc = st.columns(5)
                    cn_cfg = {
                        'bosque': cc[0].number_input("Bosque", value=55),
                        'pasto': cc[1].number_input("Pasto", value=75),
                        'cultivo': cc[2].number_input("Cultivo", value=85),
                        'urbano': cc[3].number_input("Urbano", value=95),
                        'suelo': cc[4].number_input("Suelo", value=90)
                    }
                
                st.write("**Defina el Escenario Futuro (%):**")
                sl = st.columns(5)
                inputs = [sl[0].slider("% Bosque",0,100,40), sl[1].slider("% Pasto",0,100,30),
                          sl[2].slider("% Cultivo",0,100,20), sl[3].slider("% Urbano",0,100,5),
                          sl[4].slider("% Suelo",0,100,5)]

                if abs(sum(inputs) - 100) < 0.1:
                    if st.button("üöÄ Calcular Escenario"):
                        import plotly.graph_objects as go
                        cn_act = lc.calculate_weighted_cn(df_res, cn_cfg)
                        cn_fut = (inputs[0]*cn_cfg['bosque'] + inputs[1]*cn_cfg['pasto'] + 
                                  inputs[2]*cn_cfg['cultivo'] + inputs[3]*cn_cfg['urbano'] + 
                                  inputs[4]*cn_cfg['suelo']) / 100
                        
                        q_act = lc.calculate_scs_runoff(cn_act, ppt_anual)
                        q_fut = lc.calculate_scs_runoff(cn_fut, ppt_anual)
                        
                        vol_act = (q_act * area_total_km2) / 1000
                        vol_fut = (q_fut * area_total_km2) / 1000
                        
                        c_res = st.columns(3)
                        c_res[0].metric("CN Escenario", f"{cn_fut:.1f}", delta=f"{cn_fut-cn_act:.1f}", delta_color="inverse")
                        c_res[1].metric("Escorrent√≠a Q", f"{q_fut:.0f} mm", delta=f"{q_fut-q_act:.0f} mm", delta_color="inverse")
                        c_res[2].metric("Volumen Total", f"{vol_fut:.2f} Mm¬≥", delta=f"{vol_fut-vol_act:.2f} Mm¬≥")
                        
                        fig_sim = go.Figure(data=[
                            go.Bar(name="Actual", x=["Escorrent√≠a"], y=[q_act], marker_color="#1f77b4", text=f"{q_act:.0f}", textposition="auto"),
                            go.Bar(name="Futuro", x=["Escorrent√≠a"], y=[q_fut], marker_color="#2ca02c", text=f"{q_fut:.0f}", textposition="auto"),
                        ])
                        st.plotly_chart(fig_sim, use_container_width=True)
                else:
                    st.warning("La suma debe ser 100%.")
            else:
                st.info("‚ö†Ô∏è Requiere modo Cuenca.")

    except Exception as e:
        st.error(f"Error en m√≥dulo de coberturas: {e}")


# PESTA√ëA: CORRECCI√ìN DE SESGO (VERSI√ìN BLINDADA)
# -----------------------------------------------------------------------------
def display_bias_correction_tab(df_long, gdf_stations, gdf_filtered, **kwargs):
    """
    M√≥dulo de validaci√≥n y correcci√≥n de sesgo (Estaciones vs Sat√©lite ERA5).
    Versi√≥n optimizada para series temporales mensuales.
    """
    st.subheader("üõ∞Ô∏è Validaci√≥n Mensual (Estaciones vs. Sat√©lite)")

    # --- DOCUMENTACI√ìN Y AYUDA (NUEVO BLOQUE) ---
    with st.expander(
        "‚ÑπÔ∏è Gu√≠a T√©cnica: Fuentes, Metodolog√≠a e Interpretaci√≥n", expanded=False
    ):
        st.markdown(
            """
        ### 1. ¬øQu√© hace este m√≥dulo?
        Este m√≥dulo permite comparar la **precipitaci√≥n observada** (medida por pluvi√≥metros en tierra) con la **precipitaci√≥n estimada** por modelos satelitales/rean√°lisis (ERA5-Land) para evaluar la precisi√≥n de estos √∫ltimos en la regi√≥n Andina.

        ### 2. Fuentes de Datos
        * **Estaciones (Observado):** Datos hidrometeorol√≥gicos reales cargados en el sistema (IDEAM/Particulares).
        * **Sat√©lite (Estimado):** [ERA5-Land](https://cds.climate.copernicus.eu/), un rean√°lisis clim√°tico global de alta resoluci√≥n (~9km) producido por el ECMWF.
            * *Ventaja:* Cobertura global continua y datos desde 1950.
            * *Desventaja:* Tiende a subestimar lluvias extremas en topograf√≠a compleja (monta√±as) debido a su resoluci√≥n espacial.

        ### 3. Metodolog√≠a de Procesamiento
        1.  **Agregaci√≥n Temporal:** Se transforman los datos diarios a **acumulados mensuales** exactos.
        2.  **Emparejamiento Espacial (Nearest Neighbor):** * Para cada estaci√≥n en tierra, el sistema busca el **p√≠xel (celda) m√°s cercano** del modelo satelital utilizando un algoritmo *KD-Tree*.
            * *Radio de b√∫squeda:* M√°ximo 0.1 grados (~11 km). Si no hay datos satelitales cerca, la estaci√≥n se descarta.
        3.  **C√°lculo de Diferencia:** `Dif = Obs - Sat`.
            * Valores positivos indican que la estaci√≥n midi√≥ m√°s lluvia que el sat√©lite (Subestimaci√≥n del modelo).
            * Valores negativos indican lo contrario.

        ### 4. Interpretaci√≥n de Gr√°ficos
        * **üìà Series Temporales:** Permite ver si el sat√©lite "sigue el ritmo" de la estaci√≥n (captura las temporadas de lluvias y sequ√≠as) aunque los montos no sean exactos.
        * **üó∫Ô∏è Mapa:** Muestra la ubicaci√≥n real de las estaciones sobre el fondo interpolado del sat√©lite. √ötil para identificar zonas donde el modelo falla sistem√°ticamente.
        * **üîç Correlaci√≥n:** Un $R^2$ cercano a 1 indica que el sat√©lite es un buen predictor. Si los puntos est√°n muy dispersos, el uso de datos satelitales debe hacerse con precauci√≥n (Bias Correction requerido).
        """
        )

    st.info(
        "Comparaci√≥n de series temporales mensuales: Lluvia Observada vs. ERA5-Land."
    )

    # 1. Selecci√≥n de Estaciones
    target_gdf = (
        gdf_filtered
        if gdf_filtered is not None and not gdf_filtered.empty
        else gdf_stations
    )

    if df_long.empty or target_gdf is None or target_gdf.empty:
        st.warning("Faltan datos para realizar el an√°lisis.")
        return

    # 2. Controles de UI
    c1, c2 = st.columns([2, 1])
    with c1:
        # Obtener rango de a√±os disponibles EN LOS DATOS OBSERVADOS
        years = sorted(df_long[Config.YEAR_COL].unique())
        if not years:
            st.error("El dataset no contiene informaci√≥n de a√±os.")
            return

        min_y, max_y = int(min(years)), int(max(years))
        # Slider con valores por defecto inteligentes
        default_start = max(min_y, max_y - 5)
        start_year, end_year = st.slider(
            "Per√≠odo de An√°lisis:", min_y, max_y, (default_start, max_y), key="bias_rng"
        )
    with c2:
        st.write("")  # Espaciador para alineaci√≥n vertical
        calc_btn = st.button(
            "üöÄ Calcular Series", type="primary"
        )

    # 3. L√≥gica de C√°lculo (Solo si se presiona el bot√≥n)
    if calc_btn:
        # Importaciones locales
        import geopandas as gpd  # Necesario para exportar GeoJSON
        from scipy.interpolate import griddata
        from scipy.spatial import cKDTree

        from modules.openmeteo_api import get_historical_monthly_series

        # --- PASO 1: PROCESAR DATOS OBSERVADOS ---
        with st.spinner("1/3. Procesando datos de estaciones (Agregaci√≥n Mensual)..."):
            # Filtrar datos
            mask = (
                (df_long[Config.YEAR_COL] >= start_year)
                & (df_long[Config.YEAR_COL] <= end_year)
                & (
                    df_long[Config.STATION_NAME_COL].isin(
                        target_gdf[Config.STATION_NAME_COL]
                    )
                )
            )
            df_subset = df_long[mask].copy()

            if df_subset.empty:
                st.error(
                    "No se encontraron datos observados en el periodo seleccionado."
                )
                return

            # Construir fecha robusta
            try:
                cols_data = {"year": df_subset[Config.YEAR_COL], "day": 1}
                if (
                    hasattr(Config, "MONTH_COL")
                    and Config.MONTH_COL in df_subset.columns
                ):
                    cols_data["month"] = df_subset[Config.MONTH_COL]
                elif "MONTH" in df_subset.columns:
                    cols_data["month"] = df_subset["MONTH"]
                elif "MES" in df_subset.columns:
                    cols_data["month"] = df_subset["MES"]
                else:
                    pass

                df_subset["date"] = pd.to_datetime(cols_data)
            except Exception:
                date_col = next(
                    (
                        col
                        for col in df_subset.columns
                        if "date" in col.lower() or "fecha" in col.lower()
                    ),
                    None,
                )
                if date_col:
                    df_subset["date"] = pd.to_datetime(df_subset[date_col])
                else:
                    st.error(
                        "Error cr√≠tico: No se pudo construir la fecha. Verifique columnas A√±o/Mes."
                    )
                    return

            # Normalizar fecha
            df_subset["date"] = df_subset["date"].dt.to_period("M").dt.to_timestamp()

            # Agrupar: Suma total por mes y estaci√≥n
            df_obs = (
                df_subset.groupby([Config.STATION_NAME_COL, "date"])[
                    Config.PRECIPITATION_COL
                ]
                .sum()
                .reset_index()
            )

        # --- PASO 2: DESCARGA SATELITAL (ACTUALIZADO) ---
        with st.spinner("2/3. Descargando series satelitales (ERA5-Land)..."):
            # Obtener coordenadas √∫nicas
            unique_locs = target_gdf[
                [Config.STATION_NAME_COL, "latitude", "longitude"]
            ].drop_duplicates(Config.STATION_NAME_COL)
            lats = unique_locs["latitude"].tolist()
            lons = unique_locs["longitude"].tolist()

            # Llamada a la funci√≥n robusta
            df_sat = get_historical_monthly_series(
                lats, lons, f"{start_year}-01-01", f"{end_year}-12-31"
            )

            if df_sat.empty:
                st.error(
                    "üì° La API satelital no retorn√≥ datos. Puede ser un error de conexi√≥n o timeout."
                )
                st.info(
                    "Intenta reducir el rango de a√±os o el n√∫mero de estaciones seleccionadas."
                )
                return

        # --- PASO 3: EMPAREJAMIENTO ---
        with st.spinner("3/3. Cruzando informaci√≥n espacial..."):
            obs_coords = np.column_stack(
                (unique_locs["latitude"], unique_locs["longitude"])
            )
            sat_unique = df_sat[["latitude", "longitude"]].drop_duplicates()
            sat_coords = np.column_stack(
                (sat_unique["latitude"], sat_unique["longitude"])
            )

            tree = cKDTree(sat_coords)
            dists, idxs = tree.query(obs_coords)

            map_data = []
            for i, station_name in enumerate(unique_locs[Config.STATION_NAME_COL]):
                if dists[i] < 0.1:
                    map_data.append(
                        {
                            Config.STATION_NAME_COL: station_name,
                            "sat_lat": sat_coords[idxs[i]][0],
                            "sat_lon": sat_coords[idxs[i]][1],
                            "dist_deg": dists[i],
                        }
                    )

            df_map = pd.DataFrame(map_data)
            if df_map.empty:
                st.error("No se encontraron coincidencias espaciales.")
                return

            # MERGE 1: Obs + Map
            df_merged = pd.merge(df_obs, df_map, on=Config.STATION_NAME_COL)
            # MERGE 1b: Agregar coordenadas REALES
            df_merged = pd.merge(
                df_merged, unique_locs, on=Config.STATION_NAME_COL, how="left"
            )

            # MERGE 2: + Sat√©lite
            df_final = pd.merge(
                df_merged,
                df_sat.rename(columns={"latitude": "sat_lat", "longitude": "sat_lon"}),
                on=["date", "sat_lat", "sat_lon"],
                how="inner",
            )

            df_final["diff_mm"] = (
                df_final[Config.PRECIPITATION_COL] - df_final["ppt_sat"]
            )

            st.success("‚úÖ An√°lisis completado exitosamente.")

            # --- VISUALIZACI√ìN ---
            tab_series, tab_mapa, tab_datos = st.tabs(
                ["üìà Series Temporales", "üó∫Ô∏è Mapa Promedio", "üìã Datos & Descargas"]
            )

            # TAB 1: SERIES
            with tab_series:
                c_sel, _ = st.columns([1, 2])
                with c_sel:
                    estaciones_disp = sorted(df_final[Config.STATION_NAME_COL].unique())
                    sel_st = st.selectbox(
                        "Seleccionar Visualizaci√≥n:",
                        ["Promedio Regional"] + estaciones_disp,
                    )

                if sel_st == "Promedio Regional":
                    plot_df = (
                        df_final.groupby("date")[[Config.PRECIPITATION_COL, "ppt_sat"]]
                        .mean()
                        .reset_index()
                    )
                    title_plot = "Promedio Regional (Todas las Estaciones)"
                else:
                    plot_df = df_final[df_final[Config.STATION_NAME_COL] == sel_st]
                    title_plot = f"Estaci√≥n: {sel_st}"

                fig = go.Figure()
                fig.add_trace(
                    go.Scatter(
                        x=plot_df["date"],
                        y=plot_df[Config.PRECIPITATION_COL],
                        name="Observado (Real)",
                        mode="lines+markers",
                    )
                )
                fig.add_trace(
                    go.Scatter(
                        x=plot_df["date"],
                        y=plot_df["ppt_sat"],
                        name="Sat√©lite (ERA5)",
                        mode="lines+markers",
                        line=dict(dash="dash"),
                    )
                )
                fig.update_layout(title=title_plot, hovermode="x unified")
                st.plotly_chart(fig)

            # TAB 2: MAPA
            with tab_mapa:
                st.markdown("**Comparativa Espacial (Promedio del Periodo)**")
                # Agregamos por ubicaci√≥n REAL y SATELITAL
                map_agg = (
                    df_final.groupby(
                        [
                            Config.STATION_NAME_COL,
                            "latitude",
                            "longitude",
                            "sat_lat",
                            "sat_lon",
                        ]
                    )[["ppt_sat", Config.PRECIPITATION_COL]]
                    .mean()
                    .reset_index()
                )

                # -- GENERACI√ìN DE TEXTO PARA POPUP (HOVER) --
                map_agg["hover_text"] = map_agg.apply(
                    lambda row: f"<b>{row[Config.STATION_NAME_COL]}</b><br>üíß Obs: {row[Config.PRECIPITATION_COL]:.1f} mm<br>üõ∞Ô∏è Sat: {row['ppt_sat']:.1f} mm",
                    axis=1,
                )

                try:
                    # Interpolaci√≥n Sat√©lite (Fondo)
                    grid_x, grid_y = np.mgrid[
                        map_agg["sat_lon"].min() : map_agg["sat_lon"].max() : 100j,
                        map_agg["sat_lat"].min() : map_agg["sat_lat"].max() : 100j,
                    ]
                    grid_z = griddata(
                        (map_agg["sat_lon"], map_agg["sat_lat"]),
                        map_agg["ppt_sat"],
                        (grid_x, grid_y),
                        method="cubic",
                    )

                    fig_map = go.Figure()
                    fig_map.add_trace(
                        go.Contour(
                            z=grid_z.T,
                            x=grid_x[:, 0],
                            y=grid_y[0, :],
                            colorscale="Blues",
                            opacity=0.6,
                            showscale=False,
                            name="Sat√©lite (Fondo)",
                        )
                    )
                    # Puntos Reales con HOVER PERSONALIZADO
                    fig_map.add_trace(
                        go.Scatter(
                            x=map_agg["longitude"],
                            y=map_agg["latitude"],
                            mode="markers",
                            marker=dict(
                                size=10,
                                color=map_agg[Config.PRECIPITATION_COL],
                                colorscale="RdBu",
                                showscale=True,
                                line=dict(width=1, color="black"),
                            ),
                            text=map_agg["hover_text"],  # Usamos la columna formateada
                            hoverinfo="text",  # Forzamos a mostrar solo el texto
                            name="Estaciones",
                        )
                    )
                    fig_map.update_layout(
                        title="Fondo: Sat√©lite | Puntos: Estaciones (Posici√≥n Real)",
                        height=500,
                    )
                    st.plotly_chart(fig_map, use_container_width=True)
                except Exception as e:
                    st.warning(f"No se pudo interpolar: {e}")
                    st.map(map_agg)

            # TAB 3: DATOS Y GEOJSON
            with tab_datos:
                st.markdown("### Datos Tabulares")
                st.dataframe(
                    df_final[
                        [
                            Config.STATION_NAME_COL,
                            "date",
                            Config.PRECIPITATION_COL,
                            "ppt_sat",
                            "diff_mm",
                        ]
                    ].sort_values(by=[Config.STATION_NAME_COL, "date"]),
                )

                c_csv, c_geo = st.columns(2)

                # 1. Descarga CSV
                with c_csv:
                    csv = df_final.to_csv(index=False).encode("utf-8")
                    st.download_button(
                        "üì• Descargar Series (CSV)",
                        csv,
                        "validacion_mensual_satelite.csv",
                        "text/csv",
                    )

                # 2. Descarga GEOJSON (Promedios Espaciales)
                with c_geo:
                    # Convertir el DataFrame agregado (map_agg) a GeoDataFrame
                    # map_agg ya tiene el promedio por estaci√≥n calculado en el bloque anterior (Tab 2)
                    gdf_export = gpd.GeoDataFrame(
                        map_agg,
                        geometry=gpd.points_from_xy(
                            map_agg.longitude, map_agg.latitude
                        ),
                        crs="EPSG:4326",
                    )
                    geojson_data = gdf_export.to_json()
                    st.download_button(
                        "üåç Descargar Mapa Promedio (GeoJSON)",
                        data=geojson_data,
                        file_name="estaciones_promedio_satelite.geojson",
                        mime="application/geo+json",
                    )


def display_statistics_summary_tab(df_monthly, df_anual, gdf_stations, **kwargs):
    """Tablero de resumen estad√≠stico de alto nivel: R√©cords y extremos."""

    st.markdown("### üèÜ S√≠ntesis Estad√≠stica de Precipitaci√≥n")

    st.info(
        "Resumen de valores extremos hist√≥ricos y promedios climatol√≥gicos de la red seleccionada."
    )

    if df_monthly is None or df_monthly.empty or df_anual is None or df_anual.empty:
        st.warning("No hay suficientes datos para calcular estad√≠sticas.")
        return

    # --- 1. PREPARACI√ìN DE DATOS ---
    # Aseguramos columnas auxiliares
    if "Municipio" not in df_anual.columns and gdf_stations is not None:
        # Merge para traer municipio y cuenca si no est√°n
        cols_to_merge = [Config.STATION_NAME_COL, Config.MUNICIPALITY_COL]
        if "Cuenca" in gdf_stations.columns:
            cols_to_merge.append("Cuenca")

        # Limpieza de duplicados en gdf antes del merge
        gdf_clean = gdf_stations[cols_to_merge].drop_duplicates(Config.STATION_NAME_COL)

        df_anual = pd.merge(df_anual, gdf_clean, on=Config.STATION_NAME_COL, how="left")
        df_monthly = pd.merge(
            df_monthly, gdf_clean, on=Config.STATION_NAME_COL, how="left"
        )

    # Rellenar nulos de texto
    df_anual[Config.MUNICIPALITY_COL] = df_anual[Config.MUNICIPALITY_COL].fillna(
        "Desconocido"
    )
    df_monthly[Config.MUNICIPALITY_COL] = df_monthly[Config.MUNICIPALITY_COL].fillna(
        "Desconocido"
    )

    col_cuenca = "Cuenca" if "Cuenca" in df_anual.columns else None
    if col_cuenca:
        df_anual[col_cuenca] = df_anual[col_cuenca].fillna("N/A")
        df_monthly[col_cuenca] = df_monthly[col_cuenca].fillna("N/A")

    # --- 2. C√ÅLCULO DE R√âCORDS ANUALES ---
    # M√°ximo Anual
    idx_max_anual = df_anual[Config.PRECIPITATION_COL].idxmax()
    row_max_anual = df_anual.loc[idx_max_anual]

    # M√≠nimo Anual (evitando ceros si se desea, o absoluto)
    # Filtramos ceros si se considera error, o los dejamos si son reales. Asumimos > 0 para "a√±o seco real" vs "sin datos"
    df_anual_pos = df_anual[df_anual[Config.PRECIPITATION_COL] > 0]
    if not df_anual_pos.empty:
        idx_min_anual = df_anual_pos[Config.PRECIPITATION_COL].idxmin()
        row_min_anual = df_anual_pos.loc[idx_min_anual]
    else:
        row_min_anual = row_max_anual  # Fallback

    # --- 3. C√ÅLCULO DE R√âCORDS MENSUALES ---
    idx_max_men = df_monthly[Config.PRECIPITATION_COL].idxmax()
    row_max_men = df_monthly.loc[idx_max_men]

    # M√≠nimo Mensual > 0 (el 0 es com√∫n, buscamos el m√≠nimo llovido)
    df_men_pos = df_monthly[df_monthly[Config.PRECIPITATION_COL] > 0]
    if not df_men_pos.empty:
        idx_min_men = df_men_pos[Config.PRECIPITATION_COL].idxmin()
        row_min_men = df_men_pos.loc[idx_min_men]
    else:
        row_min_men = row_max_men

    # --- 4. PROMEDIOS REGIONALES ---
    # A√±o m√°s lluvioso (Promedio de todas las estaciones ese a√±o)
    regional_anual = df_anual.groupby(Config.YEAR_COL)[Config.PRECIPITATION_COL].mean()
    year_max_reg = regional_anual.idxmax()
    val_max_reg = regional_anual.max()

    year_min_reg = regional_anual.idxmin()
    val_min_reg = regional_anual.min()

    # Mes Climatol√≥gico m√°s lluvioso
    regional_mensual = df_monthly.groupby(Config.MONTH_COL)[
        Config.PRECIPITATION_COL
    ].mean()
    mes_max_reg_idx = regional_mensual.idxmax()
    val_mes_max_reg = regional_mensual.max()
    meses_dict = {
        1: "Ene",
        2: "Feb",
        3: "Mar",
        4: "Abr",
        5: "May",
        6: "Jun",
        7: "Jul",
        8: "Ago",
        9: "Sep",
        10: "Oct",
        11: "Nov",
        12: "Dic",
    }
    mes_max_name = meses_dict.get(mes_max_reg_idx, str(mes_max_reg_idx))

    # --- 5. TENDENCIAS (Si hay datos suficientes) ---
    # Calculamos Mann-Kendall r√°pido para todas las estaciones
    trend_results = []
    import pymannkendall as mk

    stations = df_anual[Config.STATION_NAME_COL].unique()
    for stn in stations:
        sub = df_anual[df_anual[Config.STATION_NAME_COL] == stn]
        if len(sub) >= 10:
            try:
                res = mk.original_test(sub[Config.PRECIPITATION_COL])
                trend_results.append({"Estacion": stn, "Slope": res.slope})
            except:
                pass

    df_trends = pd.DataFrame(trend_results)
    if not df_trends.empty:
        max_trend = df_trends.loc[df_trends["Slope"].idxmax()]
        min_trend = df_trends.loc[df_trends["Slope"].idxmin()]
        regional_trend = df_trends["Slope"].mean()
    else:
        max_trend = {"Estacion": "N/A", "Slope": 0}
        min_trend = {"Estacion": "N/A", "Slope": 0}
        regional_trend = 0

    # --- 6. ALTITUD ---
    if gdf_stations is not None and Config.ALTITUDE_COL in gdf_stations.columns:
        # Filtrar solo las que tienen datos
        gdf_valid = gdf_stations[gdf_stations[Config.STATION_NAME_COL].isin(stations)]
        max_alt = gdf_valid.loc[gdf_valid[Config.ALTITUDE_COL].idxmax()]
        min_alt = gdf_valid.loc[gdf_valid[Config.ALTITUDE_COL].idxmin()]
    else:
        max_alt = {"Estacion": "N/A", Config.ALTITUDE_COL: 0}
        min_alt = {"Estacion": "N/A", Config.ALTITUDE_COL: 0}

    # ==========================================================================
    # RENDERIZADO VISUAL (TARJETAS)
    # ==========================================================================

    # Estilos CSS para tarjetas
    st.markdown(
        """
    <style>
    div.metric-card {
        background-color: #f9f9f9;
        border: 1px solid #e0e0e0;
        padding: 15px;
        border-radius: 10px;
        box-shadow: 2px 2px 5px rgba(0,0,0,0.05);
        margin-bottom: 10px;
    }
    h5.card-title { color: #1f77b4; margin-bottom: 0.5rem; font-size: 1.1rem; }
    div.big-val { font-size: 1.8rem; font-weight: bold; color: #333; }
    div.sub-val { font-size: 0.9rem; color: #666; margin-top: 5px;}
    span.label { font-weight: bold; color: #444; }
    </style>
    """,
        unsafe_allow_html=True,
    )

    def card(title, val, unit, stn, loc_info, date_info, icon="üåßÔ∏è"):
        # Funci√≥n helper para renderizar tarjeta HTML
        cuenca_str = (
            f"<br><span class='label'>Cuenca:</span> {loc_info.get(col_cuenca, 'N/A')}"
            if col_cuenca
            else ""
        )
        return st.markdown(
            f"""
        <div class="metric-card">
            <h5 class="card-title">{icon} {title}</h5>
            <div class="big-val">{val:,.1f} {unit}</div>
            <div class="sub-val">
                <span class="label">Estaci√≥n:</span> {stn}<br>
                <span class="label">Ubicaci√≥n:</span> {loc_info.get(Config.MUNICIPALITY_COL, 'N/A')} {cuenca_str}<br>
                <span class="label">Fecha:</span> {date_info}
            </div>
        </div>
        """,
            unsafe_allow_html=True,
        )

    # --- FILA 1: R√âCORDS ANUALES ---
    st.markdown("#### üìÖ R√©cords Hist√≥ricos Anuales")
    c1, c2 = st.columns(2)
    with c1:
        card(
            "M√°xima Precipitaci√≥n Anual",
            row_max_anual[Config.PRECIPITATION_COL],
            "mm",
            row_max_anual[Config.STATION_NAME_COL],
            row_max_anual,
            row_max_anual[Config.YEAR_COL],
            "üåä",
        )
    with c2:
        card(
            "M√≠nima Precipitaci√≥n Anual",
            row_min_anual[Config.PRECIPITATION_COL],
            "mm",
            row_min_anual[Config.STATION_NAME_COL],
            row_min_anual,
            row_min_anual[Config.YEAR_COL],
            "üåµ",
        )

    # --- FILA 2: R√âCORDS MENSUALES ---
    st.markdown("#### üóìÔ∏è R√©cords Hist√≥ricos Mensuales")
    c3, c4 = st.columns(2)
    with c3:
        # Formatear fecha mensual
        try:
            m_date = f"{meses_dict[row_max_men[Config.MONTH_COL]]} - {row_max_men[Config.YEAR_COL]}"
        except:
            m_date = str(row_max_men[Config.YEAR_COL])
        card(
            "M√°xima Lluvia Mensual",
            row_max_men[Config.PRECIPITATION_COL],
            "mm",
            row_max_men[Config.STATION_NAME_COL],
            row_max_men,
            m_date,
            "‚õàÔ∏è",
        )
    with c4:
        try:
            m_date_min = f"{meses_dict[row_min_men[Config.MONTH_COL]]} - {row_min_men[Config.YEAR_COL]}"
        except:
            m_date_min = str(row_min_men[Config.YEAR_COL])
        card(
            "M√≠nima Lluvia Mensual (>0)",
            row_min_men[Config.PRECIPITATION_COL],
            "mm",
            row_min_men[Config.STATION_NAME_COL],
            row_min_men,
            m_date_min,
            "‚òÄÔ∏è",
        )

    st.divider()

    # --- FILA 3: COMPORTAMIENTO REGIONAL ---
    st.markdown("#### üåê Comportamiento Regional y Tendencias")

    # M√©tricas Regionales
    m1, m2, m3, m4 = st.columns(4)
    m1.metric(
        "A√±o M√°s Lluvioso (Promedio)", f"{year_max_reg}", f"{val_max_reg:,.0f} mm/a√±o"
    )
    m2.metric(
        "A√±o Menos Lluvioso (Promedio)",
        f"{year_min_reg}",
        f"{val_min_reg:,.0f} mm/a√±o",
        delta_color="inverse",
    )
    m3.metric(
        "Mes M√°s Lluvioso (Climatolog√≠a)",
        f"{mes_max_name}",
        f"{val_mes_max_reg:,.0f} mm/mes",
    )
    m4.metric(
        "Tendencia Regional Promedio",
        f"{regional_trend:+.2f} mm/a√±o",
        delta="Aumento" if regional_trend > 0 else "Disminuci√≥n",
    )

    # --- FILA 4: EXTREMOS GEOGR√ÅFICOS Y TENDENCIAS ---
    c5, c6 = st.columns(2)

    with c5:
        st.markdown("**üèîÔ∏è Extremos Altitudinales**")
        st.dataframe(
            pd.DataFrame(
                [
                    {
                        "Tipo": "Mayor Altitud",
                        "Estaci√≥n": max_alt[Config.STATION_NAME_COL],
                        "Altitud": f"{max_alt[Config.ALTITUDE_COL]:.0f} msnm",
                    },
                    {
                        "Tipo": "Menor Altitud",
                        "Estaci√≥n": min_alt[Config.STATION_NAME_COL],
                        "Altitud": f"{min_alt[Config.ALTITUDE_COL]:.0f} msnm",
                    },
                ]
            ),
            hide_index=True,
        )

    with c6:
        st.markdown("**üìà Extremos de Tendencia (Mann-Kendall)**")
        st.dataframe(
            pd.DataFrame(
                [
                    {
                        "Tipo": "Mayor Aumento",
                        "Estaci√≥n": max_trend["Estacion"],
                        "Pendiente": f"{max_trend['Slope']:.2f} mm/a√±o",
                    },
                    {
                        "Tipo": "Mayor Disminuci√≥n",
                        "Estaci√≥n": min_trend["Estacion"],
                        "Pendiente": f"{min_trend['Slope']:.2f} mm/a√±o",
                    },
                ]
            ),
            hide_index=True,
        )

# --- FUNCI√ìN AUXILIAR: RESUMEN DE FILTROS ---
def display_current_filters(stations_sel, regions_sel, munis_sel, year_range, interpolacion, df_data, gdf_filtered=None, **kwargs):
    """
    Muestra resumen de filtros.
    """
    # 1. SOLUCI√ìN ESPACIO: Un contenedor invisible
    st.markdown("<div style='margin-top: 20px;'></div>", unsafe_allow_html=True)

    with st.expander("üîç Resumen de Configuraci√≥n (Clic para ocultar/mostrar)", expanded=True):
        col1, col2, col3, col4 = st.columns(4)
        with col1: st.metric("üìÖ A√±os", f"{year_range[0]} - {year_range[1]}")
        with col2: st.metric("üìç Estaciones", f"{len(stations_sel)}")
        with col3: st.metric("üîÑ Interpolaci√≥n", interpolacion)
        with col4:
            count = len(df_data) if df_data is not None else 0
            st.metric("üìä Registros", f"{count:,}")

        st.markdown("---")
        c_geo1, c_geo2 = st.columns(2)
        
        with c_geo1:
            if regions_sel: reg_txt = ", ".join(regions_sel)
            else: reg_txt = "Todas (Global)"
            st.markdown(f"**üó∫Ô∏è Regi√≥n:** {reg_txt}")

        with c_geo2:
            txt_munis = "Todos los disponibles"
            lista_nombres = []
            if munis_sel: lista_nombres = munis_sel
            elif gdf_filtered is not None and not gdf_filtered.empty:
                col_muni = next((c for c in gdf_filtered.columns if "muni" in c.lower() or "ciud" in c.lower()), None)
                if col_muni: lista_nombres = sorted(gdf_filtered[col_muni].astype(str).unique().tolist())

            if lista_nombres:
                if len(lista_nombres) > 3:
                    muestras = ", ".join(lista_nombres[:3])
                    restantes = len(lista_nombres) - 3
                    txt_munis = f"{muestras} y {restantes} m√°s..."
                else: txt_munis = ", ".join(lista_nombres)
                if not munis_sel: txt_munis = f"(Incluye: {txt_munis})"

            st.markdown(f"**üèôÔ∏è Municipios:** {txt_munis}")


# --- B. MAPA INTERACTIVO MAESTRO ---
def generar_mapa_interactivo(grid_data, bounds, gdf_stations, gdf_zona, gdf_buffer, 
                             gdf_predios=None, gdf_bocatomas=None, gdf_municipios=None,
                             nombre_capa="Variable", cmap_name="Spectral_r", opacidad=0.7):
    """
    Genera el mapa completo con Raster coloreado, Isol√≠neas limpias y Vectores ricos.
    """
    minx, miny, maxx, maxy = bounds
    center_lat = (miny + maxy) / 2
    center_lon = (minx + maxx) / 2
    
    m = folium.Map(location=[center_lat, center_lon], zoom_start=11, tiles=None, control_scale=True)
    
    # Capas Base
    folium.TileLayer(tiles="https://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}", attr="Esri", name="üõ∞Ô∏è Sat√©lite", overlay=False).add_to(m)
    folium.TileLayer(tiles="CartoDB positron", name="üó∫Ô∏è Mapa Claro", overlay=False).add_to(m)

    # 1. RASTER (Imagen de Fondo)
    if grid_data is not None:
        Z = grid_data[0] if isinstance(grid_data, tuple) else grid_data
        Z = Z.astype(float)
        try:
            valid = Z[~np.isnan(Z)]
            vmin, vmax = (np.percentile(valid, 2), np.percentile(valid, 98)) if len(valid) > 0 else (0, 1)
            
            norm = mcolors.Normalize(vmin=vmin, vmax=vmax)
            cmap = plt.get_cmap(cmap_name)
            rgba_img = cmap(norm(Z))
            rgba_img[..., 3] = np.where(np.isnan(Z), 0, opacidad)
            
            folium.raster_layers.ImageOverlay(
                image=np.flipud(rgba_img),
                bounds=[[miny, minx], [maxy, maxx]], 
                name=f"üé® {nombre_capa}", opacity=1, mercator_project=True
            ).add_to(m)
            
            # Leyenda
            colors_hex = [mcolors.to_hex(cmap(i)) for i in np.linspace(0, 1, 15)]
            cm.LinearColormap(colors=colors_hex, vmin=vmin, vmax=vmax, caption=nombre_capa).add_to(m)
        except: pass

    # 2. ISOL√çNEAS (M√âTODO LIMPIO ALLSEGS - Con etiquetas - SIN L√çNEAS RECTAS)
    if grid_data is not None:
        fg_iso = folium.FeatureGroup(name="„Ä∞Ô∏è Isol√≠neas", overlay=True, show=True)
        try:
            Z_Smooth = gaussian_filter(np.nan_to_num(Z, nan=np.nanmean(Z)), sigma=1.0)
            xi = np.linspace(minx, maxx, Z.shape[1])
            yi = np.linspace(miny, maxy, Z.shape[0])
            grid_x_mesh, grid_y_mesh = np.meshgrid(xi, yi)
            
            fig_iso, ax_iso = plt.subplots()
            contours = ax_iso.contour(grid_x_mesh, grid_y_mesh, Z_Smooth, levels=12)
            plt.close(fig_iso)
            
            for i, level_segs in enumerate(contours.allsegs):
                val = contours.levels[i]
                for segment in level_segs:
                    lat_lon_coords = [[pt[1], pt[0]] for pt in segment]
                    
                    if len(lat_lon_coords) > 10: # Solo l√≠neas significativas
                        # L√≠nea
                        folium.PolyLine(
                            lat_lon_coords, color='black', weight=0.6, opacity=0.5,
                            tooltip=f"{val:.1f}"
                        ).add_to(fg_iso)
                        
                        # ETIQUETA DE TEXTO (DivIcon)
                        # Ponemos la etiqueta en el punto medio de la l√≠nea
                        mid_idx = len(lat_lon_coords) // 2
                        mid_point = lat_lon_coords[mid_idx]
                        
                        folium.map.Marker(
                            mid_point,
                            icon=DivIcon(
                                icon_size=(150,36),
                                icon_anchor=(0,0),
                                html=f'<div style="font-size: 9pt; font-weight: bold; color: #333; text-shadow: 1px 1px 0 #fff;">{val:.0f}</div>'
                            )
                        ).add_to(fg_iso)

        except Exception as e: print(f"Iso error: {e}")
        fg_iso.add_to(m)

    # 3. MUNICIPIOS (Con Tooltip)
    if gdf_municipios is not None and not gdf_municipios.empty:
        # Pre-calculamos el campo formateado para el tooltip
        # Asumimos MPIO_NAREA en km2 -> Ha = km2 * 100
        if 'MPIO_NAREA' in gdf_municipios.columns:
            gdf_municipios['area_ha_fmt'] = (gdf_municipios['MPIO_NAREA'] * 100).apply(lambda x: f"{x:,.1f} ha")
            col_area = 'area_ha_fmt'
        else:
            col_area = None

        col_name = next((c for c in gdf_municipios.columns if 'MPIO_CNMBR' in c or 'nombre' in c), None)
        
        # Configurar campos del tooltip
        fields = []
        aliases = []
        if col_name: 
            fields.append(col_name); aliases.append('Municipio:')
        if col_area:
            fields.append(col_area); aliases.append('√Årea:')

        folium.GeoJson(
            gdf_municipios, name="üèõÔ∏è Municipios",
            style_function=lambda x: {'color': '#7f8c8d', 'weight': 1, 'fill': False, 'dashArray': '4, 4'},
            tooltip=folium.GeoJsonTooltip(fields=fields, aliases=aliases) if fields else None
        ).add_to(m)

    # 4. CAPAS ZONA
    if gdf_zona is not None:
        folium.GeoJson(gdf_zona, name="üü¶ Cuenca", style_function=lambda x: {'color': 'black', 'weight': 2, 'fill': False}).add_to(m)
    if gdf_buffer is not None:
        folium.GeoJson(gdf_buffer, name="‚≠ï Buffer", style_function=lambda x: {'color': 'red', 'weight': 1, 'dashArray': '5, 5', 'fill': False}).add_to(m)

    # 5. PREDIOS (Interacci√≥n Rica)
    if gdf_predios is not None and not gdf_predios.empty:
        fg_predios = folium.FeatureGroup(name="üè° Predios", show=True)
        
        # A. Asegurar Proyecci√≥n (Vital para que no caigan en el oc√©ano)
        try:
            if gdf_predios.crs is not None and gdf_predios.crs.to_string() != "EPSG:4326":
                gdf_viz = gdf_predios.to_crs(epsg=4326)
            else:
                gdf_viz = gdf_predios
        except:
            gdf_viz = gdf_predios # Si falla la conversi√≥n, usamos el original
            
        # B. Iteraci√≥n Segura
        for _, row in gdf_viz.iterrows():
            if row.geometry and not row.geometry.is_empty:
                try:
                    # Intento 1: Popup Rico (Con tus datos)
                    html = generar_popup_predio(row)
                    popup_obj = folium.Popup(html, max_width=250)
                except:
                    # Intento 2: Popup B√°sico (Si falla el HTML, que al menos salga el nombre)
                    popup_obj = folium.Popup(str(row.get('nombre_pre', 'Predio')), max_width=200)

                # Dibujamos el pol√≠gono
                folium.GeoJson(
                    row.geometry,
                    style_function=lambda x: {'color': '#e67e22', 'weight': 1.5, 'fillOpacity': 0.3, 'fillColor': '#f39c12'},
                    popup=popup_obj,
                    tooltip=str(row.get('nombre_pre', 'Predio'))
                ).add_to(fg_predios)

        fg_predios.add_to(m)

    # 6. BOCATOMAS (Puntos con Popup HTML Rico)
    if gdf_bocatomas is not None and not gdf_bocatomas.empty:
        fg_bocas = folium.FeatureGroup(name="üö∞ Bocatomas", show=True)
        for _, row in gdf_bocatomas.iterrows():
            if row.geometry:
                html = generar_popup_bocatoma(row)
                folium.CircleMarker(
                    location=[row.geometry.y, row.geometry.x],
                    radius=6, color='white', weight=1, fill=True, fill_color='#16a085', fill_opacity=1,
                    popup=folium.Popup(html, max_width=200),
                    tooltip=str(row.get('nombre_predio', 'Bocatoma'))
                ).add_to(fg_bocas)
        fg_bocas.add_to(m)

    # 7. ESTACIONES (Puntos con Popup HTML Rico)
    if gdf_stations is not None and not gdf_stations.empty:
        fg_est = folium.FeatureGroup(name="üå¶Ô∏è Estaciones")
        for _, row in gdf_stations.iterrows():
            html = generar_popup_estacion(row)
            folium.CircleMarker(
                location=[row.geometry.y, row.geometry.x],
                radius=5, color='black', weight=1, fill=True, fill_color='#3498db', fill_opacity=1,
                popup=folium.Popup(html, max_width=200),
                tooltip=row.get('nombre', 'Estaci√≥n')
            ).add_to(fg_est)
        fg_est.add_to(m)

    # Controles
    folium.LayerControl(position='topright', collapsed=False).add_to(m)
    Fullscreen().add_to(m)
    MousePosition().add_to(m)
    MeasureControl(position='bottomleft').add_to(m)
    
    return m

# --- C. RENDERIZADOR ---
def display_advanced_maps_tab(df_long, gdf_stations, matrices, grid, mask, gdf_zona, gdf_buffer, gdf_predios, gdf_bocatomas=None, gdf_municipios=None):
    # Panel de Control
    opciones = sorted(list(matrices.keys()))
    c1, c2, c3 = st.columns([3, 2, 2])
    
    with c1: capa_sel = st.selectbox("Capa a Visualizar:", opciones)
    
    with c2:
        paletas = ["Spectral_r", "viridis", "RdYlBu", "YlGnBu", "terrain", "magma", "jet", "coolwarm", "Greys", "Blues", "Reds"]
        idx_def = 0
        if 'Elevaci√≥n' in capa_sel: idx_def = paletas.index('terrain')
        elif 'Precipitaci√≥n' in capa_sel: idx_def = paletas.index('Spectral_r')
        elif 'Temperatura' in capa_sel: idx_def = paletas.index('RdYlBu')
        elif 'Erosi√≥n' in capa_sel: idx_def = paletas.index('Reds')
        elif 'Escorrent√≠a' in capa_sel: idx_def = paletas.index('Blues')
        cmap_user = st.selectbox("Paleta de Color:", paletas, index=idx_def)
    
    with c3: opacidad = st.slider("Opacidad:", 0.0, 1.0, 0.7)
    
    m = generar_mapa_interactivo(
        grid_data=matrices[capa_sel],
        bounds=gdf_buffer.total_bounds,
        gdf_stations=gdf_stations,
        gdf_zona=gdf_zona,
        gdf_buffer=gdf_buffer,
        gdf_predios=gdf_predios,
        gdf_bocatomas=gdf_bocatomas,
        gdf_municipios=gdf_municipios,
        nombre_capa=capa_sel,
        cmap_name=cmap_user,
        opacidad=opacidad
    )
    st_folium(m, use_container_width=True, height=600)
    
# -------------------------------------------------------------------------
# FUNCI√ìN COMPARATIVA MULTIESCALAR (VERSI√ìN PREMIUM: CON SELECTOR DE ETIQUETA üè∑Ô∏è)
# -------------------------------------------------------------------------
def display_multiscale_tab(df_ignored, gdf_stations, gdf_subcuencas):
    try:
        from modules.db_manager import get_engine
    except ImportError:
        st.error("Error importando db_manager.")
        return

    st.markdown("#### üó∫Ô∏è Comparativa de Reg√≠menes de Lluvia")
    st.info("üí° An√°lisis Multiescalar: Integra datos de Lluvia, Regiones (BD) y Cuencas (Mapa).")

    # 1. RECUPERACI√ìN DE DATOS (TODO DESDE LA BD)
    try:
        engine = get_engine()
        with engine.connect() as conn:
            # A. Datos de Lluvia
            df_fresh = pd.read_sql("SELECT fecha, id_estacion, valor FROM precipitacion", conn)
            
            # B. Metadatos de Estaciones (Con Regi√≥n y Coordenadas)
            df_meta_bd = pd.read_sql("SELECT id_estacion, nombre, municipio, subregion, latitud, longitud FROM estaciones", conn)
            
            # C. Mapa de Cuencas (Directo de la BD)
            try:
                gdf_polys_bd = gpd.read_postgis("SELECT * FROM cuencas", conn, geom_col="geometry")
            except Exception:
                gdf_polys_bd = None 

    except Exception as e:
        st.error(f"Error cr√≠tico conectando a Base de Datos: {e}")
        return

    # 2. PROCESAMIENTO DE DATOS
    df_fresh['fecha'] = pd.to_datetime(df_fresh['fecha'])
    df_fresh['MES_NUM'] = df_fresh['fecha'].dt.month
    df_fresh['id_estacion'] = df_fresh['id_estacion'].astype(str).str.strip()
    df_datos = df_fresh.copy()

    df_meta = df_meta_bd.copy()
    df_meta.columns = [str(c).strip().lower() for c in df_meta.columns]
    df_meta['id_estacion'] = df_meta['id_estacion'].astype(str).str.strip()

    # --- 3. C√ÅLCULO DE CUENCA CON SELECTOR DE COLUMNAS ---
    col_cuenca_default = None
    opciones_nombre_cuenca = [] # Aqu√≠ guardaremos las columnas disponibles (ej: subc_lbl, nombre)
    
    # Priorizamos mapa de BD
    gdf_polys = gdf_polys_bd if gdf_polys_bd is not None else gdf_subcuencas

    if gdf_polys is not None:
        try:
            # Normalizar columnas del mapa
            gdf_polys.columns = [str(c).strip().lower() for c in gdf_polys.columns]
            if gdf_polys.crs is None: gdf_polys.set_crs("EPSG:4326", inplace=True)
            
            # Identificar columnas que parecen nombres (texto) para d√°rselas a elegir al usuario
            cols_ignore = ['geometry', 'id', 'gid', 'objectid', 'shape_leng', 'shape_area', 'index_right']
            opciones_nombre_cuenca = [c for c in gdf_polys.columns if c not in cols_ignore and not c.startswith('shape')]
            
            # Preparar puntos de estaciones
            df_meta['longitud'] = pd.to_numeric(df_meta['longitud'], errors='coerce')
            df_meta['latitud'] = pd.to_numeric(df_meta['latitud'], errors='coerce')
            puntos_validos = df_meta.dropna(subset=['longitud', 'latitud']).copy()
            
            if not puntos_validos.empty:
                gdf_puntos = gpd.GeoDataFrame(
                    puntos_validos, 
                    geometry=gpd.points_from_xy(puntos_validos.longitud, puntos_validos.latitud),
                    crs="EPSG:4326"
                )
                
                # Alinear proyecciones
                if gdf_puntos.crs != gdf_polys.crs: gdf_polys = gdf_polys.to_crs(gdf_puntos.crs)
                
                # SPATIAL JOIN: Nos traemos TODAS las columnas de texto del mapa
                cols_to_join = ['geometry'] + opciones_nombre_cuenca
                gdf_cruce = gpd.sjoin(gdf_puntos, gdf_polys[cols_to_join], how="left", predicate="intersects")
                
                # Limpieza de duplicados
                gdf_cruce = gdf_cruce.drop_duplicates(subset=['id_estacion'])
                
                # Merge final hacia los metadatos
                df_meta = pd.merge(
                    df_meta, 
                    gdf_cruce[['id_estacion'] + opciones_nombre_cuenca], 
                    on='id_estacion', 
                    how='left'
                )
                
                # Intentamos definir una por defecto (prioridad subc_lbl)
                if 'subc_lbl' in opciones_nombre_cuenca: col_cuenca_default = 'subc_lbl'
                elif 'nombre_cuenca' in opciones_nombre_cuenca: col_cuenca_default = 'nombre_cuenca'
                elif opciones_nombre_cuenca: col_cuenca_default = opciones_nombre_cuenca[0]

        except Exception as e:
            pass

    # 4. MERGE FINAL DE TODO
    df_full = pd.merge(df_datos, df_meta, on='id_estacion', how='inner')

    # 5. DETECCI√ìN DE COLUMNAS
    col_municipio = find_col(df_full, ['municipio', 'mpio', 'mpio_cnmbr'])
    col_region = find_col(df_full, ['subregion', 'region', 'zona'])
    
    # 6. INTERFAZ GR√ÅFICA
    meses_mapa = {1: 'Ene', 2: 'Feb', 3: 'Mar', 4: 'Abr', 5: 'May', 6: 'Jun', 
                  7: 'Jul', 8: 'Ago', 9: 'Sep', 10: 'Oct', 11: 'Nov', 12: 'Dic'}
    df_full['Nombre_Mes'] = df_full['MES_NUM'].map(meses_mapa)

    c1, c2 = st.columns([1, 2])
    with c1:
        opts = []
        if col_municipio: opts.append("Municipio")
        if col_region: opts.append("Regi√≥n") 
        # Si hay columnas de cuenca disponibles (aunque sea 1), mostramos la opci√≥n
        if opciones_nombre_cuenca: opts.append("Cuenca")
        
        if not opts:
            st.warning("‚ö†Ô∏è No se detectaron agrupaciones geogr√°ficas.")
            return

        nivel = st.radio("Agrupar por:", opts)
        
        # --- L√ìGICA DE SELECCI√ìN DE COLUMNA ---
        campo_filtro = None
        
        if nivel == "Municipio": 
            campo_filtro = col_municipio
            
        elif nivel == "Regi√≥n": 
            campo_filtro = col_region
            
        elif nivel == "Cuenca":
            # üî• AQU√ç EST√Å LA MAGIA: Selector de campo para Cuenca üî•
            if opciones_nombre_cuenca:
                # Calculamos el √≠ndice por defecto (buscando subc_lbl)
                idx_def = 0
                if 'subc_lbl' in opciones_nombre_cuenca:
                    idx_def = opciones_nombre_cuenca.index('subc_lbl')
                
                col_seleccionada = st.selectbox(
                    "üè∑Ô∏è Etiqueta de Cuenca:", 
                    opciones_nombre_cuenca, 
                    index=idx_def,
                    help="Seleccione qu√© columna del mapa usar para los nombres."
                )
                campo_filtro = col_seleccionada
            else:
                st.warning("No hay etiquetas de texto en el mapa de cuencas.")
                return

        # Llenar lista de items
        items = sorted([str(x) for x in df_full[campo_filtro].dropna().unique() if str(x).lower() != 'nan'])

    with c2:
        seleccion = st.multiselect(f"Seleccione {nivel}:", items, default=items[:3] if len(items)>2 else items)

    if seleccion:
        df_gp = df_full[df_full[campo_filtro].astype(str).isin(seleccion)]
        df_gp = df_gp.groupby(['MES_NUM', 'Nombre_Mes', campo_filtro])['valor'].mean().reset_index().sort_values('MES_NUM')

        fig = px.line(
            df_gp, x='Nombre_Mes', y='valor', color=campo_filtro,
            title=f"R√©gimen de Precipitaci√≥n - Comparativa por {nivel} ({campo_filtro})", markers=True
        )
        fig.update_xaxes(categoryorder='array', categoryarray=list(meses_mapa.values()), title="Mes")
        
        st.plotly_chart(fig, use_container_width=True)
        st.download_button("üì• Descargar CSV", df_gp.to_csv(index=False).encode('utf-8-sig'), "comparativa.csv")



