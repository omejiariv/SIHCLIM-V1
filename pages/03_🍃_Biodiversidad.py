# pages/03_üçÉ_Biodiversidad.py

import streamlit as st
import sys
import os
import io
import pandas as pd
import numpy as np
import geopandas as gpd
import rasterio
from rasterio.warp import reproject, Resampling
import plotly.graph_objects as go
import plotly.express as px
from modules.admin_utils import init_supabase

# --- IMPORTACI√ìN DE M√ìDULOS DEL SISTEMA ---
try:
    sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
    from modules import selectors, config, gbif_connector, carbon_calculator
    from modules import life_zones as lz 
    from modules import land_cover as lc
except Exception as e:
    st.error(f"Error cr√≠tico de importaci√≥n: {e}")
    st.stop()

# 1. CONFIGURACI√ìN
st.set_page_config(page_title="Monitor de Biodiversidad", page_icon="üçÉ", layout="wide")
st.title("üçÉ Biodiversidad y Servicios Ecosist√©micos Integrados")

# 2. SELECTOR ESPACIAL
try:
    ids_seleccionados, nombre_seleccion, altitud_ref, gdf_zona = selectors.render_selector_espacial()
except Exception as e:
    st.error(f"Error en selector: {e}")
    st.stop()

def save_to_csv(df):
    return df.to_csv(index=False).encode('utf-8')

# --- FUNCI√ìN DETECTIVE (VERSI√ìN DIAGN√ìSTICO) ---

# --- REEMPLAZAR LA FUNCI√ìN get_raster_from_cloud POR ESTA VERSI√ìN ---

@st.cache_resource(show_spinner=False)
def get_raster_from_cloud(filename):
    """
    Buscador Profundo: Busca en la ra√≠z y dentro de carpetas del bucket 'rasters'.
    """
    try:
        client = init_supabase()
        bucket_name = "rasters" 
        
        # 1. Listar contenido ra√≠z del bucket
        items_root = client.storage.from_(bucket_name).list()
        
        # 2. Construir lista plana de archivos (buscando dentro de carpetas si es necesario)
        all_files = []
        for item in items_root:
            if item['metadata'] is None: # Es una carpeta
                folder_name = item['name']
                # Listar contenido de la carpeta
                sub_items = client.storage.from_(bucket_name).list(path=folder_name)
                for sub in sub_items:
                    all_files.append(f"{folder_name}/{sub['name']}")
            else:
                # Es un archivo en la ra√≠z
                all_files.append(item['name'])

        # 3. L√≥gica de B√∫squeda Flexible
        # Buscamos si alguna parte del nombre coincide (ej: "DemAntioquia" en "Coberturas/DemAntioquia_v2.tif")
        keyword = filename.split('_')[0].split('.')[0] # Ej: de "DemAntioquia_EPSG..." toma "DemAntioquia"
        
        target_file = None
        for real_name in all_files:
            # Limpieza para comparar
            clean_real = real_name.split('/')[-1] # Quitar nombre de carpeta
            
            # A. Coincidencia exacta
            if filename == clean_real:
                target_file = real_name
                break
            
            # B. Coincidencia parcial (el "salvavidas")
            if keyword.lower() in clean_real.lower() and filename.endswith('.tif'):
                target_file = real_name
                st.toast(f"‚ö†Ô∏è Archivo encontrado con nombre diferente: '{real_name}'")
                break
        
        # 4. Descargar o Reportar
        if target_file:
            file_bytes = client.storage.from_(bucket_name).download(target_file)
            return io.BytesIO(file_bytes)
        else:
            # SI FALLA: Muestra qu√© hay realmente en el bucket para diagnosticar
            st.warning(f"üîç No encontr√© '{filename}'.\nüìÇ Archivos disponibles en 'rasters': {all_files}")
            return None

    except Exception as e:
        st.error(f"Error de conexi√≥n con Storage: {e}")
        return None
        
@st.cache_data(ttl=3600)
def load_layer_cached(layer_name):
    file_map = {
        "Cuencas": "SubcuencasAinfluencia.geojson",
        "Municipios": "MunicipiosAntioquia.geojson",
        "Predios": "PrediosEjecutados.geojson"
    }
    if layer_name in file_map:
        try:
            # Ajuste de ruta robusto
            file_path = os.path.join(config.Config.DATA_DIR, file_map[layer_name])
            if not os.path.exists(file_path):
                # Fallback por si DATA_DIR no resuelve bien en cloud
                file_path = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', 'data', file_map[layer_name]))
            
            if os.path.exists(file_path):
                gdf = gpd.read_file(file_path)
                if gdf.crs and gdf.crs != "EPSG:4326": gdf = gdf.to_crs("EPSG:4326")
                return gdf
        except: return None
    return None

# --- MOTOR DE INTEGRACI√ìN: √ÅLGEBRA DE MAPAS ---
@st.cache_data(show_spinner=False)
def analizar_coberturas_por_zona_vida(_gdf_zona, zone_key):
    """
    Realiza la intersecci√≥n raster entre Zonas de Vida y Coberturas.
    Retorna un DataFrame con hect√°reas por combinaci√≥n.
    """
    try:
        # 1. Rutas de Archivos Base
        dem_path = st.session_state.get('dem_path', config.Config.DEM_FILE_PATH)
        ppt_path = st.session_state.get('ppt_path', config.Config.PRECIP_RASTER_PATH)
        cov_path = st.session_state.get('cov_path', config.Config.LAND_COVER_RASTER_PATH)

        # 2. Generar Mapa de Zonas de Vida (Raster 1)
        # Usamos _gdf_zona (el objeto original)
        lz_arr, lz_profile, lz_names, _ = lz.generate_life_zone_map(
            dem_path, ppt_path, mask_geometry=_gdf_zona, downscale_factor=4
        )
        
        if lz_arr is None: return None

        # 3. Alinear Mapa de Coberturas (Raster 2) al Raster 1
        with rasterio.open(cov_path) as src_cov:
            cov_aligned = np.zeros_like(lz_arr, dtype=np.uint8)
            
            reproject(
                source=rasterio.band(src_cov, 1),
                destination=cov_aligned,
                src_transform=src_cov.transform,
                src_crs=src_cov.crs,
                dst_transform=lz_profile['transform'],
                dst_crs=lz_profile['crs'],
                resampling=Resampling.nearest
            )

        # 4. C√°lculo de √Åreas (Hect√°reas)
        try:
            # Estimaci√≥n simple basada en la resoluci√≥n del transform
            res_x_deg = lz_profile['transform'][0]
            meters_per_deg = 111132.0 
            pixel_area_m2 = (res_x_deg * meters_per_deg) ** 2
            pixel_area_ha = pixel_area_m2 / 10000.0
        except:
            pixel_area_ha = 1.0

        # 5. Cruce (Crosstab)
        df_cross = pd.DataFrame({
            'ZV_ID': lz_arr.flatten(),
            'COV_ID': cov_aligned.flatten()
        })
        
        df_cross = df_cross[(df_cross['ZV_ID'] > 0) & (df_cross['COV_ID'] > 0)]
        
        resumen = df_cross.groupby(['ZV_ID', 'COV_ID']).size().reset_index(name='Pixeles')
        resumen['Hectareas'] = resumen['Pixeles'] * pixel_area_ha
        
        # 6. Enriquecer con Nombres
        resumen['Zona_Vida'] = resumen['ZV_ID'].map(lambda x: lz_names.get(x, f"ZV {x}"))
        resumen['Cobertura'] = resumen['COV_ID'].map(lambda x: lc.LAND_COVER_LEGEND.get(x, f"Clase {x}"))
        
        return resumen

    except Exception as e:
        # st.warning(f"Detalle t√©cnico cruce: {e}") # Descomentar para debug
        return None
        
# --- FUNCI√ìN DE INTEGRACI√ìN: DETECTAR ZONA DE VIDA ---
def detectar_zona_vida_dominante(gdf_zona):
    """
    Usa el m√≥dulo life_zones para estimar la zona clim√°tica del pol√≠gono seleccionado
    sin tener que procesar todo el raster pesado si no es necesario.
    """
    try:
        # 1. Calculamos el centroide de la zona seleccionada
        centroid = gdf_zona.to_crs("+proj=cea").centroid.to_crs("EPSG:4326").iloc[0]
        altitud = altitud_ref if altitud_ref > 0 else 1500 # Default si falla
        
        # 2. Obtenemos precipitaci√≥n promedio (Simulada o de base de datos)
        # En una integraci√≥n total, aqu√≠ leer√≠amos el raster de PPAMAnt.tif en ese punto
        ppt_estimada = 2000 # Valor medio para la regi√≥n si no hay raster cargado
        
        # 3. Usamos la l√≥gica de clasificaci√≥n de life_zones.py
        # ID -> Nombre
        zona_id = lz.classify_life_zone_alt_ppt(altitud, ppt_estimada)
        zona_nombre = lz.holdridge_int_to_name_simplified.get(zona_id, "Desconocido")
        
        # 4. Mapeo a c√≥digos de √Ålvarez (Ecuaciones)
        # Esto es un diccionario de traducci√≥n simple para el ejemplo
        mapa_codigos = {
            "Bosque h√∫medo Premontano (bh-PM)": "bh-PM",
            "Bosque muy h√∫medo Premontano (bmh-PM)": "bmh-PM",
            "Bosque muy h√∫medo Montano (bmh-M)": "bmh-M",
            "Bosque h√∫medo Tropical (bh-T)": "bh-T"
        }
        return mapa_codigos.get(zona_nombre, "bh-MB") # Default seguro
    except:
        return "bh-MB"

# --- DEFINICI√ìN DE TABS PRINCIPALES ---
tab_mapa, tab_tax, tab_carbon = st.tabs(["üó∫Ô∏è Mapa & GBIF", "üìä Taxonom√≠a", "üå≥ Calculadora Carbono"])

# Variable global para datos de biodiversidad
gdf_bio = pd.DataFrame()
threatened = pd.DataFrame()
n_threat = 0

# --- PROCESAMIENTO PREVIO (Solo si hay zona) ---
if gdf_zona is not None:
    with st.spinner(f"üì° Escaneando biodiversidad en {nombre_seleccion}..."):
        gdf_bio = gbif_connector.get_biodiversity_in_polygon(gdf_zona, limit=3000)
        
    if not gdf_bio.empty and 'Amenaza IUCN' in gdf_bio.columns:
        threatened = gdf_bio[~gdf_bio['Amenaza IUCN'].isin(['NE', 'LC', 'NT', 'DD', 'nan'])]
        n_threat = threatened['Nombre Cient√≠fico'].nunique()

# ==============================================================================
# TAB 1: MAPA Y M√âTRICAS
# ==============================================================================
with tab_mapa:
    if gdf_zona is not None:
        # 1. M√©tricas Principales
        c1, c2, c3, c4 = st.columns(4)
        c1.metric("Registros GBIF", f"{len(gdf_bio):,.0f}")
        c2.metric("Especies", f"{gdf_bio['Nombre Cient√≠fico'].nunique():,.0f}" if not gdf_bio.empty else "0")
        c3.metric("Familias", f"{gdf_bio['Familia'].nunique():,.0f}" if not gdf_bio.empty and 'Familia' in gdf_bio.columns else "0")
        c4.metric("Amenazadas (IUCN)", f"{n_threat}")

        # 2. Visor Territorial
        st.markdown("##### Visor Territorial")
        
        fig = go.Figure()

        # A. CENTRO DEL MAPA
        try:
            center = gdf_zona.to_crs("+proj=cea").centroid.to_crs("EPSG:4326").iloc[0]
            center_lat, center_lon = center.y, center.x
        except: center_lat, center_lon = 6.5, -75.5

        # B. CAPA ZONA (ROJO)
        for idx, row in gdf_zona.iterrows():
            if row.geometry:
                polys = [row.geometry] if row.geometry.geom_type == 'Polygon' else list(row.geometry.geoms) if row.geometry.geom_type == 'MultiPolygon' else []
                for poly in polys:
                    x, y = poly.exterior.xy
                    fig.add_trace(go.Scattermapbox(lon=list(x), lat=list(y), mode='lines', line=dict(width=3, color='red'), name='Zona Selecci√≥n', hoverinfo='skip'))

        # C. CAPAS DE CONTEXTO (Municipios, Cuencas, Predios)
        layers_to_show = [("Municipios", "gray", 1), ("Cuencas", "blue", 1.5), ("Predios", "orange", 1)]
        
        for lyr_name, color, width in layers_to_show:
            gdf_lyr = load_layer_cached(lyr_name)
            if gdf_lyr is not None:
                # Recorte espacial para optimizar (solo predios)
                if lyr_name == "Predios":
                    try:
                        roi_buf = gdf_zona.to_crs("EPSG:3116").buffer(1000).to_crs("EPSG:4326")
                        gdf_lyr = gpd.clip(gdf_lyr, roi_buf)
                    except: pass
                
                if not gdf_lyr.empty:
                    # Dibujamos solo el primer pol√≠gono con leyenda, el resto oculto en grupo
                    for idx, row in gdf_lyr.iterrows():
                        if row.geometry:
                            polys = [row.geometry] if row.geometry.geom_type == 'Polygon' else list(row.geometry.geoms) if row.geometry.geom_type == 'MultiPolygon' else []
                            for i, poly in enumerate(polys):
                                x, y = poly.exterior.xy
                                show_leg = True if idx == 0 and i == 0 else False
                                visible_opt = 'legendonly' if lyr_name == "Predios" else True
                                fig.add_trace(go.Scattermapbox(
                                    lon=list(x), lat=list(y), mode='lines', 
                                    line=dict(width=width, color=color), 
                                    name=lyr_name, legendgroup=lyr_name, 
                                    showlegend=show_leg, hoverinfo='skip', visible=visible_opt
                                ))

        # D. PUNTOS DE BIODIVERSIDAD (VERDE)
        if not gdf_bio.empty:
            fig.add_trace(go.Scattermapbox(
                lon=gdf_bio['lon'], lat=gdf_bio['lat'], 
                mode='markers', marker=dict(size=7, color='rgb(0, 200, 100)'), 
                text=gdf_bio['Nombre Com√∫n'], name='Biodiversidad'
            ))

        fig.update_layout(
            mapbox_style="carto-positron", 
            mapbox=dict(center=dict(lat=center_lat, lon=center_lon), zoom=10), 
            margin={"r":0,"t":0,"l":0,"b":0}, height=600,
            legend=dict(yanchor="top", y=0.99, xanchor="left", x=0.01, bgcolor="rgba(255, 255, 255, 0.8)")
        )
        st.plotly_chart(fig, use_container_width=True)
        
        if not gdf_bio.empty:
            st.download_button("üíæ Descargar Datos (CSV)", save_to_csv(gdf_bio.drop(columns='geometry', errors='ignore')), f"biodiv_{nombre_seleccion}.csv", "text/csv")

    else:
        st.info("üëà Seleccione una zona en el men√∫ lateral para visualizar el mapa.")

# ==============================================================================
# TAB 2: TAXONOM√çA
# ==============================================================================
with tab_tax:
    if not gdf_bio.empty:
        c1, c2 = st.columns([2,1])
        with c1:
            st.markdown("##### Estructura Taxon√≥mica")
            if 'Reino' in gdf_bio.columns and 'Familia' in gdf_bio.columns:
                df_chart = gdf_bio.fillna("Sin Dato")
                fig_sun = px.sunburst(df_chart, path=['Reino', 'Clase', 'Orden', 'Familia'], height=600)
                st.plotly_chart(fig_sun, use_container_width=True)
            else:
                st.warning("Datos taxon√≥micos insuficientes.")
        
        with c2:
            st.markdown("##### Especies Amenazadas")
            if not threatened.empty:
                st.warning(f"‚ö†Ô∏è {n_threat} especies en riesgo.")
                st.dataframe(threatened[['Nombre Cient√≠fico', 'Nombre Com√∫n', 'Amenaza IUCN']].drop_duplicates(), use_container_width=True, hide_index=True)
            else:
                st.success("‚úÖ No se detectaron especies en categor√≠as cr√≠ticas (CR, EN, VU) en esta zona.")
        
        st.markdown("##### Detalle de Registros")
        st.dataframe(gdf_bio.drop(columns='geometry', errors='ignore'), use_container_width=True)
    else:
        st.info("No hay datos de biodiversidad para mostrar estad√≠sticas.")

# ==============================================================================
# TAB 3: CALCULADORA DE CARBONO (SIST√âMICA)
# ==============================================================================
with tab_carbon:
    st.header("üå≥ Estimaci√≥n de Servicios Ecosist√©micos (Carbono)")
    
    if gdf_zona is None:
        st.warning("üëà Por favor selecciona una zona en el men√∫ lateral para iniciar.")
        st.stop()

    st.subheader("üîç Diagn√≥stico Territorial Integrado")
    
    # 1. DESCARGA DE RECURSOS (NUBE)
    with st.spinner("‚òÅÔ∏è Descargando capas clim√°ticas y de cobertura..."):
        dem_bytes = get_raster_from_cloud("DemAntioquia_EPSG3116.tif")
        ppt_bytes = get_raster_from_cloud("PPAMAnt.tif")
        cov_bytes = get_raster_from_cloud("Cob25m_WGS84.tif") # Nombre exacto en bucket

    # 2. PROCESAMIENTO
    if dem_bytes and ppt_bytes and cov_bytes:
        with st.spinner("üîÑ Cruzando mapas de Clima (Holdridge) y Cobertura..."):
            # AQU√ç ESTABA EL ERROR: Ahora pasamos 5 argumentos (incluyendo archivos y la clave)
            df_diagnostico = analizar_coberturas_por_zona_vida(
                gdf_zona, 
                nombre_seleccion,  # Clave de cache
                dem_bytes, 
                ppt_bytes, 
                cov_bytes
            )
    else:
        st.error("‚ùå No se pudieron descargar los mapas base desde la nube.")
        df_diagnostico = None

    # 3. RESULTADOS
    if df_diagnostico is not None and not df_diagnostico.empty:
        # IDs de Pastos/Degradados
        target_ids = [7, 3, 11] 
        df_potencial = df_diagnostico[df_diagnostico['COV_ID'].isin(target_ids)].copy()
        total_potencial = df_potencial['Hectareas'].sum()
        
        c_kpi1, c_kpi2 = st.columns(2)
        area_tot = gdf_zona.to_crs('+proj=cea').area.sum()/10000
        c_kpi1.metric("√Årea Total Seleccionada", f"{area_tot:,.1f} ha")
        c_kpi2.metric("Potencial Restauraci√≥n", f"{total_potencial:,.1f} ha", 
                      help="Suma de Pastos y √Åreas abiertas en todas las zonas de vida.")

        fig_bar = px.bar(df_potencial, x='Hectareas', y='Zona_Vida', color='Cobertura', 
                         orientation='h', title="√Åreas Restaurables por Clima",
                         color_discrete_sequence=px.colors.qualitative.Pastel)
        st.plotly_chart(fig_bar, use_container_width=True)
    else:
        if dem_bytes: # Solo mostrar advertencia si la descarga funcion√≥ pero el cruce fall√≥
            st.warning("El diagn√≥stico espacial no arroj√≥ resultados (posiblemente la zona est√° fuera del mapa).")
        df_potencial = pd.DataFrame()
        total_potencial = 0

    st.divider()

    # --- B. HERRAMIENTAS DE C√ÅLCULO ---
    modo_calc = st.radio("Selecciona el enfoque:", 
                         ["üîÆ Proyecci√≥n (Planificaci√≥n)", "üìè Inventario (L√≠nea Base)"], 
                         horizontal=True)

    if "Proyecci√≥n" in modo_calc:
        c1, c2 = st.columns([1, 2])
        with c1:
            st.markdown("**Configuraci√≥n**")
            opcion_area = st.radio("√Årea a restaurar:", ["Manual", "Todo el Potencial"], index=1)
            
            if opcion_area == "Manual":
                area_ha = st.number_input("√Årea (Ha):", min_value=0.1, value=1.0)
            else:
                val_default = float(total_potencial) if total_potencial > 0 else 1.0
                area_ha = st.number_input("√Årea (Ha):", min_value=0.1, value=val_default, disabled=True)

            anios_proj = st.slider("Horizonte (a√±os):", 5, 50, 20)
            if st.button("üöÄ Calcular Escenario", type="primary"):
                df_proj = carbon_calculator.calcular_proyeccion_captura(area_ha, anios_proj)
                st.session_state['df_carbon_proj'] = df_proj

        with c2:
            if 'df_carbon_proj' in st.session_state:
                df = st.session_state['df_carbon_proj']
                total_c = df['Proyecto_tCO2e_Acumulado'].iloc[-1]
                
                k1, k2, k3 = st.columns(3)
                k1.metric("Total CO2e", f"{total_c:,.0f} t")
                k2.metric("Promedio Anual", f"{(total_c/anios_proj):,.0f} t/a√±o")
                k3.metric("Valor Potencial", f"${(total_c*5):,.0f} USD")

                fig = px.area(df, x='A√±o', y='Proyecto_tCO2e_Acumulado',
                              title=f"Curva de Acumulaci√≥n ({area_ha:.1f} ha)",
                              color_discrete_sequence=['#27ae60'])
                st.plotly_chart(fig, use_container_width=True)

    else:
        c_inv_1, c_inv_2 = st.columns([1, 2])
        with c_inv_1:
            st.info("Sube Excel con columnas: DAP, Altura")
            up_file = st.file_uploader("Cargar Archivo", type=['csv', 'xlsx'])
            
            zv_sugerida = "bh-MB"
            if df_diagnostico is not None and not df_diagnostico.empty:
                try:
                    top_zv = df_diagnostico.groupby('Zona_Vida')['Hectareas'].sum().idxmax()
                    # Mapeo b√°sico de nombres largos a c√≥digos
                    mapa_nombres = {
                        "Bosque h√∫medo Premontano (bh-PM)": "bh-PM", 
                        "Bosque muy h√∫medo Montano Bajo (bmh-MB)": "bmh-MB",
                        "Bosque h√∫medo Tropical (bh-T)": "bh-T"
                    }
                    # Intenta buscar coincidencia parcial si no es exacta
                    for k, v in mapa_nombres.items():
                        if v in top_zv or top_zv in k:
                            zv_sugerida = v
                            break
                except: pass

            opciones_zv = ["bh-MB", "bh-PM", "bh-T", "bmh-M", "bmh-MB", "bmh-PM", "bp-PM", "bs-T", "me-T"]
            idx_def = opciones_zv.index(zv_sugerida) if zv_sugerida in opciones_zv else 0
            
            zona_vida = st.selectbox("Ecuaci√≥n (Zona de Vida):", opciones_zv, index=idx_def, help=f"Sugerido: {zv_sugerida}")

        with c_inv_2:
            if up_file and st.button("üßÆ Procesar"):
                try:
                    if up_file.name.endswith('.csv'):
                        df_inv = pd.read_csv(up_file, sep=';' if ';' in up_file.getvalue().decode('latin1') else ',')
                    else:
                        df_inv = pd.read_excel(up_file)
                    
                    df_res, msg = carbon_calculator.calcular_inventario_forestal(df_inv, zona_vida)
                    
                    if df_res is not None:
                        st.success("‚úÖ Procesado.")
                        tot_carb = df_res['CO2e_Total_tCO2e'].sum()
                        st.metric("Stock Total", f"{tot_carb:,.2f} tCO2e")
                        st.dataframe(df_res.head())
                        csv = df_res.to_csv(index=False).encode('utf-8')
                        st.download_button("üì• Descargar", csv, "inventario.csv", "text/csv")
                    else:
                        st.error(msg)
                except Exception as e:
                    st.error(f"Error: {e}")







